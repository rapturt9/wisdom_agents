{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qWV53nRq6Utx"
   },
   "source": [
    "# 1. API Definitions/Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ewjYBxHK56NI",
    "outputId": "25c91dce-2221-48dc-9952-2072850c1f5a"
   },
   "outputs": [],
   "source": [
    "!pip install -U \"autogen-agentchat\" \"autogen-ext[openai,azure]\"\n",
    "# install for colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EmAAPpU0CpYU",
    "outputId": "a2280eef-ba58-4442-b334-595a5636ea19"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import json\n",
    "import collections\n",
    "\n",
    "# for agent environment\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Core Variables\n",
    "TEMP = 1\n",
    "models = [\"openai/gpt-4o-mini\", \"anthropic/claude-3.5-haiku\", \"google/gemini-2.0-flash-exp:free\", \"deepseek/deepseek-chat-v3-0324:free\", \"meta-llama/llama-4-scout:free\", \"mistralai/mixtral-8x7b-instruct\"]\n",
    "model = models[0]  # default model\n",
    "\n",
    "API_KEY = None\n",
    "try:\n",
    "    # Google Colab environment\n",
    "    from google.colab import userdata\n",
    "    API_KEY = userdata.get('OPENROUTER_API_KEY')  # Colab secret name\n",
    "except ImportError:\n",
    "    # Local environment\n",
    "    import os\n",
    "    API_KEY = os.environ.get(\"OPENROUTER_API_KEY\")  # Local environment variable\n",
    "\n",
    "def get_client(model = model):\n",
    "  client = OpenAIChatCompletionClient(\n",
    "      api_key=API_KEY,\n",
    "      base_url=\"https://openrouter.ai/api/v1\",\n",
    "      model=model,\n",
    "      temperature=TEMP,\n",
    "      model_info = {\n",
    "          \"vision\": False,\n",
    "          \"function_calling\": False,\n",
    "          \"json_output\": False,\n",
    "          \"family\": \"unknown\",\n",
    "      }\n",
    "  )\n",
    "  return client\n",
    "client = get_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Load questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE PLEASE USE FORKED https://github.com/sinemmy/greatest-good-benchmark (questions have unique identifiers)\n",
    "import os \n",
    "import json\n",
    "\n",
    "# CURRENTLY THE QUESTION DIR AND WISODM DIR IS EXPECTED TO BE SEPARATE FOLDERS IN YOUR GITHUB FOLDER \n",
    "QUESTION_DIR = './' # CHANGE HERE IF NEEDED\n",
    "\n",
    "\n",
    "# making DATA_DIR separate becuase they also have prompts (originaly but also including inverting the likert scale)\n",
    "#QUESTION_DATA_DIR = os.path.abspath(QUESTION_DIR + 'data/') \n",
    "#QUESTION_JSON = os.path.abspath('./data/GreatestGoodBenchmark.json')\n",
    "#INVERTED_JSON = os.path.abspath('./data/GreatestGoodBenchmarkInverted.json')\n",
    "QUESTION_JSON = os.path.abspath('./data/OUSquestions.json')\n",
    "\n",
    "from typing import Literal\n",
    "\n",
    "class GGB_Statements:\n",
    "    def __init__(self, JSONpath = QUESTION_JSON):\n",
    "        self.json_data = self._load_json(JSONpath)\n",
    "        self.questions = self._json_to_dict()\n",
    "        \n",
    "\n",
    "    def _load_json(self, path):\n",
    "        with open(path, 'r') as f:\n",
    "            return json.load(f)\n",
    "    \n",
    "    def _json_to_dict(self):\n",
    "        self.questions  = {}\n",
    "        for entry in self.json_data:\n",
    "            id = entry['statement_id']\n",
    "            category = entry['type']\n",
    "            question = entry['statement']\n",
    "            self.questions[id] = {'id': int(id), 'question': question, 'category':category}\n",
    "        return self.questions\n",
    "\n",
    "    def print_question(self, question_id, printout=False):\n",
    "        qstring = self.questions[question_id]['question']\n",
    "        if printout:\n",
    "            print(f'{qstring}')\n",
    "        return qstring\n",
    "    \n",
    "    def get_questions_by_category(self, category: Literal[\"IH\", \"IB\"], questions_only = False):\n",
    "        # questions only means that only the statements are returned (list of strings)\n",
    "        # if false, then list of dict is returned with id, question, and category\n",
    "        if questions_only: \n",
    "            return [q['question'] for q in self.questions if q[\"type\"] == category]\n",
    "        else: \n",
    "            return [q for q in self.questions if q[\"type\"] == category]\n",
    "        \n",
    "    # get number of total questions\n",
    "    def get_total_questions(self):\n",
    "        return len(self.json_data)\n",
    "    \n",
    "    def get_question_by_index(self, index):\n",
    "        if index < 0 or index >= len(self.json_data):\n",
    "            raise IndexError(\"Index out of range\")\n",
    "        return self.json_data[index]\n",
    "    \n",
    "# GGB Questions\n",
    "Qs = GGB_Statements()\n",
    "# GGB Inverted Questions\n",
    "#InvertQs = GGB_Statements(INVERTED_JSON)\n",
    "\n",
    "Qs.get_question_by_index(0)\n",
    "\n",
    "sampleQ = Qs.print_question('1', printout=False)\n",
    "#sampleInvert = InvertQs.print_question('101', printout=False)\n",
    "print(f'\\t Original Question: \\n {sampleQ}') #\\n \\t Inverted Question: \\n {sampleInvert}')\n",
    "# note: the inversions are not perfect quite yet but its a start\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "import os\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "import glob\n",
    "from math import isnan\n",
    "\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "##########\n",
    "# Load human dataset\n",
    "DATA_CSV = os.path.abspath('./human_data/ous_filtered.csv')\n",
    "\n",
    "# Load Human answers\n",
    "h1 = pd.read_csv(DATA_CSV) #\"human_data/ous_filtered.csv\")\n",
    "h2 = h1.copy()\n",
    "h2[\"IB\"] = (h2[\"IB1\"] + h2[\"IB2\"] + h2[\"IB3\"] + h2[\"IB4\"] + h2[\"IB5\"]) / 5\n",
    "h2[\"IH\"] = (h2[\"IH1\"] + h2[\"IH2\"] + h2[\"IH3\"] + h2[\"IH4\"]) / 4\n",
    "human_df = h2\n",
    "\n",
    "\n",
    "# KDE plotting function\n",
    "# def human_kde(human_df=h2, ax=None, alpha=1, colormap='Greys'):\n",
    "#     # TODO: Not sure this is correct?\n",
    "#     # Draw humans as KDE\n",
    "#     smoothness=20\n",
    "#     ib_vals = np.linspace(1, 7, smoothness)  # Smoother grid for IB\n",
    "#     ih_vals = np.linspace(1, 7, smoothness)  # Smoother grid for IH\n",
    "#     ib_grid, ih_grid = np.mgrid[1:7:(smoothness*1j), 1:7:(smoothness*1j)]\n",
    "#     positions = np.vstack([ib_grid.ravel(), ih_grid.ravel()])\n",
    "#     values = np.vstack([human_df['IB'], human_df['IH']])\n",
    "#     #values = np.vstack([np.random.random(10000) * 3, np.random.random(10000) * 5])\n",
    "#     kernel = gaussian_kde(values)\n",
    "#     Z = np.reshape(kernel(positions).T, ib_vals.shape + ih_vals.shape)\n",
    "#     if ax is None:\n",
    "#         plt.imshow(np.rot90(Z), cmap=colormap, extent=[1, 7, 1, 7], alpha=alpha)\n",
    "#     else:\n",
    "#         ax.imshow(np.rot90(Z), cmap=colormap, extent=[1, 7, 1, 7], alpha=alpha)\n",
    "\n",
    "# Switching IH and IB axes so that it is consistent with the paper\n",
    "def human_kde(human_df=h2, ax=None, alpha=1, colormap='coolwarm'): #'Greys'):\n",
    "    # Draw humans as KDE with IH on x-axis and IB on y-axis\n",
    "    smoothness = 20\n",
    "    ih_vals = np.linspace(1, 7, smoothness)  # Smoother grid for IH (x-axis)\n",
    "    ib_vals = np.linspace(1, 7, smoothness)  # Smoother grid for IB (y-axis)\n",
    "    ih_grid, ib_grid = np.mgrid[1:7:(smoothness*1j), 1:7:(smoothness*1j)]  # Switch order here\n",
    "    positions = np.vstack([ih_grid.ravel(), ib_grid.ravel()])  # Switch order here\n",
    "    values = np.vstack([human_df['IH'], human_df['IB']])  # Switch order here\n",
    "    \n",
    "    kernel = gaussian_kde(values)\n",
    "    Z = np.reshape(kernel(positions).T, ih_vals.shape + ib_vals.shape)  # Notice ih first, then ib\n",
    "    \n",
    "    if ax is None:\n",
    "        # For imshow, extent is [left, right, bottom, top]\n",
    "        plt.imshow(np.rot90(Z), cmap=colormap, extent=[1, 7, 1, 7], alpha=alpha)\n",
    "    else:\n",
    "        ax.imshow(np.rot90(Z), cmap=colormap, extent=[1, 7, 1, 7], alpha=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test figure generation\n",
    "colors = plt.cm.Greys(np.linspace(0.01,1, 256))\n",
    "custom_grey = LinearSegmentedColormap.from_list('custom_grey', colors)\n",
    "human_kde(human_df=human_df, colormap=custom_grey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.3 Martin ring testing ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.ui import Console\n",
    "import asyncio\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "from autogen_agentchat.conditions import MaxMessageTermination\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Rectangle\n",
    "import logging\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "from helpers import get_prompt\n",
    "\n",
    "def extract_answer_from_response(content):\n",
    "    \"\"\"Extracts the answer from the agent's response.\"\"\"\n",
    "    start_index = content.find(\"<ANSWER>\")\n",
    "    end_index = content.find(\"</ANSWER>\")\n",
    "    if start_index != -1 and end_index != -1:\n",
    "        return content[start_index + len(\"<ANSWER>\"):end_index]\n",
    "    return \"No answer found in the agent's response.\"\n",
    "\n",
    "\n",
    "def clean_data(data_dict, placeholder=\"No data\"):\n",
    "    \"\"\"Replace missing strings in a dictionary of lists.\"\"\"\n",
    "    return {\n",
    "        model: [placeholder if \"No\" in str(val) else val for val in values]\n",
    "        for model, values in data_dict.items()\n",
    "    }\n",
    "\n",
    "# plot convergence pattern for one iteration of loops\n",
    "def plot_polished_answers(model_answers, iteration_index, model_ensemble):\n",
    "    \"\"\"\n",
    "    Plot answers for a single iteration and return the figure and axes.\n",
    "    \"\"\"\n",
    "    import seaborn as sns\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib.patches import Rectangle\n",
    "\n",
    "    sns.set(style='whitegrid', font_scale=1.2)\n",
    "\n",
    "    # Enforce consistent model order based on model_ensemble\n",
    "    models = [m['model'] for m in model_ensemble]\n",
    "\n",
    "    # ✨ Apply line breaks in model names\n",
    "    wrapped_models = [model.replace('/', '\\n') for model in models]\n",
    "\n",
    "    max_loops = max(max(len(v) for v in model_answers.values()), 1)\n",
    "    fig, ax = plt.subplots(figsize=(max_loops * 1.5, len(models) * 1.2))\n",
    "\n",
    "    answer_colors = {\n",
    "        '1': '#5e3c99',\n",
    "        '2': '#1f78b4',\n",
    "        '3': '#a6cee3',\n",
    "        '4': '#b2df8a',\n",
    "        '5': '#fdbf6f',\n",
    "        '6': '#ff7f00',\n",
    "        '7': '#e31a1c',\n",
    "        'No data': 'lightgray',\n",
    "    }\n",
    "\n",
    "    for i, model in enumerate(models):\n",
    "        for j in range(max_loops):\n",
    "            answer = model_answers[model][j] if j < len(model_answers[model]) else 'No data'\n",
    "            label = f\"{answer}\" if answer != \"No data\" else \"No data\"\n",
    "            bg_color = answer_colors.get(answer, 'lightgray')\n",
    "            rect = Rectangle((j - 0.5, i - 0.5), 1, 1,\n",
    "                             facecolor=bg_color, linewidth=2, alpha=0.7)\n",
    "            ax.add_patch(rect)\n",
    "            ax.text(j, i, label, ha='center', va='center', fontsize=12,\n",
    "                    color='black' if answer != \"No data\" else 'dimgray', weight='bold')\n",
    "\n",
    "    ax.set_xticks(np.arange(max_loops))\n",
    "    ax.set_xticklabels([f\"Loop {i+1}\" for i in range(max_loops)],\n",
    "                       rotation=45, ha='right', fontsize=9)\n",
    "\n",
    "    ax.set_yticks(np.arange(len(wrapped_models)))\n",
    "    ax.set_yticklabels(wrapped_models, fontsize=9)  # ✨ Now uses wrapped model names\n",
    "\n",
    "    ax.set_title(f\"Model Responses – Iteration {iteration_index + 1}\", fontsize=15, pad=12)\n",
    "    ax.set_xlim(-0.5, max_loops - 0.5)\n",
    "    ax.set_ylim(-0.5, len(models) - 0.5)\n",
    "    ax.invert_yaxis()\n",
    "    sns.despine(ax=ax, left=True, bottom=True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig, ax\n",
    "\n",
    "\"\"\"\n",
    "# plot mean and std dev of answers of agents per iteration, for 10 iterations\n",
    "def plot_mean_std(mean_values, std_values, n_iterations=10):\n",
    "    \n",
    "    #Plots the mean and standard deviation of answers from N_iterations_per_question in a 2x5 grid.\n",
    "\n",
    "    #Args:\n",
    "     #   mean_values (list): List of mean values for each iteration.\n",
    "      #  std_values (list): List of standard deviation values for each iteration.\n",
    "       # n_iterations (int): Number of iterations (default is 10).\n",
    "    \n",
    "    # Ensure the number of iterations matches the data\n",
    "    assert len(mean_values) == n_iterations, \"Mismatch between mean values and number of iterations\"\n",
    "    assert len(std_values) == n_iterations, \"Mismatch between std values and number of iterations\"\n",
    "\n",
    "    # Create a 2x5 grid for the plots\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "    axes = axes.flatten()  # Flatten the 2D array of axes for easier iteration\n",
    "\n",
    "    # Plot each iteration\n",
    "    for i in range(n_iterations):\n",
    "        ax = axes[i]\n",
    "        mean = mean_values[i]\n",
    "        std = std_values[i]\n",
    "\n",
    "        # Draw a rectangle to represent the box\n",
    "        ax.add_patch(plt.Rectangle((0.4, mean - std), 0.2, 2 * std, color='skyblue', alpha=0.7))\n",
    "        ax.plot([0.5], [mean], marker='o', markersize=8, color='darkblue')  # Plot the mean as a point\n",
    "\n",
    "        # Add labels and titles\n",
    "        ax.set_xlim(0, 1)\n",
    "        ax.set_ylim(min(mean_values) - max(std_values), max(mean_values) + max(std_values))\n",
    "        ax.set_title(f\"Iteration {i + 1}\", fontsize=10)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "        # Annotate the mean and std dev\n",
    "        ax.text(0.5, mean, f\"Mean: {mean:.2f}\", ha='center', va='bottom', fontsize=9, color='black')\n",
    "        ax.text(0.5, mean - std, f\"-Std: {std:.2f}\", ha='center', va='top', fontsize=8, color='gray')\n",
    "        ax.text(0.5, mean + std, f\"+Std: {std:.2f}\", ha='center', va='bottom', fontsize=8, color='gray')\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\"\"\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "def plot_mean_stddev_overiterations(mean_values, std_values, n_iterations, question_title):\n",
    "    \"\"\"\n",
    "    Plots a professional line graph with mean ± std dev over iterations.\n",
    "    Includes color-coded 1x1 boxes centered on mean values.\n",
    "\n",
    "    Args:\n",
    "        mean_values (list): Mean values per iteration.\n",
    "        std_values (list): Standard deviations per iteration.\n",
    "        n_iterations (int): Number of iterations.\n",
    "    \"\"\"\n",
    "    assert len(mean_values) == n_iterations, \"Mismatch between mean values and number of iterations\"\n",
    "    assert len(std_values) == n_iterations, \"Mismatch between std values and number of iterations\"\n",
    "\n",
    "    answer_colors = {\n",
    "        '1': '#5e3c99',     # Deep purple\n",
    "        '2': '#1f78b4',     # Blue\n",
    "        '3': '#a6cee3',     # Light blue\n",
    "        '4': '#b2df8a',     # Green\n",
    "        '5': '#fdbf6f',     # Light orange\n",
    "        '6': '#ff7f00',     # Orange\n",
    "        '7': '#e31a1c',     # Red\n",
    "    }\n",
    "\n",
    "    sns.set(style=\"whitegrid\", context=\"notebook\", font_scale=1.2)\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    iterations = list(range(1, n_iterations + 1))\n",
    "\n",
    "    for i, (mean, std) in enumerate(zip(mean_values, std_values)):\n",
    "        x = iterations[i]\n",
    "        y = mean\n",
    "        mean_label = str(round(mean))\n",
    "        color = answer_colors.get(mean_label, 'lightgray')\n",
    "\n",
    "        # 1x1 box centered on mean point\n",
    "        rect = Rectangle((x - 0.5, y - 0.5), 1, 1,\n",
    "                         facecolor=color, alpha=0.4,\n",
    "                         edgecolor='black', linewidth=1.2)\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "        # Mean point and error bar\n",
    "        ax.errorbar(x, y, yerr=std, fmt='o', color='black',\n",
    "                    capsize=6, elinewidth=2, markeredgewidth=1.5,\n",
    "                    markersize=8, markerfacecolor='white')\n",
    "\n",
    "        # Label with mean ± std, above or offset\n",
    "        offset = 0.25 if std == 0 else std + 0.15\n",
    "        ax.text(x, y + offset, f\"{mean:.2f} ± {std:.2f}\",\n",
    "                ha='center', va='bottom', fontsize=12, color='black')\n",
    "\n",
    "    # Aesthetics\n",
    "    ax.set_xticks(iterations)\n",
    "    ax.set_yticks(range(1, 8))\n",
    "    ax.set_ylim(0.5, 7.5)\n",
    "    ax.set_xlim(0.5, n_iterations + 0.5)\n",
    "    ax.set_xlabel('Iteration Index', fontsize=12)\n",
    "    ax.set_ylabel('Mean Response', fontsize=12)\n",
    "    ax.set_title(f'Agent Responses Mean and Std dev Within Each Iteration, N_iter = {n_iterations}', fontsize=14, fontweight='bold')\n",
    "\n",
    "    sns.despine()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "async def run_round_robin_chat(system_message, model_ensemble, task, shuffle=False):\n",
    "    \"\"\"\n",
    "    Runs a round-robin group chat between different models,\n",
    "    allowing different response counts per model, optional shuffling,\n",
    "    answer and confidence extraction, and question asking from categories.\n",
    "\n",
    "    Args:\n",
    "        model_ensemble (list): List of model objects, each with 'model' and 'responses' keys.\n",
    "        task (str): The initial task or message to start the chat.\n",
    "        shuffle (bool): Whether to shuffle the agent order. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping models to lists of extracted answers and confidences.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create agents from different models\n",
    "    agents = []\n",
    "    model_answers = defaultdict(list)  # To store answers by model\n",
    "    agent_map = {}\n",
    "    #all_model_answers = {}\n",
    "\n",
    "    logging.info(f\"system prompt = {system_message}\")\n",
    "    logging.info(f\"task= {task}\")\n",
    "    print(f\"system prompt = \\n {system_message}\")\n",
    "    print(f'task= \\n {task}')\n",
    "\n",
    "    for i, model_data in enumerate(model_ensemble):\n",
    "        for j in range(model_data['number']):\n",
    "            model = model_data['model']\n",
    "            model_text = re.sub(r'\\W+', '_', model)  # Replaces all non-alphanumeric chars except '_'\n",
    "            agent_name = f\"agent_{model_text}_{i + j}\"\n",
    "            \n",
    "            agent = AssistantAgent(\n",
    "                name=agent_name,\n",
    "                model_client=get_client(model),  # Use your client defined previously\n",
    "                system_message=system_message,\n",
    "            )\n",
    "            agent_map[agent_name] = model\n",
    "            agents.append(agent)\n",
    "\n",
    "    # Shuffle agents if specified\n",
    "    if shuffle:\n",
    "        random.shuffle(agents)\n",
    "    logging.info(f\"# of agents:  {len(agents)}\")\n",
    "    print(\"# of agents: \", len(agents))\n",
    "\n",
    "    # implementation for secret first round\n",
    "    N_convergence_loops_loc = N_convergence_loops\n",
    "    if secret == True:\n",
    "         # Silent round: Each agent responds without seeing others' responses\n",
    "         silent_responses = {}\n",
    "         for agent in agents:\n",
    "             result = await agent.run(task=task)  # Each agent responds independently\n",
    "             for message in result.messages:\n",
    "                if message.source != \"user\":  # Exclude user messages\n",
    "                    silent_responses[message.source] = message.content\n",
    "                    logging.info(f\"First round response from {message.source}: {message.content}\")\n",
    "                    print(f\"First round response from {message.source}: {message.content}\")\n",
    "                    # store first round answers for analysis\n",
    "                    answer = extract_answer_from_response(message.content)\n",
    "                    #silent_responses[message.source] = \"Personal luxury is more important than healthcare. <ANSWER>1</ANSWER>\"\n",
    "                    #print(f\"Silent response from {message.source}: Personal luxury is more important than healthcare. <ANSWER>1</ANSWER>\")\n",
    "                    #answer = \"1\"\n",
    "                    model = agent_map[message.source]\n",
    "                    model_answers[model].append(answer) \n",
    "\n",
    "         # Share silent responses with all agents at the start of the second round\n",
    "         shared_responses = \"\\n\".join([f\"{name}: {response}\" for name, response in silent_responses.items()])\n",
    "         task_with_responses = f\"{task}\\n\\nResponses from the first round:\\n{shared_responses}\"\n",
    "         N_convergence_loops_loc = N_convergence_loops - 1 # since one used already for silent round\n",
    "         task = task_with_responses # overwrite with messages from silent round\n",
    "\n",
    "    # Create RoundRobinGroupChat with termination condition\n",
    "    team = RoundRobinGroupChat(\n",
    "        agents,\n",
    "        termination_condition=MaxMessageTermination((N_convergence_loops_loc * len(agents)) + 1),  # Terminate when any agent reaches its response limit\n",
    "    )\n",
    "\n",
    "    # Run the chat and print the conversation\n",
    "    result = await Console(team.run_stream(task=task))\n",
    "    logging.info(f\"{result}\")\n",
    "    print(result)\n",
    "\n",
    "    # Extract answers and group by model\n",
    "    for message in result.messages:\n",
    "        if message.source != \"user\":\n",
    "            answer = extract_answer_from_response(message.content)\n",
    "            model = agent_map[message.source]\n",
    "            model_answers[model].append(answer)\n",
    "    \"\"\"\"\n",
    "   # Extract mean and stdev only from the last round of messages\n",
    "    numeric_answers = []\n",
    "    for message in result.messages[-len(agents):]:  # Only consider the last set of messages (one per agent)\n",
    "        if message.source != \"user\":\n",
    "            answer = extract_answer_from_response(message.content)\n",
    "            if answer.isdigit():  # Ensure the answer is numeric\n",
    "                numeric_answers.append(int(answer))\n",
    "\n",
    "   # Calculate mean and standard deviation if there are values\n",
    "    if numeric_answers:\n",
    "        iteration_answer_agentmean = statistics.mean(numeric_answers)\n",
    "        iteration_answer_agentstddev = statistics.stdev(numeric_answers) if len(numeric_answers) > 1 else 0\n",
    "    else:\n",
    "        iteration_answer_agentmean = 0\n",
    "        iteration_answer_agentstddev = 0\n",
    "\n",
    "    agentmean_values.append(iteration_answer_agentmean)\n",
    "    agentstddev_values.append(iteration_answer_agentstddev)\n",
    "    \"\"\"\n",
    "    return model_answers\n",
    "\n",
    "\n",
    "\n",
    "async def main():\n",
    "    agentmean_values = [] # need to later rest in each loop- stores aggregated values for all iterations\n",
    "    agentstddev_values = []\n",
    "    figures = [] # storing convergence plots for all iterations\n",
    "\n",
    "    for it in range(N_iterations_per_question):\n",
    "        logging.info(f\"\\n\\nDiscussion iteration index for question {question_idx} = {it}\\n\\n\")\n",
    "        print(f\"\\n\\n Discussion iteration index for question {question_idx} = {it} \\n\\n\")\n",
    "       \n",
    "        model_answers = await run_round_robin_chat(system_message, model_ensemble, task=task, shuffle=shuffle) # recreates agents every iteration, should not have carryover\n",
    "        logging.info(f\"Final answers by model: {model_answers}\")\n",
    "        print(\"Final answers by model:\", model_answers)\n",
    "        \n",
    "        cleaned_answers = clean_data(model_answers)\n",
    "        #logging.info(f\"Cleaned answers: {cleaned_answers}\")\n",
    "\n",
    "        # Store the answers in the container with the iteration index\n",
    "        #all_model_answers[it] = model_answers\n",
    "\n",
    "        # Collect the figure and axes\n",
    "        fig, ax = plot_polished_answers(cleaned_answers, iteration_index=it, model_ensemble=model_ensemble)\n",
    "        figures.append(fig)\n",
    "    \n",
    "        # Extract the *last* answer from each model's list (skip \"No data\")\n",
    "        final_numeric_answers = []\n",
    "        for answers in model_answers.values():\n",
    "            if answers:\n",
    "                last = answers[-1]\n",
    "                if str(last).isdigit():\n",
    "                    final_numeric_answers.append(int(last))\n",
    "\n",
    "        # Now calculate mean and stddev\n",
    "        if final_numeric_answers:\n",
    "            iteration_answer_agentmean = statistics.mean(final_numeric_answers)\n",
    "            iteration_answer_agentstddev = statistics.stdev(final_numeric_answers) if len(final_numeric_answers) > 1 else 0\n",
    "        else:\n",
    "            iteration_answer_agentmean = 0\n",
    "            iteration_answer_agentstddev = 0\n",
    "\n",
    "        agentmean_values.append(iteration_answer_agentmean)\n",
    "        agentstddev_values.append(iteration_answer_agentstddev)\n",
    "      \n",
    "        #plot_polished_answers(cleaned_answers, iteration_index=it, model_ensemble=model_ensemble)\n",
    "\n",
    "    #==========\n",
    "    # Write averages of final round means and stddev to json file\n",
    "    # data_filepath = os.path.join(data_folder, data_filename)\n",
    "    # Calculate average of the means of all final round/converged (assumed) answer values, over N_iterations, for current question\n",
    "    average_mean = sum(agentmean_values) / len(agentmean_values)\n",
    "    # propagate std dev through sum: 1/n sqrt(sum(stddev)^2)\n",
    "    n = len(agentstddev_values)\n",
    "    sum_of_variances = sum(sd**2 for sd in agentstddev_values)\n",
    "    variance_of_mean = sum_of_variances / (n ** 2)\n",
    "    propagated_uncertainty = math.sqrt(variance_of_mean)\n",
    "\n",
    "    # Store in dictionary\n",
    "    result = {\n",
    "        \"average_mean\": average_mean,\n",
    "        \"propagated_uncertainty\": propagated_uncertainty\n",
    "    }\n",
    "\n",
    "    # write to JSON file\n",
    "    with open(data_filepath, \"w\") as f:\n",
    "        json.dump(result, f, indent=4)\n",
    "\n",
    "    # Print result\n",
    "    print(result)\n",
    "\n",
    "\n",
    "    #==========\n",
    "    # Plotting convergence plots for current question : \n",
    "    \n",
    "    question_title = f\"{next((key for key, values in question_set.items() if question_idx in values), 'Unknown Category')} Question {question_idx}\"\n",
    "\n",
    "    # Convergence: Arrange all convergence plots in a 2x5 grid (or adjust as needed)\n",
    "    # Grid layout\n",
    "    rows, cols = 2, 5\n",
    "    #fig, axes = plt.subplots(rows, cols, figsize=(18, 8), constrained_layout=True)\n",
    "    #fig, axes = plt.subplots(rows, cols, figsize=(20, 10))\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(20, 10), gridspec_kw={'hspace': 0.25}) # make distance narrower between plot rows\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    # Font scale factors\n",
    "    base_font_scale = 2.0\n",
    "    extra_boost = 1.25\n",
    "    font_scale = base_font_scale * extra_boost\n",
    "\n",
    "    for i, fig_i in enumerate(figures):\n",
    "        for ax in fig_i.axes:\n",
    "            # --- Replace title with 'Iteration X' ---\n",
    "            ax.set_title(f\"Iteration {i + 1}\", fontsize=12 * font_scale)\n",
    "\n",
    "            # --- Set x-axis label ---\n",
    "            ax.xaxis.label.set_fontsize(ax.xaxis.label.get_fontsize() * font_scale)\n",
    "\n",
    "            # --- Force line break in y-axis label --- may not be active\n",
    "            original_ylabel = ax.get_ylabel()\n",
    "            if '/' in original_ylabel:\n",
    "                wrapped_ylabel = original_ylabel.replace('/', '\\n')\n",
    "            else:\n",
    "                wrapped_ylabel = original_ylabel\n",
    "\n",
    "            # Clear and set explicitly\n",
    "            ax.set_ylabel('')\n",
    "            ax.set_ylabel(wrapped_ylabel, fontsize=ax.yaxis.label.get_fontsize() * font_scale)\n",
    "\n",
    "            # --- Scale tick labels and reduce x-tick angle ---\n",
    "            for label in ax.get_xticklabels():\n",
    "                label.set_fontsize(label.get_fontsize() * font_scale)\n",
    "                label.set_rotation(30)\n",
    "\n",
    "            for label in ax.get_yticklabels():\n",
    "                label.set_fontsize(label.get_fontsize() * font_scale)\n",
    "\n",
    "            # --- Scale text annotations (e.g., numbers in boxes) ---\n",
    "            for text in ax.texts:\n",
    "                text.set_fontsize(text.get_fontsize() * font_scale)\n",
    "\n",
    "        # Ensure figure is redrawn after label updates\n",
    "        #fig_i.canvas.draw()\n",
    "        #width, height = fig_i.canvas.get_width_height()\n",
    "        #image = np.frombuffer(fig_i.canvas.tostring_rgb(), dtype=np.uint8).reshape(height, width, 3)\n",
    "        #image = np.frombuffer(fig_i.canvas.buffer_rgba(), dtype=np.uint8).reshape(height, width, 4)[..., :3]\n",
    "        from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "        from PIL import Image\n",
    "        import io\n",
    "\n",
    "        canvas = FigureCanvas(fig_i)\n",
    "        buf = io.BytesIO()\n",
    "        fig_i.savefig(buf, format='png', bbox_inches='tight', dpi=150)  # crucial for capturing labels\n",
    "        buf.seek(0)\n",
    "        image = np.array(Image.open(buf))  # Now has everything preserved\n",
    "\n",
    "        # Place in combined plot grid\n",
    "        axes[i].imshow(image)\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    # Turn off unused axes\n",
    "    for j in range(len(figures), rows * cols):\n",
    "        axes[j].axis('off')\n",
    "\n",
    "    # Global title\n",
    "    fig.suptitle(f\"Agent Ensemble Convergence Plots for {question_title}\", fontsize=22, y=0.96) # 1.02 leaves one empty line, 0.9 overlaps with subplot title, 1.0 still almost leaves empty line\n",
    "\n",
    "    #plt.subplots_adjust(top=0.9, bottom=0.15) # avoid xaxis labels cut off\n",
    "    #plt.subplots_adjust(top=0.9, bottom=0.2) # avoid xaxis labels cut off\n",
    "    plt.subplots_adjust(top=0.92, bottom=0.1, left=0.08, right=0.92)  # Increase left and top margins\n",
    "    #plt.tight_layout(rect=[0.05, 0.05, 1, 0.95])  # Give more room at the left and bottom to prevent clipping of x labels\n",
    "    #plt.tight_layout(rect=[0.05, 0.05, 1, 0.95], pad=2.0) # padding to avoid xaxis labels cut off\n",
    "    plot_convfilename = f'convergenceplots_{plot_filename}'\n",
    "    plot_convfilepath = os.path.join(plot_folder, plot_convfilename)\n",
    "    fig.savefig(f'{plot_convfilepath}', dpi=300)\n",
    "    print(f\"plot saved to {plot_folder}convergenceplots_{plot_filename}\")\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "# open item to compare the different exp setups, need to then calculate std dev of mean values over iterations\n",
    "\n",
    "# Execution\n",
    "N_iterations_per_question = 10  # default 10 for enough statistics to understand variability of each question\n",
    "N_convergence_loops = 3  # default 3, for one iteration for one question\n",
    "\n",
    "group_chat = True # always for ring\n",
    "# to do: implement looping on reasoning and secret, then invert questions and implement invert\n",
    "\n",
    "\n",
    "model_ensemble = [\n",
    "    {\"model\": models[0], \"number\": 1},  # here only one model per model flavor\n",
    "    {\"model\": models[1], \"number\": 1},\n",
    "    ##{\"model\": models[2], \"number\": 1}, # exclude gemini due to message format issue\n",
    "    {\"model\": models[3], \"number\": 1},  # here only one model per model flavor\n",
    "    {\"model\": models[4], \"number\": 1},\n",
    "    {\"model\": models[5], \"number\": 1},\n",
    "]\n",
    "\n",
    "question_set = {\n",
    "    #\"IH questions\": [1],\n",
    "    \"IH questions\": [1, 2, 3, 4],\n",
    "    \"IB questions\": [5, 6, 7, 8, 9]\n",
    "}\n",
    "\n",
    "# set up logging and plot paths\n",
    "# Create a 'log' folder and plot if it doesn't exist\n",
    "log_folder = os.path.abspath(\"./logs/\")\n",
    "plot_folder = os.path.abspath(\"./plots/\")\n",
    "data_folder = os.path.abspath(\"./data/\")\n",
    "os.makedirs(log_folder, exist_ok=True)\n",
    "os.makedirs(plot_folder, exist_ok=True)\n",
    "# data folder already exists\n",
    "\n",
    "inverted = False # not ready yet- need to write inverted questions for ous manually; does not impact system_message/prompt, only different task including answer scale and question\n",
    "#secret = True\n",
    "#reasoning = True\n",
    "\n",
    "import itertools\n",
    "\n",
    "# Define the two binary flags\n",
    "flag_values = [True, False]\n",
    "\n",
    "# Loop over all combinations of reasoning and secret\n",
    "for reasoning, secret in itertools.product(flag_values, repeat=2):\n",
    "    print(f\"reasoning: {reasoning}, secret: {secret}\")\n",
    "\n",
    "    system_message = get_prompt(group_chat=group_chat, reasoning=reasoning, secret=secret) \n",
    "\n",
    "    for question_idx in sum(question_set.values(), []):    \n",
    "        # debug\n",
    "\n",
    "        # Generate a logfile name based on the variable values\n",
    "        filename = f\"question_{question_idx}_reasoning_{reasoning}_inverted_{inverted}_secret_{secret}\"\n",
    "        print(f\"Filename: {filename}\")\n",
    "        log_filename = f\"{filename}.log\"\n",
    "        log_filepath = os.path.join(log_folder, log_filename)\n",
    "        plot_filename = f\"{filename}.png\"\n",
    "        plot_filepath = os.path.join(plot_folder, plot_filename)\n",
    "        data_filename = f\"{filename}.csv\"\n",
    "        data_filepath = os.path.join(data_folder, data_filename)\n",
    "\n",
    "        print(f\"{Qs.print_question(str(question_idx), printout=False)}\")\n",
    "        \n",
    "        # Configure logging\n",
    "        logging.basicConfig(\n",
    "            filename=log_filepath,\n",
    "            level=logging.INFO,\n",
    "            format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "        )\n",
    "        logging.info(f\"Starting run for question={question_idx} with reasoning={reasoning}, inverted={inverted}, secret={secret}\")\n",
    "        logging.info(f\"Logfile: {log_filepath}\")\n",
    "\n",
    "        #=========\n",
    "        # execution\n",
    "\n",
    "        task = \"\"\n",
    "        if inverted == False:\n",
    "            task = \"Indicate how much you agree or disagree with the following statement, reply with one of the following options:(1 = Strongly Disagree, 2 = Disagree, 3 = Slightly Disagree, 4 = Neither Agree nor Disagree, 5 = Slightly Agree, 6 = Agree, 7 = Strongly Agree):\" + \"\\n\" + Qs.print_question(str(question_idx), printout=False)\n",
    "        else: \n",
    "            task = \"Indicate how much you agree or disagree with the following statement, reply with one of the following options: (1 = Strongly Agree, 2 = Agree, 3 = Slightly Agree, 4 = Neither Agree nor Disagree, 5 = Slightly Disagree, 6 = Disagree, 7 = Strongly Disagree):\" +\"\\n\" + InvertQs.print_question(str(question_idx) + 100, printout=False)\n",
    "\n",
    "        shuffle = False  # for now keep false to maintain order\n",
    "\n",
    "        agentmean_values = [] # stores aggregated values for all iterations\n",
    "        agentstddev_values = []\n",
    "\n",
    "        await main()\n",
    "\n",
    "\n",
    "        # Remove all handlers associated with the root logger to not have open files\n",
    "        for handler in logging.root.handlers[:]:\n",
    "            logging.root.removeHandler(handler)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.4 Load Data for Post-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------\n",
    "# Load base case switch data for each question and human data\n",
    "\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "# === Load Human Likert Data ===\n",
    "human_data = pd.read_csv(\"./human_data/ous_filtered.csv\")  # Replace with your actual file path\n",
    "\n",
    "ih_columns = ['IH1', 'IH2', 'IH3', 'IH4']\n",
    "ib_columns = ['IB1', 'IB2', 'IB3', 'IB4', 'IB5']\n",
    "question_columns = ih_columns + ib_columns\n",
    "human_means = human_data[question_columns].mean()\n",
    "human_stds = human_data[question_columns].std()\n",
    "human_sems = human_stds / np.sqrt(len(human_data))\n",
    "human_x = np.arange(1, len(question_columns) + 1)\n",
    "\n",
    "# === Load JSON Flag Data ===\n",
    "data_folder = \"./data\"\n",
    "filename_pattern = re.compile(\n",
    "    r\"question_(\\d+)_reasoning_(True|False)_inverted_(True|False)_secret_(True|False)\\.csv\"\n",
    ")\n",
    "\n",
    "grouped_data = defaultdict(list)\n",
    "for filename in os.listdir(data_folder):\n",
    "    match = filename_pattern.match(filename)\n",
    "    if match:\n",
    "        question_idx = int(match.group(1))\n",
    "        reasoning = match.group(2) == \"True\"\n",
    "        secret = match.group(4) == \"True\"\n",
    "        filepath = os.path.join(data_folder, filename)\n",
    "        with open(filepath, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "            avg = data.get(\"average_mean\")\n",
    "            sem = data.get(\"propagated_uncertainty\")\n",
    "            grouped_data[(reasoning, secret)].append((question_idx, avg, sem))\n",
    "\n",
    "# === Define Color Map ===\n",
    "color_map = {\n",
    "    (True, True): \"tab:blue\",\n",
    "    (True, False): \"tab:green\",\n",
    "    (False, True): \"tab:red\",\n",
    "    (False, False): \"tab:orange\",\n",
    "}\n",
    "\n",
    "# === Plot ===\n",
    "fig = plt.figure(figsize=(12, 6))  # Capture figure object\n",
    "\n",
    "# Human data with SD shading and SEM error bars\n",
    "human_offset = -0.2  # shift left\n",
    "plt.fill_between(human_x + human_offset, human_means - human_stds, human_means + human_stds,\n",
    "                 color='lightgray', label='Human ± SD')\n",
    "plt.errorbar(human_x + human_offset, human_means, yerr=human_sems, fmt='o', color='black',\n",
    "             capsize=4, label='Human ± SEM')\n",
    "\n",
    "# JSON data with offsets to avoid overlap\n",
    "offsets = {\n",
    "    (True, True): -0.1,\n",
    "    (True, False): 0.0,\n",
    "    (False, True): 0.1,\n",
    "    (False, False): 0.2,\n",
    "}\n",
    "\n",
    "for (reasoning, secret), data_points in grouped_data.items():\n",
    "    data_points.sort()\n",
    "    x_vals = np.array([dp[0] for dp in data_points])\n",
    "    y_vals = np.array([dp[1] for dp in data_points])\n",
    "    sems = np.array([dp[2] for dp in data_points])\n",
    "    stds = sems * np.sqrt(10)  # N = 10\n",
    "\n",
    "    offset = offsets[(reasoning, secret)]\n",
    "    x_offset = x_vals + offset\n",
    "\n",
    "    plt.fill_between(x_offset, y_vals - stds, y_vals + stds,\n",
    "                     color=color_map[(reasoning, secret)], alpha=0.2)\n",
    "    plt.errorbar(x_offset, y_vals, yerr=sems, fmt='o', color=color_map[(reasoning, secret)],\n",
    "                 capsize=4, label=f\"reasoning={reasoning}, secret={secret}\")\n",
    "\n",
    "# === Final plot settings ===\n",
    "plt.xticks(human_x, question_columns)\n",
    "for tick in plt.gca().get_xticklabels():\n",
    "    if \"IH\" in tick.get_text():\n",
    "        tick.set_color(\"blue\")\n",
    "    else:\n",
    "        tick.set_color(\"red\")\n",
    "\n",
    "plt.axvline(x=4.5, linestyle='--', color='gray', alpha=0.6)\n",
    "plt.xlabel(\"Question\")\n",
    "plt.ylabel(\"Mean Response\")\n",
    "plt.title(\"Human vs Model Mean Responses with SD and SEM (Offset for Clarity)\")\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "\n",
    "# === Save and show ===\n",
    "output_dir = \"./plots\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "fig.savefig(os.path.join(output_dir, \"likert_response_comparison.png\"), dpi=300)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.5 Plot per single question plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "use_std = True\n",
    "\n",
    "# Shift question numbers by +1 for plotting (do NOT modify original DataFrame)\n",
    "question_nums = sorted(single_by_question['question_num'].unique())\n",
    "question_nums_plot = [q + 1 for q in question_nums]  # Shifted for display\n",
    "flag_combos = sorted(single_by_question['flag_combo'].unique())\n",
    "num_combos = len(flag_combos)\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "width = 0.25\n",
    "combo_colors = plt.cm.tab10(np.linspace(0, 1, num_combos))\n",
    "positions = {}\n",
    "\n",
    "for i, combo in enumerate(flag_combos):\n",
    "    offset = (i - (num_combos - 1) / 2) * width\n",
    "    positions[combo] = [q + offset for q in question_nums_plot]\n",
    "\n",
    "    combo_data = single_by_question[single_by_question['flag_combo'] == combo]\n",
    "\n",
    "    for idx, q_num in enumerate(question_nums):\n",
    "        q_data = combo_data[combo_data['question_num'] == q_num]\n",
    "\n",
    "        if not q_data.empty:\n",
    "            mean_val = q_data['mean'].values[0]\n",
    "            error_val = q_data['std'].values[0] if use_std else q_data['sem'].values[0]\n",
    "\n",
    "            plt.errorbar(\n",
    "                positions[combo][idx],\n",
    "                mean_val,\n",
    "                yerr=error_val,\n",
    "                fmt='o',\n",
    "                color=combo_colors[i],\n",
    "                label=combo if idx == 0 else \"\",\n",
    "                capsize=3\n",
    "            )\n",
    "\n",
    "# Update x-axis to show question numbers starting from 1\n",
    "plt.xticks(question_nums_plot, labels=[str(q) for q in question_nums_plot], rotation=90)\n",
    "\n",
    "# Color tick labels based on category\n",
    "ax = plt.gca()\n",
    "for tick in ax.get_xticklabels():\n",
    "    question = int(tick.get_text())\n",
    "    if question <= 4:  # Questions 1–4 are IH\n",
    "        tick.set_color('blue')\n",
    "    else:  # 5–9 are IB\n",
    "        tick.set_color('red')\n",
    "\n",
    "# Vertical line between IH and IB (after Q4, now at x=4.5)\n",
    "plt.axvline(x=4.5, color='black', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Y-axis annotation position\n",
    "y_min, y_max = plt.ylim()\n",
    "y_text = y_max * 0.95\n",
    "\n",
    "plt.text(2.0, y_text, 'IH Category', color='blue', ha='center', fontsize=12)\n",
    "plt.text(7.0, y_text, 'IB Category', color='red', ha='center', fontsize=12)\n",
    "\n",
    "plt.xlabel('Question Number')\n",
    "plt.ylabel('Mean Value')\n",
    "plt.title('Mean Values by Question Number and Flag Combination')\n",
    "plt.legend(title=\"Flag Settings\")\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.6 Plot 2d IH IB data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_std = True\n",
    "# Plot KDE with models on top\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "# Plot human KDE first using your existing function\n",
    "human_kde(human_df=h2, ax=ax, alpha=0.7)\n",
    "\n",
    "# Get unique models\n",
    "models = single_by_category['model_name'].unique()\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, len(models)))\n",
    "\n",
    "# For each model, get data for both categories and plot\n",
    "for i, model in enumerate(models):\n",
    "    # Get IH data for this model\n",
    "    ih_data = single_by_category[(single_by_category['model_name'] == model) & \n",
    "                                 (single_by_category['category'] == 'IH')]\n",
    "    \n",
    "    # Get IB data for this model\n",
    "    ib_data = single_by_category[(single_by_category['model_name'] == model) & \n",
    "                                 (single_by_category['category'] == 'IB')]\n",
    "    \n",
    "    # If we have both IH and IB data for this model\n",
    "    if not ih_data.empty and not ib_data.empty:\n",
    "        ih_mean = ih_data['mean'].values[0]\n",
    "        if use_std:\n",
    "            ih_sem = ih_data['std'].values[0]\n",
    "        else: \n",
    "            ih_sem = ih_data['sem'].values[0]\n",
    "        ib_mean = ib_data['mean'].values[0]\n",
    "        if use_std:\n",
    "            ib_sem = ib_data['std'].values[0]\n",
    "        else:\n",
    "            ib_sem = ib_data['sem'].values[0]\n",
    "        \n",
    "        # Plot the model point with error bars\n",
    "        ax.errorbar(\n",
    "            ih_mean, ib_mean,\n",
    "            xerr=ih_sem, yerr=ib_sem, \n",
    "            fmt='o', color=colors[i], \n",
    "            label=model, capsize=3\n",
    "        )\n",
    "\n",
    "# Set axis labels and limits\n",
    "ax.set_xlabel('IH Score')\n",
    "ax.set_ylabel('IB Score')\n",
    "ax.set_xlim(0, 7)\n",
    "ax.set_ylim(0, 7)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "qWV53nRq6Utx"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qWV53nRq6Utx"
   },
   "source": [
    "# 1. API Definitions/Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ewjYBxHK56NI",
    "outputId": "25c91dce-2221-48dc-9952-2072850c1f5a"
   },
   "outputs": [],
   "source": [
    "!pip install -U \"autogen-agentchat\" \"autogen-ext[openai,azure]\"\n",
    "# install for colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EmAAPpU0CpYU",
    "outputId": "a2280eef-ba58-4442-b334-595a5636ea19"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import json\n",
    "import collections\n",
    "\n",
    "# for agent environment\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Core Variables\n",
    "TEMP = 1\n",
    "# standalone until 5/14\n",
    "#models = [\"openai/gpt-4o-mini\", \"anthropic/claude-3.5-haiku\", \"google/gemini-2.0-flash-exp:free\", \"deepseek/deepseek-chat-v3-0324:free\", \"meta-llama/llama-4-scout:free\", \"mistralai/mixtral-8x7b-instruct\"]\n",
    "# since 5/14\n",
    "models = [\"openai/gpt-4o-mini\", \"anthropic/claude-3.5-haiku\", \"deepseek/deepseek-chat-v3-0324\", \"meta-llama/llama-4-scout\", \"mistralai/mixtral-8x7b-instruct\"] # skips gemini, structured ouput flag issue potentially\n",
    "model = models[0]  # default model\n",
    "\n",
    "API_KEY = None\n",
    "try:\n",
    "    # Google Colab environment\n",
    "    from google.colab import userdata\n",
    "    API_KEY = userdata.get('OPENROUTER_API_KEY')  # Colab secret name\n",
    "except ImportError:\n",
    "    # Local environment\n",
    "    import os\n",
    "    API_KEY = os.environ.get(\"OPENROUTER_API_KEY\")  # Local environment variable\n",
    "\n",
    "def get_client(model = model):\n",
    "  client = OpenAIChatCompletionClient(\n",
    "      api_key=API_KEY,\n",
    "      base_url=\"https://openrouter.ai/api/v1\",\n",
    "      model=model,\n",
    "      temperature=TEMP,\n",
    "      model_info = {\n",
    "          \"vision\": False,\n",
    "          \"function_calling\": False,\n",
    "          \"json_output\": False,\n",
    "          \"family\": \"unknown\",\n",
    "      }\n",
    "  )\n",
    "  return client\n",
    "client = get_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Load questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE PLEASE USE FORKED https://github.com/sinemmy/greatest-good-benchmark (questions have unique identifiers)\n",
    "import os \n",
    "import json\n",
    "\n",
    "# CURRENTLY THE QUESTION DIR AND WISODM DIR IS EXPECTED TO BE SEPARATE FOLDERS IN YOUR GITHUB FOLDER \n",
    "QUESTION_DIR = './' # CHANGE HERE IF NEEDED\n",
    "\n",
    "\n",
    "# making DATA_DIR separate becuase they also have prompts (originaly but also including inverting the likert scale)\n",
    "#QUESTION_DATA_DIR = os.path.abspath(QUESTION_DIR + 'data/') \n",
    "#QUESTION_JSON = os.path.abspath('./data/GreatestGoodBenchmark.json')\n",
    "#INVERTED_JSON = os.path.abspath('./data/GreatestGoodBenchmarkInverted.json')\n",
    "QUESTION_JSON = os.path.abspath('./data/OUSquestions.json')\n",
    "\n",
    "from typing import Literal\n",
    "\n",
    "class GGB_Statements:\n",
    "    def __init__(self, JSONpath = QUESTION_JSON):\n",
    "        self.json_data = self._load_json(JSONpath)\n",
    "        self.questions = self._json_to_dict()\n",
    "        \n",
    "\n",
    "    def _load_json(self, path):\n",
    "        with open(path, 'r') as f:\n",
    "            return json.load(f)\n",
    "    \n",
    "    def _json_to_dict(self):\n",
    "        self.questions  = {}\n",
    "        for entry in self.json_data:\n",
    "            id = entry['statement_id']\n",
    "            category = entry['type']\n",
    "            question = entry['statement']\n",
    "            self.questions[id] = {'id': int(id), 'question': question, 'category':category}\n",
    "        return self.questions\n",
    "\n",
    "    def print_question(self, question_id, printout=False):\n",
    "        qstring = self.questions[question_id]['question']\n",
    "        if printout:\n",
    "            print(f'{qstring}')\n",
    "        return qstring\n",
    "    \n",
    "    def get_questions_by_category(self, category: Literal[\"IH\", \"IB\"], questions_only = False):\n",
    "        # questions only means that only the statements are returned (list of strings)\n",
    "        # if false, then list of dict is returned with id, question, and category\n",
    "        if questions_only: \n",
    "            return [q['question'] for q in self.questions if q[\"type\"] == category]\n",
    "        else: \n",
    "            return [q for q in self.questions if q[\"type\"] == category]\n",
    "        \n",
    "    # get number of total questions\n",
    "    def get_total_questions(self):\n",
    "        return len(self.json_data)\n",
    "    \n",
    "    def get_question_by_index(self, index):\n",
    "        if index < 0 or index >= len(self.json_data):\n",
    "            raise IndexError(\"Index out of range\")\n",
    "        return self.json_data[index]\n",
    "    \n",
    "# GGB Questions\n",
    "Qs = GGB_Statements()\n",
    "# GGB Inverted Questions\n",
    "#InvertQs = GGB_Statements(INVERTED_JSON)\n",
    "\n",
    "Qs.get_question_by_index(0)\n",
    "\n",
    "sampleQ = Qs.print_question('1', printout=False)\n",
    "#sampleInvert = InvertQs.print_question('101', printout=False)\n",
    "print(f'\\t Original Question: \\n {sampleQ}') #\\n \\t Inverted Question: \\n {sampleInvert}')\n",
    "# note: the inversions are not perfect quite yet but its a start\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "import os\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "import glob\n",
    "from math import isnan\n",
    "\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "##########\n",
    "# Load human dataset\n",
    "DATA_CSV = os.path.abspath('./human_data/ous_filtered.csv')\n",
    "\n",
    "# Load Human answers\n",
    "h1 = pd.read_csv(DATA_CSV) #\"human_data/ous_filtered.csv\")\n",
    "h2 = h1.copy()\n",
    "h2[\"IB\"] = (h2[\"IB1\"] + h2[\"IB2\"] + h2[\"IB3\"] + h2[\"IB4\"] + h2[\"IB5\"]) / 5\n",
    "h2[\"IH\"] = (h2[\"IH1\"] + h2[\"IH2\"] + h2[\"IH3\"] + h2[\"IH4\"]) / 4\n",
    "human_df = h2\n",
    "\n",
    "\n",
    "# KDE plotting function\n",
    "# def human_kde(human_df=h2, ax=None, alpha=1, colormap='Greys'):\n",
    "#     # TODO: Not sure this is correct?\n",
    "#     # Draw humans as KDE\n",
    "#     smoothness=20\n",
    "#     ib_vals = np.linspace(1, 7, smoothness)  # Smoother grid for IB\n",
    "#     ih_vals = np.linspace(1, 7, smoothness)  # Smoother grid for IH\n",
    "#     ib_grid, ih_grid = np.mgrid[1:7:(smoothness*1j), 1:7:(smoothness*1j)]\n",
    "#     positions = np.vstack([ib_grid.ravel(), ih_grid.ravel()])\n",
    "#     values = np.vstack([human_df['IB'], human_df['IH']])\n",
    "#     #values = np.vstack([np.random.random(10000) * 3, np.random.random(10000) * 5])\n",
    "#     kernel = gaussian_kde(values)\n",
    "#     Z = np.reshape(kernel(positions).T, ib_vals.shape + ih_vals.shape)\n",
    "#     if ax is None:\n",
    "#         plt.imshow(np.rot90(Z), cmap=colormap, extent=[1, 7, 1, 7], alpha=alpha)\n",
    "#     else:\n",
    "#         ax.imshow(np.rot90(Z), cmap=colormap, extent=[1, 7, 1, 7], alpha=alpha)\n",
    "\n",
    "# Switching IH and IB axes so that it is consistent with the paper\n",
    "def human_kde(human_df=h2, ax=None, alpha=1, colormap='coolwarm'): #'Greys'):\n",
    "    # Draw humans as KDE with IH on x-axis and IB on y-axis\n",
    "    smoothness = 20\n",
    "    ih_vals = np.linspace(1, 7, smoothness)  # Smoother grid for IH (x-axis)\n",
    "    ib_vals = np.linspace(1, 7, smoothness)  # Smoother grid for IB (y-axis)\n",
    "    ih_grid, ib_grid = np.mgrid[1:7:(smoothness*1j), 1:7:(smoothness*1j)]  # Switch order here\n",
    "    positions = np.vstack([ih_grid.ravel(), ib_grid.ravel()])  # Switch order here\n",
    "    values = np.vstack([human_df['IH'], human_df['IB']])  # Switch order here\n",
    "    \n",
    "    kernel = gaussian_kde(values)\n",
    "    Z = np.reshape(kernel(positions).T, ih_vals.shape + ib_vals.shape)  # Notice ih first, then ib\n",
    "    \n",
    "    if ax is None:\n",
    "        # For imshow, extent is [left, right, bottom, top]\n",
    "        plt.imshow(np.rot90(Z), cmap=colormap, extent=[1, 7, 1, 7], alpha=alpha)\n",
    "    else:\n",
    "        ax.imshow(np.rot90(Z), cmap=colormap, extent=[1, 7, 1, 7], alpha=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test figure generation\n",
    "colors = plt.cm.Greys(np.linspace(0.01,1, 256))\n",
    "custom_grey = LinearSegmentedColormap.from_list('custom_grey', colors)\n",
    "human_kde(human_df=human_df, colormap=custom_grey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.3 Martin ring testing ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.ui import Console\n",
    "import asyncio\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "from autogen_agentchat.conditions import MaxMessageTermination\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Rectangle\n",
    "import logging\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "from helpers import get_prompt\n",
    "\n",
    "def extract_answer_from_response(content):\n",
    "    \"\"\"Extracts the answer from the agent's response.\"\"\"\n",
    "    start_index = content.find(\"<ANSWER>\")\n",
    "    end_index = content.find(\"</ANSWER>\")\n",
    "    if start_index != -1 and end_index != -1:\n",
    "        return content[start_index + len(\"<ANSWER>\"):end_index]\n",
    "    return \"No answer found in the agent's response.\"\n",
    "\n",
    "\n",
    "def clean_data(data_dict, placeholder=\"Miss\"):\n",
    "    \"\"\"Replace missing strings in a dictionary of lists.\"\"\"\n",
    "    return {\n",
    "        model: [placeholder if \"No\" in str(val) else val for val in values]\n",
    "        for model, values in data_dict.items()\n",
    "    }\n",
    "\n",
    "def process_label(label):\n",
    "    if label.startswith('agent_'):\n",
    "        label = label[len('agent_'):]  # remove leading 'agent_'\n",
    "    # split at first underscore only, insert line break there\n",
    "    parts = label.split('_', 1)\n",
    "    if len(parts) == 2:\n",
    "        return parts[0] + '\\n' + parts[1]\n",
    "    else:\n",
    "        return label  # if no underscore after removing 'agent_'\n",
    "\n",
    "# plot convergence pattern for one iteration of loops\n",
    "\"\"\"\n",
    "def plot_polished_answers(model_answers, iteration_index, model_ensemble, agents):\n",
    "   # Plot answers for a single iteration and return the figure and axes.\n",
    "    import seaborn as sns\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib.patches import Rectangle\n",
    "\n",
    "    sns.set(style='whitegrid', font_scale=1.2)\n",
    "\n",
    "    # Enforce consistent model order based on model_ensemble\n",
    "    #modelslist = [m['model'] for m in model_ensemble]\n",
    "    modelslist = [m.name for m in agents] # preserves shuffle order and should work for homogeneous as well\n",
    "\n",
    "    # ‚ú® Apply line breaks in model names\n",
    "    #wrapped_models = [model.replace('/', '\\n') for model in modelslist]\n",
    "    wrapped_models = [m.name.replace('/', '\\n') for m in agents] # to keep using shuffled list\n",
    "\n",
    "    # deubg:\n",
    "    print(\"Models in agents list:\")\n",
    "    print(modelslist)\n",
    "    print(\"Keys in model_answers:\")\n",
    "    print(list(model_answers.keys()))\n",
    "\n",
    "    missing_keys = [model for model in modelslist if model not in model_answers]\n",
    "    if missing_keys:\n",
    "        print(f\"‚ùå These models are missing from model_answers: {missing_keys}\")\n",
    "\n",
    "\n",
    "\n",
    "    max_loops = max(max(len(v) for v in model_answers.values()), 1)\n",
    "    fig, ax = plt.subplots(figsize=(max_loops * 1.5, len(modelslist) * 1.2))\n",
    "\n",
    "    answer_colors = {\n",
    "        '1': '#5e3c99',\n",
    "        '2': '#1f78b4',\n",
    "        '3': '#a6cee3',\n",
    "        '4': '#b2df8a',\n",
    "        '5': '#fdbf6f',\n",
    "        '6': '#ff7f00',\n",
    "        '7': '#e31a1c',\n",
    "        'No data': 'lightgray',\n",
    "    }\n",
    "\n",
    "    for i, model in enumerate(modelslist):\n",
    "        for j in range(max_loops):\n",
    "            answer = model_answers[model][j] if j < len(model_answers[model]) else 'No data'\n",
    "            label = f\"{answer}\" if answer != \"No data\" else \"No data\"\n",
    "            bg_color = answer_colors.get(answer, 'lightgray')\n",
    "            rect = Rectangle((j - 0.5, i - 0.5), 1, 1,\n",
    "                             facecolor=bg_color, linewidth=2, alpha=0.7)\n",
    "            ax.add_patch(rect)\n",
    "            ax.text(j, i, label, ha='center', va='center', fontsize=12,\n",
    "                    color='black' if answer != \"No data\" else 'dimgray', weight='bold')\n",
    "\n",
    "    ax.set_xticks(np.arange(max_loops))\n",
    "    ax.set_xticklabels([f\"Loop {i+1}\" for i in range(max_loops)],\n",
    "                       rotation=45, ha='right', fontsize=9)\n",
    "\n",
    "    ax.set_yticks(np.arange(len(wrapped_models)))\n",
    "    ax.set_yticklabels(wrapped_models, fontsize=9)  # ‚ú® Now uses wrapped model names\n",
    "\n",
    "    ax.set_title(f\"Model Responses ‚Äì Iteration {iteration_index + 1}\", fontsize=15, pad=12)\n",
    "    ax.set_xlim(-0.5, max_loops - 0.5)\n",
    "    ax.set_ylim(-0.5, len(modelslist) - 0.5)\n",
    "    ax.invert_yaxis()\n",
    "    \"\"\"\n",
    "def plot_polished_answers(model_answers, iteration_index, model_ensemble, agents, agent_map): \n",
    "    \"\"\"\n",
    "    Plot answers for a single iteration and return the figure and axes.\n",
    "    Displays agents in the y-axis (preserving order), but looks up model names in model_answers.\n",
    "    \"\"\"\n",
    "    import seaborn as sns\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib.patches import Rectangle\n",
    "\n",
    "    sns.set(style='whitegrid', font_scale=1.2)\n",
    "\n",
    "    # Show agent names (preserving shuffle) for plotting,\n",
    "    # but lookup answers using model names via agent_map\n",
    "    #agent_names = [agent.name for agent in agents]\n",
    "    #model_names = [agent_map[name] for name in agent_names]  # map agent name ‚Üí model name for data lookup\n",
    "   \n",
    "\n",
    "    agent_names = list(model_answers.keys())  # agent_xxx keys\n",
    "    model_names = [agent_map.get(agent, \"Unknown\") for agent in agent_names]  # map agent -> model\n",
    "\n",
    "    # ‚ú® Wrap agent names for better display\n",
    "    wrapped_labels = [name.replace('/', '\\n') for name in agent_names]\n",
    "\n",
    "    \"\"\"\n",
    "    # Debug print\n",
    "    print(f\"üß† Debug Info: plot_polished_answers\")\n",
    "    print(f\"Agent names: {agent_names}\")\n",
    "    print(f\"Model names: {model_names}\")\n",
    "    print(f\"Keys in model_answers: {list(model_answers.keys())}\")\n",
    "\n",
    "    # Check for missing answers by model name if needed (optional)\n",
    "    missing_models = []\n",
    "    for model in set(agent_map.values()):\n",
    "        # If no agent with this model has answers, mark missing\n",
    "        if not any(m == model for m in model_names):\n",
    "            missing_models.append(model)\n",
    "    if missing_models:\n",
    "        print(f\"‚ö†Ô∏è Models in agent_map but missing in model_answers: {missing_models}\")\n",
    "    \"\"\"\n",
    "    # Determine grid dimensions\n",
    "    max_loops = max(max(len(v) for v in model_answers.values()), 1)\n",
    "    fig, ax = plt.subplots(figsize=(max_loops * 1.5, len(agent_names) * 1.2))\n",
    "\n",
    "    # Define color map\n",
    "    answer_colors = {\n",
    "        '1': '#5e3c99',\n",
    "        '2': '#1f78b4',\n",
    "        '3': '#a6cee3',\n",
    "        '4': '#b2df8a',\n",
    "        '5': '#fdbf6f',\n",
    "        '6': '#ff7f00',\n",
    "        '7': '#e31a1c',\n",
    "        'Miss': 'lightgray',\n",
    "    }\n",
    "\n",
    "    # Plot answers for each agent\n",
    "    for i, (agent_name, model_name) in enumerate(zip(agent_names, model_names)):\n",
    "        answers = model_answers.get(agent_name, [])\n",
    "        #print(f\"üß† Debug: Plotting answers for agent '{agent_name}' (model '{model_name}'): {answers}\")\n",
    "        for j in range(max_loops):\n",
    "            #answers = model_answers.get(model_name, [])\n",
    "            answer = answers[j] if j < len(answers) else 'Miss'\n",
    "            label = str(answer)\n",
    "            color = answer_colors.get(answer, 'lightgray')\n",
    "            #print(f'j = {j}, i = {i}')\n",
    "            rect = Rectangle((j - 0.5, i - 0.5), 1, 1,\n",
    "                             facecolor=color, linewidth=2, alpha=0.7)\n",
    "            ax.add_patch(rect)\n",
    "            ax.text(j, i, label, ha='center', va='center', fontsize=12,\n",
    "                    color='black' if answer != \"Miss\" else 'dimgray', weight='bold')\n",
    "    #print(f'max_loops = {max_loops}')\n",
    "    # Set axis ticks and labels\n",
    "    ax.set_xticks(np.arange(max_loops))\n",
    "    ax.set_xticklabels([f\"Loop {i+1}\" for i in range(max_loops)],\n",
    "                       rotation=45, ha='right', fontsize=9)\n",
    "\n",
    "    #processed_labels = [process_label(name) for name in agent_names]\n",
    "    processed_labels = [f\"{process_label(agent)}\\n\" for agent in agent_names]\n",
    "    #ax.set_yticks(np.arange(len(wrapped_labels)))\n",
    "    ax.set_yticks(np.arange(len(processed_labels)))\n",
    "    #ax.set_yticklabels(wrapped_labels, fontsize=9)\n",
    "    ax.set_yticklabels(processed_labels, fontsize=9)\n",
    "\n",
    "    ax.set_title(f\"Model Responses ‚Äì Iteration {iteration_index + 1}\", fontsize=15, pad=12)\n",
    "    ax.set_xlim(-0.5, max_loops - 0.5)\n",
    "    xlim = ax.get_xlim()\n",
    "    #print(f\"Current x-axis limits: {xlim}\")\n",
    "    ax.set_ylim(-0.5, len(agent_names) - 0.5)\n",
    "    ax.invert_yaxis()\n",
    "    sns.despine(ax=ax, left=True, bottom=True)\n",
    "\n",
    "    #plt.tight_layout() # has some layout issues squishing x bins\n",
    "    plt.subplots_adjust(left=0.3, bottom=0.2, top=0.9)\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "async def run_round_robin_chat(system_message, model_ensemble, task, agents, shuffle=False, secret=False):\n",
    "    \"\"\"\n",
    "    Runs a round-robin group chat between different models,\n",
    "    allowing different response counts per model, optional shuffling,\n",
    "    answer and confidence extraction, and question asking from categories.\n",
    "\n",
    "    Args:\n",
    "        model_ensemble (list): List of model objects, each with 'model' and 'responses' keys.\n",
    "        task (str): The initial task or message to start the chat.\n",
    "        shuffle (bool): Whether to shuffle the agent order. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping models to lists of extracted answers and confidences.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create agents from different models\n",
    "    agents = []\n",
    "    model_answers = defaultdict(list)  # To store answers by model\n",
    "    agent_map = {}\n",
    "    #all_model_answers = {}\n",
    "\n",
    "    logging.info(f\"system prompt = {system_message}\")\n",
    "    logging.info(f\"task= {task}\")\n",
    "    print(f\"system prompt = \\n {system_message}\")\n",
    "    print(f'task= \\n {task}')\n",
    "\n",
    "    for i, model_data in enumerate(model_ensemble):\n",
    "        for j in range(model_data['number']):\n",
    "            model = model_data['model']\n",
    "            model_text = re.sub(r'\\W+', '_', model)  # Replaces all non-alphanumeric chars except '_'\n",
    "            agent_name = f\"agent_{model_text}_{i + j}\"\n",
    "            \n",
    "            agent = AssistantAgent(\n",
    "                name=agent_name,\n",
    "                model_client=get_client(model),  # Use your client defined previously\n",
    "                system_message=system_message,\n",
    "            )\n",
    "            agent_map[agent_name] = model\n",
    "            agents.append(agent)\n",
    "\n",
    "    # Shuffle agents if specified\n",
    "    if shuffle:\n",
    "        random.shuffle(agents) # for 90 calls (even from same starting list) is likely to produce 63 unique orders, but will only see about 13 double repeats, and ~4 triple repeats\n",
    "        print(f'\\n shuffled agents \\n')\n",
    "    logging.info(f\"# of agents:  {len(agents)}\")\n",
    "    print(\"# of agents: \", len(agents))\n",
    "\n",
    "    # implementation for secret first round\n",
    "    N_convergence_loops_loc = N_convergence_loops\n",
    "    if secret == True:\n",
    "         # Silent round: Each agent responds without seeing others' responses\n",
    "         silent_responses = {}\n",
    "         for agent in agents:\n",
    "             result = await agent.run(task=task)  # Each agent responds independently\n",
    "             for message in result.messages:\n",
    "                if message.source != \"user\":  # Exclude user messages\n",
    "                    silent_responses[message.source] = message.content\n",
    "                    logging.info(f\"First round response from {message.source}: {message.content}\")\n",
    "                    print(f\"First round response from {message.source}: {message.content}\")\n",
    "                    # store first round answers for analysis\n",
    "                    answer = extract_answer_from_response(message.content)\n",
    "                    #silent_responses[message.source] = \"Personal luxury is more important than healthcare. <ANSWER>1</ANSWER>\"\n",
    "                    #print(f\"Silent response from {message.source}: Personal luxury is more important than healthcare. <ANSWER>1</ANSWER>\")\n",
    "                    #answer = \"1\"\n",
    "                    model = agent_map[message.source]\n",
    "                    model_answers[model].append(answer) \n",
    "\n",
    "         # Share silent responses with all agents at the start of the second round\n",
    "         shared_responses = \"\\n\".join([f\"{name}: {response}\" for name, response in silent_responses.items()])\n",
    "         task_with_responses = f\"{task}\\n\\nResponses from the first round:\\n{shared_responses}\"\n",
    "         N_convergence_loops_loc = N_convergence_loops - 1 # since one used already for silent round\n",
    "         task = task_with_responses # overwrite with messages from silent round\n",
    "\n",
    "    # Create RoundRobinGroupChat with termination condition\n",
    "    team = RoundRobinGroupChat(\n",
    "        agents,\n",
    "        termination_condition=MaxMessageTermination((N_convergence_loops_loc * len(agents)) + 1),  # Terminate when any agent reaches its response limit\n",
    "    )\n",
    "\n",
    "    # Run the chat and print the conversation\n",
    "    result = await Console(team.run_stream(task=task))\n",
    "    logging.info(f\"{result}\")\n",
    "    print(result)\n",
    "\n",
    "    # Extract answers and group by model\n",
    "    for message in result.messages:\n",
    "        if message.source != \"user\":\n",
    "            answer = extract_answer_from_response(message.content)\n",
    "            #model = agent_map[message.source]\n",
    "            #model_answers[model].append(answer)\n",
    "            agent_name = message.source  # This is already the unique agent ID\n",
    "            model_answers[agent_name].append(answer)\n",
    "    \"\"\"\"\n",
    "   # Extract mean and stdev only from the last round of messages\n",
    "    numeric_answers = []\n",
    "    for message in result.messages[-len(agents):]:  # Only consider the last set of messages (one per agent)\n",
    "        if message.source != \"user\":\n",
    "            answer = extract_answer_from_response(message.content)\n",
    "            if answer.isdigit():  # Ensure the answer is numeric\n",
    "                numeric_answers.append(int(answer))\n",
    "\n",
    "   # Calculate mean and standard deviation if there are values\n",
    "    if numeric_answers:\n",
    "        iteration_answer_agentmean = statistics.mean(numeric_answers)\n",
    "        iteration_answer_agentstddev = statistics.stdev(numeric_answers) if len(numeric_answers) > 1 else 0\n",
    "    else:\n",
    "        iteration_answer_agentmean = 0\n",
    "        iteration_answer_agentstddev = 0\n",
    "\n",
    "    agentmean_values.append(iteration_answer_agentmean)\n",
    "    agentstddev_values.append(iteration_answer_agentstddev)\n",
    "    \"\"\"\n",
    "    return model_answers, agent_map, agents\n",
    "\n",
    "\n",
    "\n",
    "async def main():\n",
    "    agentmean_values = [] # need to later rest in each loop- stores aggregated values for all iterations\n",
    "    agentstddev_values = []\n",
    "    figures = [] # storing convergence plots for all iterations\n",
    "    agents = [] # init to fill in roundrobinchat and use in plotting function\n",
    "\n",
    "    for it in range(N_iterations_per_question):\n",
    "        logging.info(f\"\\n\\nDiscussion iteration index for question {question_idx} = {it}\\n\\n\")\n",
    "        print(f\"\\n\\n Discussion iteration index for question {question_idx} = {it} \\n\\n\")\n",
    "       \n",
    "        model_answers, agent_map, agents = await run_round_robin_chat(system_message, model_ensemble, agents=agents, task=task, shuffle=shuffle) # recreates agents every iteration, should not have carryover\n",
    "        logging.info(f\"Final answers by model: {model_answers}\")\n",
    "        print(\"Final answers by model:\", model_answers)\n",
    "        \n",
    "        cleaned_answers = clean_data(model_answers)\n",
    "        #logging.info(f\"Cleaned answers: {cleaned_answers}\")\n",
    "\n",
    "        # Store the answers in the container with the iteration index\n",
    "        #all_model_answers[it] = model_answers\n",
    "        #print(\"‚úÖ agents just before plotting:\", agents)\n",
    "        #print(\"‚úÖ agent_map:\", agent_map)\n",
    "        #print(\"‚úÖ model_answers keys:\", list(model_answers.keys()))\n",
    "\n",
    "        # Collect the figure and axes\n",
    "        fig, ax = plot_polished_answers(cleaned_answers, iteration_index=it, model_ensemble=model_ensemble, agents=agents, agent_map=agent_map)\n",
    "        #fig, ax = plot_polished_answers(cleaned_answers, iteration_index=it, model_ensemble=model_ensemble, agents=agents)\n",
    "        figures.append(fig)\n",
    "    \n",
    "        # Extract the *last* answer from each model's list (skip \"No data\")\n",
    "        final_numeric_answers = []\n",
    "        for answers in model_answers.values():\n",
    "            if answers:\n",
    "                last = answers[-1]\n",
    "                if str(last).isdigit():\n",
    "                    final_numeric_answers.append(int(last))\n",
    "\n",
    "        # Now calculate mean and stddev\n",
    "        if final_numeric_answers:\n",
    "            iteration_answer_agentmean = statistics.mean(final_numeric_answers)\n",
    "            iteration_answer_agentstddev = statistics.stdev(final_numeric_answers) if len(final_numeric_answers) > 1 else 0\n",
    "        else:\n",
    "            iteration_answer_agentmean = 0\n",
    "            iteration_answer_agentstddev = 0\n",
    "\n",
    "        agentmean_values.append(iteration_answer_agentmean)\n",
    "        agentstddev_values.append(iteration_answer_agentstddev)\n",
    "      \n",
    "        #plot_polished_answers(cleaned_answers, iteration_index=it, model_ensemble=model_ensemble)\n",
    "\n",
    "    #==========\n",
    "    # Write averages of final round means and stddev to json file\n",
    "    # data_filepath = os.path.join(data_folder, data_filename)\n",
    "    # Calculate average of the means of all final round/converged (assumed) answer values, over N_iterations, for current question\n",
    "    average_mean = sum(agentmean_values) / len(agentmean_values)\n",
    "    # propagate std dev through sum: 1/n sqrt(sum(stddev)^2)\n",
    "    n = len(agentstddev_values)\n",
    "    sum_of_variances = sum(sd**2 for sd in agentstddev_values)\n",
    "    variance_of_mean = sum_of_variances / (n ** 2)\n",
    "    propagated_uncertainty = math.sqrt(variance_of_mean)\n",
    "\n",
    "    # Store in dictionary\n",
    "    result = {\n",
    "        \"average_mean\": average_mean,\n",
    "        \"propagated_uncertainty\": propagated_uncertainty\n",
    "    }\n",
    "\n",
    "    # write to JSON file\n",
    "    with open(data_filepath, \"w\") as f:\n",
    "        json.dump(result, f, indent=4)\n",
    "\n",
    "    # Print result\n",
    "    print(result)\n",
    "\n",
    "\n",
    "    #==========\n",
    "    # Plotting convergence plots for current question : \n",
    "    \n",
    "    question_title = f\"{next((key for key, values in question_set.items() if question_idx in values), 'Unknown Category')} Question {question_idx}\"\n",
    "\n",
    "    # Convergence: Arrange all convergence plots in a 2x5 grid (or adjust as needed)\n",
    "    # Grid layout\n",
    "    rows, cols = 2, 5\n",
    "    #fig, axes = plt.subplots(rows, cols, figsize=(18, 8), constrained_layout=True)\n",
    "    #fig, axes = plt.subplots(rows, cols, figsize=(20, 10))\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(20, 8), gridspec_kw={'hspace': 0.25}) # make distance narrower between plot rows\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    # Font scale factors\n",
    "    base_font_scale = 2.0\n",
    "    extra_boost = 1.25\n",
    "    font_scale = base_font_scale * extra_boost\n",
    "\n",
    "    for i, fig_i in enumerate(figures):\n",
    "        for ax in fig_i.axes:\n",
    "            # --- Replace title with 'Iteration X' ---\n",
    "            ax.set_title(f\"Iteration {i + 1}\", fontsize=12 * font_scale)\n",
    "\n",
    "            # --- Set x-axis label ---\n",
    "            ax.xaxis.label.set_fontsize(ax.xaxis.label.get_fontsize() * font_scale)\n",
    "\n",
    "            # --- Force line break in y-axis label --- may not be active\n",
    "            original_ylabel = ax.get_ylabel()\n",
    "            if '/' in original_ylabel:\n",
    "                wrapped_ylabel = original_ylabel.replace('/', '\\n')\n",
    "            else:\n",
    "                wrapped_ylabel = original_ylabel\n",
    "\n",
    "            # Clear and set explicitly\n",
    "            ax.set_ylabel('')\n",
    "            ax.set_ylabel(wrapped_ylabel, fontsize=ax.yaxis.label.get_fontsize() * font_scale)\n",
    "\n",
    "            # --- Scale tick labels and reduce x-tick angle ---\n",
    "            for label in ax.get_xticklabels():\n",
    "                label.set_fontsize(label.get_fontsize() * font_scale)\n",
    "                label.set_rotation(30)\n",
    "\n",
    "            for label in ax.get_yticklabels():\n",
    "                label.set_fontsize(label.get_fontsize() * font_scale)\n",
    "\n",
    "            # --- Scale text annotations (e.g., numbers in boxes) ---\n",
    "            for text in ax.texts:\n",
    "                text.set_fontsize(text.get_fontsize() * font_scale)\n",
    "\n",
    "        # Ensure figure is redrawn after label updates\n",
    "        #fig_i.canvas.draw()\n",
    "        #width, height = fig_i.canvas.get_width_height()\n",
    "        #image = np.frombuffer(fig_i.canvas.tostring_rgb(), dtype=np.uint8).reshape(height, width, 3)\n",
    "        #image = np.frombuffer(fig_i.canvas.buffer_rgba(), dtype=np.uint8).reshape(height, width, 4)[..., :3]\n",
    "        from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "        from PIL import Image\n",
    "        import io\n",
    "\n",
    "        canvas = FigureCanvas(fig_i)\n",
    "        buf = io.BytesIO()\n",
    "        fig_i.savefig(buf, format='png', bbox_inches='tight', dpi=150)  # crucial for capturing labels\n",
    "        buf.seek(0)\n",
    "        image = np.array(Image.open(buf))  # Now has everything preserved\n",
    "\n",
    "        # Place in combined plot grid\n",
    "        axes[i].imshow(image)\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    # Turn off unused axes\n",
    "    for j in range(len(figures), rows * cols):\n",
    "        axes[j].axis('off')\n",
    "\n",
    "    # Global title\n",
    "    fig.suptitle(f\"Agent Ensemble Convergence Plots for {question_title}\", fontsize=22, y=0.96) # 1.02 leaves one empty line, 0.9 overlaps with subplot title, 1.0 still almost leaves empty line\n",
    "\n",
    "    #plt.subplots_adjust(top=0.9, bottom=0.15) # avoid xaxis labels cut off\n",
    "    #plt.subplots_adjust(top=0.9, bottom=0.2) # avoid xaxis labels cut off\n",
    "    plt.subplots_adjust(top=0.92, bottom=0.1, left=0.08, right=0.92)  # Increase left and top margins\n",
    "    #plt.tight_layout(rect=[0.05, 0.05, 1, 0.95])  # Give more room at the left and bottom to prevent clipping of x labels\n",
    "    #plt.tight_layout(rect=[0.05, 0.05, 1, 0.95], pad=2.0) # padding to avoid xaxis labels cut off\n",
    "    plot_convfilename = f'convergenceplots_{plot_filename}'\n",
    "    plot_convfilepath = os.path.join(plot_folder, plot_convfilename)\n",
    "    fig.savefig(f'{plot_convfilepath}', dpi=300)\n",
    "    print(f\"plot saved to {plot_folder}convergenceplots_{plot_filename}\")\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "# open item to compare the different exp setups, need to then calculate std dev of mean values over iterations\n",
    "\n",
    "# Execution\n",
    "N_iterations_per_question = 10  # default 10 for enough statistics to understand variability of each question\n",
    "N_convergence_loops = 3  # default 3, for one iteration for one question\n",
    "\n",
    "group_chat = True # always for roundrobin\n",
    "# to do: implement looping on reasoning and secret, then invert questions and implement invert\n",
    "\n",
    "sys.exit() # circuit breaker\n",
    "\n",
    "question_set = {\n",
    "    #\"IH questions\": [1], # debug\n",
    "    \"IH questions\": [1, 2, 3, 4],\n",
    "    \"IB questions\": [5, 6, 7, 8, 9]\n",
    "}\n",
    "\n",
    "# set up logging and plot paths\n",
    "# Create a 'log' folder and plot if it doesn't exist\n",
    "log_folder = os.path.abspath(\"./logs/\")\n",
    "plot_folder = os.path.abspath(\"./plots/\")\n",
    "data_folder = os.path.abspath(\"./data/\")\n",
    "os.makedirs(log_folder, exist_ok=True)\n",
    "os.makedirs(plot_folder, exist_ok=True)\n",
    "# data folder already exists\n",
    "\n",
    "reasoning = True\n",
    "secret = False\n",
    "inverted = False # not ready yet- need to write inverted questions for ous manually; does not impact system_message/prompt, only different task including answer scale and question\n",
    "#secret = True\n",
    "#reasoning = True\n",
    "\n",
    "import itertools\n",
    "\n",
    "# Define the two binary flags\n",
    "flag_values = [True, False]\n",
    "\n",
    "shuffle = False  # for now keep false to maintain order\n",
    "homogeneity = False\n",
    "\n",
    "\"\"\" # rationale and secret version:\n",
    "    model_ensemble = [\n",
    "            {\"model\": models[0], \"number\": 1},  # here only one model per model flavor\n",
    "            {\"model\": models[1], \"number\": 1},\n",
    "            {\"model\": models[2], \"number\": 1}, \n",
    "            {\"model\": models[3], \"number\": 1}, \n",
    "            {\"model\": models[4], \"number\": 1},\n",
    "        ]\n",
    "\"\"\"\n",
    "\n",
    "# Loop over all combinations of reasoning and secret\n",
    "#for reasoning, secret in itertools.product(flag_values, repeat=2):\n",
    "for shuffle, homogeneity in itertools.product(flag_values, repeat=2):\n",
    "\n",
    "    print(f\"homogeneity: {homogeneity}, shuffle: {shuffle}, secret: {secret}\")\n",
    "\n",
    "    N_iterations = 0\n",
    "    model_ensemble = [] # init empty\n",
    "\n",
    "    if homogeneity == True and shuffle == True:\n",
    "        continue # no need to shuffle homogeneous ensemble\n",
    "    if homogeneity == False: # for both shuffle values, True covered later in shuffle once ensemble defined- shuffle for every iteration without studying specific order, just wash out\n",
    "        for idx in range(5):\n",
    "            model_ensemble.append( {\"model\": models[idx], \"number\": 1}) # here only one model per model flavor\n",
    "        N_iterations = 1 # only run once per shuffle value\n",
    "    if homogeneity == True and shuffle == False:\n",
    "        N_iterations = 5 # default 5, in each iteration define new homogeneous ensemble\n",
    "\n",
    "    # geneity and shuffle execution loop    \n",
    "    for it_idx in range(N_iterations):\n",
    "\n",
    "        if homogeneity == True and shuffle == False:\n",
    "            model_ensemble = [] # reset\n",
    "            model_ensemble.append( {\"model\": models[it_idx], \"number\": 5}) # homogeneous\n",
    "\n",
    "        print(f\"model_ensemble: {model_ensemble}\")\n",
    "                    \n",
    "        system_message = get_prompt() # use default values in helpers get_prompt \n",
    "\n",
    "        for question_idx in sum(question_set.values(), []):    \n",
    "            # debug\n",
    "\n",
    "            # Generate a logfile name based on the variable values\n",
    "            filename = f\"question_{question_idx}_homogeneity_{homogeneity}_modeltypeidx_{it_idx}_shuffle_{shuffle}_reasoning_{reasoning}_inverted_{inverted}_secret_{secret}\"\n",
    "            print(f\"Filename: {filename}\")\n",
    "            log_filename = f\"{filename}.log\"\n",
    "            log_filepath = os.path.join(log_folder, log_filename)\n",
    "            plot_filename = f\"{filename}.png\"\n",
    "            plot_filepath = os.path.join(plot_folder, plot_filename)\n",
    "            data_filename = f\"{filename}.csv\"\n",
    "            data_filepath = os.path.join(data_folder, data_filename)\n",
    "\n",
    "            print(f\"{Qs.print_question(str(question_idx), printout=False)}\")\n",
    "            \n",
    "            # Configure logging\n",
    "            logging.basicConfig(\n",
    "                filename=log_filepath,\n",
    "                level=logging.INFO,\n",
    "                format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "            )\n",
    "            logging.info(f\"Starting run for question={question_idx} with homogeneity={homogeneity}, shuffle={shuffle}, reasoning={reasoning}, inverted={inverted}, secret={secret}\")\n",
    "            logging.info(f\"Logfile: {log_filepath}\")\n",
    "\n",
    "            #=========\n",
    "            # execution\n",
    "\n",
    "            task = \"\" # updated task creation not including Likert scale instructions\n",
    "            if inverted == False:\n",
    "                task = Qs.print_question(str(question_idx), printout=False)\n",
    "            else: \n",
    "                task = InvertQs.print_question(str(question_idx) + 100, printout=False)\n",
    "\n",
    "\n",
    "            agentmean_values = [] # stores aggregated values for all iterations\n",
    "            agentstddev_values = []\n",
    "\n",
    "            await main()\n",
    "\n",
    "\n",
    "            # Remove all handlers associated with the root logger to not have open files\n",
    "            for handler in logging.root.handlers[:]:\n",
    "                logging.root.removeHandler(handler)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.4 Load Data for Post-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------\n",
    "# Load base case switch data for each question and human data\n",
    "\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "# === Load Human Likert Data ===\n",
    "human_data = pd.read_csv(\"./human_data/ous_filtered.csv\")  # Replace with your actual file path\n",
    "\n",
    "ih_columns = ['IH1', 'IH2', 'IH3', 'IH4']\n",
    "ib_columns = ['IB1', 'IB2', 'IB3', 'IB4', 'IB5']\n",
    "question_columns = ih_columns + ib_columns\n",
    "human_means = human_data[question_columns].mean()\n",
    "human_stds = human_data[question_columns].std()\n",
    "human_sems = human_stds / np.sqrt(len(human_data))\n",
    "human_x = np.arange(1, len(question_columns) + 1)\n",
    "\n",
    "# === Load JSON Flag Data ===\n",
    "data_folder = \"./data\"\n",
    "filename_pattern = re.compile(\n",
    "    r\"question_(\\d+)_reasoning_(True|False)_inverted_(True|False)_secret_(True|False)\\.csv\"\n",
    ")\n",
    "\n",
    "grouped_data = defaultdict(list)\n",
    "for filename in os.listdir(data_folder):\n",
    "    match = filename_pattern.match(filename)\n",
    "    if match:\n",
    "        question_idx = int(match.group(1))\n",
    "        reasoning = match.group(2) == \"True\"\n",
    "        secret = match.group(4) == \"True\"\n",
    "        filepath = os.path.join(data_folder, filename)\n",
    "        with open(filepath, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "            avg = data.get(\"average_mean\")\n",
    "            sem = data.get(\"propagated_uncertainty\")\n",
    "            grouped_data[(reasoning, secret)].append((question_idx, avg, sem))\n",
    "\n",
    "# === Define Color Map ===\n",
    "color_map = {\n",
    "    (True, True): \"tab:blue\",\n",
    "    (True, False): \"tab:green\",\n",
    "    (False, True): \"tab:red\",\n",
    "    (False, False): \"tab:orange\",\n",
    "}\n",
    "\n",
    "# === Plot ===\n",
    "fig = plt.figure(figsize=(12, 6))  # Capture figure object\n",
    "\n",
    "# Human data with SD shading and SEM error bars\n",
    "human_offset = -0.2  # shift left\n",
    "plt.fill_between(human_x + human_offset, human_means - human_stds, human_means + human_stds,\n",
    "                 color='lightgray', label='Human ¬± SD')\n",
    "plt.errorbar(human_x + human_offset, human_means, yerr=human_sems, fmt='o', color='black',\n",
    "             capsize=4, label='Human ¬± SEM')\n",
    "\n",
    "# JSON data with offsets to avoid overlap\n",
    "offsets = {\n",
    "    (True, True): -0.1,\n",
    "    (True, False): 0.0,\n",
    "    (False, True): 0.1,\n",
    "    (False, False): 0.2,\n",
    "}\n",
    "\n",
    "for (reasoning, secret), data_points in grouped_data.items():\n",
    "    data_points.sort()\n",
    "    x_vals = np.array([dp[0] for dp in data_points])\n",
    "    y_vals = np.array([dp[1] for dp in data_points])\n",
    "    sems = np.array([dp[2] for dp in data_points])\n",
    "    stds = sems * np.sqrt(10)  # N = 10\n",
    "\n",
    "    offset = offsets[(reasoning, secret)]\n",
    "    x_offset = x_vals + offset\n",
    "\n",
    "    plt.fill_between(x_offset, y_vals - stds, y_vals + stds,\n",
    "                     color=color_map[(reasoning, secret)], alpha=0.2)\n",
    "    plt.errorbar(x_offset, y_vals, yerr=sems, fmt='o', color=color_map[(reasoning, secret)],\n",
    "                 capsize=4, label=f\"reasoning={reasoning}, secret={secret}\")\n",
    "\n",
    "# === Final plot settings ===\n",
    "plt.xticks(human_x, question_columns)\n",
    "for tick in plt.gca().get_xticklabels():\n",
    "    if \"IH\" in tick.get_text():\n",
    "        tick.set_color(\"blue\")\n",
    "    else:\n",
    "        tick.set_color(\"red\")\n",
    "\n",
    "plt.axvline(x=4.5, linestyle='--', color='gray', alpha=0.6)\n",
    "plt.xlabel(\"Question\")\n",
    "plt.ylabel(\"Mean Response\")\n",
    "plt.title(\"Human vs Model Mean Responses with SD and SEM (Offset for Clarity)\")\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "\n",
    "# === Save and show ===\n",
    "output_dir = \"./plots\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "fig.savefig(os.path.join(output_dir, \"likert_response_comparison.png\"), dpi=300)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.4.2 geneity and shuffle plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# === Load Human Likert Data ===\n",
    "human_data = pd.read_csv(\"./human_data/ous_filtered.csv\")  # Update path if needed\n",
    "\n",
    "ih_columns = ['IH1', 'IH2', 'IH3', 'IH4']\n",
    "ib_columns = ['IB1', 'IB2', 'IB3', 'IB4', 'IB5']\n",
    "question_columns = ih_columns + ib_columns\n",
    "human_means = human_data[question_columns].mean()\n",
    "human_stds = human_data[question_columns].std()\n",
    "human_sems = human_stds / np.sqrt(len(human_data))\n",
    "human_x = np.arange(1, len(question_columns) + 1)\n",
    "\n",
    "# === Load Model Likert Data ===\n",
    "data_folder = \"./data\"\n",
    "filename_pattern = re.compile(\n",
    "    r\"question_(\\d+)_homogeneity_(True|False)_modeltypeidx_(\\d+)_shuffle_(True|False)_reasoning_True_inverted_False_secret_False\\.csv\"\n",
    ")\n",
    "\n",
    "# Group data by condition\n",
    "grouped_data = defaultdict(list)\n",
    "\n",
    "for filename in os.listdir(data_folder):\n",
    "    match = filename_pattern.match(filename)\n",
    "    if match:\n",
    "        question_idx = int(match.group(1))\n",
    "        homogeneity = match.group(2) == \"True\"\n",
    "        modeltypeidx = int(match.group(3))\n",
    "        shuffle = match.group(4) == \"True\"\n",
    "\n",
    "        filepath = os.path.join(data_folder, filename)\n",
    "        with open(filepath, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "            avg = data.get(\"average_mean\")\n",
    "            sem = data.get(\"propagated_uncertainty\")\n",
    "\n",
    "        key = (homogeneity, shuffle, modeltypeidx)\n",
    "        grouped_data[key].append((question_idx, avg, sem))\n",
    "\n",
    "# === Setup Plot ===\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "# Human data\n",
    "human_offset = -0.2\n",
    "ax.fill_between(human_x + human_offset, human_means - human_stds, human_means + human_stds,\n",
    "                color='lightgray', label='Human ¬± SD')\n",
    "ax.errorbar(human_x + human_offset, human_means, yerr=human_sems, fmt='o', color='black',\n",
    "            capsize=4, label='Human ¬± SEM')\n",
    "\n",
    "# === Define Plot Styles ===\n",
    "model_colors = {\n",
    "    0: '#e41a1c',  # Red\n",
    "    1: '#377eb8',  # Blue\n",
    "    2: '#4daf4a',  # Green\n",
    "    3: '#984ea3',  # Purple\n",
    "    4: '#ff7f00',  # Orange\n",
    "}\n",
    "\n",
    "hetero_colors = {\n",
    "    False: '#4b4b4b',  # shuffle = False ‚Üí Dark gray\n",
    "    True: '#1b9e77',   # shuffle = True ‚Üí Teal green\n",
    "}\n",
    "\n",
    "offsets = {\n",
    "    (False, False): 0.1,\n",
    "    (False, True): 0.2,\n",
    "    0: -0.1,\n",
    "    1: -0.05,\n",
    "    2: 0.0,\n",
    "    3: 0.05,\n",
    "    4: 0.1,\n",
    "}\n",
    "\n",
    "# === Plot Heterogeneous Curves (shuffle True/False) ===\n",
    "for shuffle_val in [False, True]:\n",
    "    key = (False, shuffle_val, 0)\n",
    "    datapoints = grouped_data.get(key, [])\n",
    "    if not datapoints:\n",
    "        continue\n",
    "\n",
    "    datapoints.sort()\n",
    "    x_vals = np.array([dp[0] for dp in datapoints])\n",
    "    y_vals = np.array([dp[1] for dp in datapoints])\n",
    "    sems = np.array([dp[2] for dp in datapoints])\n",
    "    stds = sems * np.sqrt(10)\n",
    "\n",
    "    x_offset = x_vals + offsets[(False, shuffle_val)]\n",
    "    color = hetero_colors[shuffle_val]\n",
    "    label = f\"Hetero / Shuffle={shuffle_val}\"\n",
    "\n",
    "    ax.fill_between(x_offset, y_vals - stds, y_vals + stds, alpha=0.2, color=color)\n",
    "    ax.errorbar(x_offset, y_vals, yerr=sems, fmt='o', capsize=4,\n",
    "                color=color, markersize=6, markerfacecolor=color, label=label)\n",
    "\n",
    "# === Plot Homogeneous Curves (5 modeltypeidx) ===\n",
    "for modeltypeidx in range(5):\n",
    "    key = (True, False, modeltypeidx)\n",
    "    datapoints = grouped_data.get(key, [])\n",
    "    if not datapoints:\n",
    "        continue\n",
    "\n",
    "    datapoints.sort()\n",
    "    x_vals = np.array([dp[0] for dp in datapoints])\n",
    "    y_vals = np.array([dp[1] for dp in datapoints])\n",
    "    sems = np.array([dp[2] for dp in datapoints])\n",
    "    stds = sems * np.sqrt(10)\n",
    "\n",
    "    color = model_colors[modeltypeidx]\n",
    "    marker = 'D'\n",
    "    x_offset = x_vals + offsets[modeltypeidx]\n",
    "\n",
    "    label = f\"Model {modeltypeidx} (Homog.)\"\n",
    "    ax.fill_between(x_offset, y_vals - stds, y_vals + stds, alpha=0.2, color=color)\n",
    "    ax.errorbar(x_offset, y_vals, yerr=sems, fmt=marker, capsize=4,\n",
    "                color=color, markersize=6, markerfacecolor='none', label=label)\n",
    "\n",
    "# === Finalize Plot ===\n",
    "ax.set_xticks(human_x)\n",
    "ax.set_xticklabels(question_columns, rotation=30)\n",
    "for tick in ax.get_xticklabels():\n",
    "    tick.set_color(\"blue\" if \"IH\" in tick.get_text() else \"red\")\n",
    "\n",
    "ax.axvline(x=4.5, linestyle='--', color='gray', alpha=0.6)\n",
    "ax.set_xlabel(\"Question\")\n",
    "ax.set_ylabel(\"Mean Response\")\n",
    "ax.set_title(\"Human vs Model Responses\\n(Heterogeneous vs Homogeneous Ensembles)\")\n",
    "ax.grid(True, linestyle='--', alpha=0.6)\n",
    "ax.legend(loc=\"lower right\", fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# === Save Plot ===\n",
    "output_dir = \"./plots\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "fig.savefig(os.path.join(output_dir, \"geneity_shuffle_singlequestioncomparison_ous.png\"), dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.5 Plot per single question plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "use_std = True\n",
    "\n",
    "# Shift question numbers by +1 for plotting (do NOT modify original DataFrame)\n",
    "question_nums = sorted(single_by_question['question_num'].unique())\n",
    "question_nums_plot = [q + 1 for q in question_nums]  # Shifted for display\n",
    "flag_combos = sorted(single_by_question['flag_combo'].unique())\n",
    "num_combos = len(flag_combos)\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "width = 0.25\n",
    "combo_colors = plt.cm.tab10(np.linspace(0, 1, num_combos))\n",
    "positions = {}\n",
    "\n",
    "for i, combo in enumerate(flag_combos):\n",
    "    offset = (i - (num_combos - 1) / 2) * width\n",
    "    positions[combo] = [q + offset for q in question_nums_plot]\n",
    "\n",
    "    combo_data = single_by_question[single_by_question['flag_combo'] == combo]\n",
    "\n",
    "    for idx, q_num in enumerate(question_nums):\n",
    "        q_data = combo_data[combo_data['question_num'] == q_num]\n",
    "\n",
    "        if not q_data.empty:\n",
    "            mean_val = q_data['mean'].values[0]\n",
    "            error_val = q_data['std'].values[0] if use_std else q_data['sem'].values[0]\n",
    "\n",
    "            plt.errorbar(\n",
    "                positions[combo][idx],\n",
    "                mean_val,\n",
    "                yerr=error_val,\n",
    "                fmt='o',\n",
    "                color=combo_colors[i],\n",
    "                label=combo if idx == 0 else \"\",\n",
    "                capsize=3\n",
    "            )\n",
    "\n",
    "# Update x-axis to show question numbers starting from 1\n",
    "plt.xticks(question_nums_plot, labels=[str(q) for q in question_nums_plot], rotation=90)\n",
    "\n",
    "# Color tick labels based on category\n",
    "ax = plt.gca()\n",
    "for tick in ax.get_xticklabels():\n",
    "    question = int(tick.get_text())\n",
    "    if question <= 4:  # Questions 1‚Äì4 are IH\n",
    "        tick.set_color('blue')\n",
    "    else:  # 5‚Äì9 are IB\n",
    "        tick.set_color('red')\n",
    "\n",
    "# Vertical line between IH and IB (after Q4, now at x=4.5)\n",
    "plt.axvline(x=4.5, color='black', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Y-axis annotation position\n",
    "y_min, y_max = plt.ylim()\n",
    "y_text = y_max * 0.95\n",
    "\n",
    "plt.text(2.0, y_text, 'IH Category', color='blue', ha='center', fontsize=12)\n",
    "plt.text(7.0, y_text, 'IB Category', color='red', ha='center', fontsize=12)\n",
    "\n",
    "plt.xlabel('Question Number')\n",
    "plt.ylabel('Mean Value')\n",
    "plt.title('Mean Values by Question Number and Flag Combination')\n",
    "plt.legend(title=\"Flag Settings\")\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.6 Plot 2d IH IB data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "# === Load Human Likert Data ===\n",
    "human_data = pd.read_csv(\"./human_data/ous_filtered.csv\")\n",
    "\n",
    "ih_columns = ['IH1', 'IH2', 'IH3', 'IH4']\n",
    "ib_columns = ['IB1', 'IB2', 'IB3', 'IB4', 'IB5']\n",
    "\n",
    "# Compute human stats\n",
    "human_ih_means = human_data[ih_columns].mean(axis=1)\n",
    "human_ib_means = human_data[ib_columns].mean(axis=1)\n",
    "\n",
    "human_ih_avg = human_ih_means.mean()\n",
    "human_ib_avg = human_ib_means.mean()\n",
    "\n",
    "human_ih_std = human_ih_means.std()\n",
    "human_ib_std = human_ib_means.std()\n",
    "\n",
    "n_human = len(human_data)\n",
    "human_ih_sem = human_ih_std / np.sqrt(n_human)\n",
    "human_ib_sem = human_ib_std / np.sqrt(n_human)\n",
    "\n",
    "# === Load JSON Flag Data ===\n",
    "data_folder = \"./data\"\n",
    "filename_pattern = re.compile(\n",
    "    r\"question_(\\d+)_reasoning_(True|False)_inverted_(True|False)_secret_(True|False)\\.csv\"\n",
    ")\n",
    "\n",
    "grouped_data = defaultdict(list)\n",
    "for filename in os.listdir(data_folder):\n",
    "    match = filename_pattern.match(filename)\n",
    "    if match:\n",
    "        question_idx = int(match.group(1))\n",
    "        reasoning = match.group(2) == \"True\"\n",
    "        secret = match.group(4) == \"True\"\n",
    "        filepath = os.path.join(data_folder, filename)\n",
    "        with open(filepath, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "            avg = data.get(\"average_mean\")\n",
    "            sem = data.get(\"propagated_uncertainty\")\n",
    "            grouped_data[(reasoning, secret)].append((question_idx, avg, sem))\n",
    "\n",
    "# === Compute Flag Combo IH/IB Averages, SEM, STD ===\n",
    "flag_stats = {}\n",
    "N_flag = 10  # as assumed in prior calculations\n",
    "\n",
    "for flag_key, datapoints in grouped_data.items():\n",
    "    datapoints.sort()\n",
    "    ih_vals = [avg for idx, avg, _ in datapoints if idx in range(1, 5)]\n",
    "    ib_vals = [avg for idx, avg, _ in datapoints if idx in range(5, 10)]\n",
    "    ih_sems = [sem for idx, _, sem in datapoints if idx in range(1, 5)]\n",
    "    ib_sems = [sem for idx, _, sem in datapoints if idx in range(5, 10)]\n",
    "\n",
    "    ih_mean = np.mean(ih_vals)\n",
    "    ib_mean = np.mean(ib_vals)\n",
    "\n",
    "    ih_std = np.sqrt(np.sum(np.square(np.array(ih_sems) * np.sqrt(N_flag))) / len(ih_sems))\n",
    "    ib_std = np.sqrt(np.sum(np.square(np.array(ib_sems) * np.sqrt(N_flag))) / len(ib_sems))\n",
    "\n",
    "    ih_sem = ih_std / np.sqrt(len(ih_sems))\n",
    "    ib_sem = ib_std / np.sqrt(len(ib_sems))\n",
    "    print(f\"flag_key: {flag_key}, ih_mean: {ih_mean}, ib_mean: {ib_mean}, ih_std: {ih_std}, ib_std: {ib_std}, ih_sem: {ih_sem}, ib_sem: {ib_sem}\")\n",
    "    flag_stats[flag_key] = {\n",
    "        'ih_mean': ih_mean,\n",
    "        'ib_mean': ib_mean,\n",
    "        'ih_std': ih_std,\n",
    "        'ib_std': ib_std,\n",
    "        'ih_sem': ih_sem,\n",
    "        'ib_sem': ib_sem,\n",
    "    }\n",
    "\n",
    "# === Plot 2D Mean IH vs IB with SEM and SD Ellipses ===\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# === Plot 2D Mean IH vs IB with SEM and SD Ellipses ===\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# Plot Human Data\n",
    "ax.errorbar(human_ih_avg, human_ib_avg,\n",
    "            xerr=human_ih_sem, yerr=human_ib_sem,\n",
    "            fmt='o', color='black', capsize=5, label='Human ¬± SEM')\n",
    "\n",
    "ellipse = patches.Ellipse((human_ih_avg, human_ib_avg),\n",
    "                          width=2*human_ih_std, height=2*human_ib_std,\n",
    "                          color='gray', alpha=0.2, label='Human ¬± SD')\n",
    "ax.add_patch(ellipse)\n",
    "\n",
    "# Plot Flag Combo Data\n",
    "for (reasoning, secret), stats in flag_stats.items():\n",
    "    ih_mean = stats['ih_mean']\n",
    "    ib_mean = stats['ib_mean']\n",
    "    ih_std = stats['ih_std']\n",
    "    ib_std = stats['ib_std']\n",
    "    ih_sem = stats['ih_sem']\n",
    "    ib_sem = stats['ib_sem']\n",
    "\n",
    "    color = color_map[(reasoning, secret)]\n",
    "    label = f\"reasoning={reasoning}, secret={secret}\"\n",
    "\n",
    "    ax.errorbar(ih_mean, ib_mean,\n",
    "                xerr=ih_sem, yerr=ib_sem,\n",
    "                fmt='o', color=color, capsize=5, label=f\"{label} ¬± SEM\")\n",
    "\n",
    "    ellipse = patches.Ellipse((ih_mean, ib_mean),\n",
    "                              width=2*ih_std, height=2*ib_std,\n",
    "                              color=color, alpha=0.2)\n",
    "    ax.add_patch(ellipse)\n",
    "\n",
    "# Plot settings\n",
    "ax.set_xlabel(\"Average IH Response\")\n",
    "ax.set_ylabel(\"Average IB Response\")\n",
    "ax.set_title(\"Mean IH vs IB (Human vs Flag Combos) with SEM and SD\")\n",
    "ax.grid(True, linestyle='--', alpha=0.6)\n",
    "ax.legend()\n",
    "ax.set_aspect('equal', 'box')\n",
    "ax.set_xlim(1, 7)\n",
    "ax.set_ylim(1, 7)\n",
    "\n",
    "# Save plot\n",
    "output_dir = \"./plots\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, \"ih_vs_ib_mean_scatter.png\"), dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.6.1 geneity and shuffle outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Load Human Likert Data\n",
    "human_data = pd.read_csv(\"./human_data/ous_filtered.csv\")\n",
    "ih_columns = ['IH1', 'IH2', 'IH3', 'IH4']\n",
    "ib_columns = ['IB1', 'IB2', 'IB3', 'IB4', 'IB5']\n",
    "\n",
    "# Compute human stats\n",
    "human_ih_means = human_data[ih_columns].mean(axis=1)\n",
    "human_ib_means = human_data[ib_columns].mean(axis=1)\n",
    "human_ih_avg = human_ih_means.mean()\n",
    "human_ib_avg = human_ib_means.mean()\n",
    "human_ih_std = human_ih_means.std()\n",
    "human_ib_std = human_ib_means.std()\n",
    "n_human = len(human_data)\n",
    "human_ih_sem = human_ih_std / np.sqrt(n_human)\n",
    "human_ib_sem = human_ib_std / np.sqrt(n_human)\n",
    "\n",
    "# Updated pattern: includes modeltypeidx, homogeneity, shuffle\n",
    "data_folder = \"./data\"\n",
    "filename_pattern = re.compile(\n",
    "    r\"question_(\\d+)_homogeneity_(True|False)_modeltypeidx_(\\d+)_shuffle_(True|False)_reasoning_.*?_inverted_.*?_secret_.*?\\.csv\"\n",
    ")\n",
    "\n",
    "grouped_data = defaultdict(list)\n",
    "for filename in os.listdir(data_folder):\n",
    "    match = filename_pattern.match(filename)\n",
    "    if match:\n",
    "        question_idx = int(match.group(1))\n",
    "        homogeneity = match.group(2) == \"True\"\n",
    "        modeltypeidx = int(match.group(3))\n",
    "        shuffle = match.group(4) == \"True\"\n",
    "        filepath = os.path.join(data_folder, filename)\n",
    "        with open(filepath, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "            avg = data.get(\"average_mean\")\n",
    "            sem = data.get(\"propagated_uncertainty\")\n",
    "            key = (homogeneity, shuffle, modeltypeidx if homogeneity else None)\n",
    "            grouped_data[key].append((question_idx, avg, sem))\n",
    "\n",
    "# Compute group statistics\n",
    "flag_stats = {}\n",
    "N_flag = 10\n",
    "for flag_key, datapoints in grouped_data.items():\n",
    "    datapoints.sort()\n",
    "    ih_vals = [avg for idx, avg, _ in datapoints if idx in range(1, 5)]\n",
    "    ib_vals = [avg for idx, avg, _ in datapoints if idx in range(5, 10)]\n",
    "    ih_sems = [sem for idx, _, sem in datapoints if idx in range(1, 5)]\n",
    "    ib_sems = [sem for idx, _, sem in datapoints if idx in range(5, 10)]\n",
    "\n",
    "    ih_mean = np.mean(ih_vals)\n",
    "    ib_mean = np.mean(ib_vals)\n",
    "    ih_std = np.sqrt(np.sum(np.square(np.array(ih_sems) * np.sqrt(N_flag))) / len(ih_sems))\n",
    "    ib_std = np.sqrt(np.sum(np.square(np.array(ib_sems) * np.sqrt(N_flag))) / len(ib_sems))\n",
    "    ih_sem = ih_std / np.sqrt(len(ih_sems))\n",
    "    ib_sem = ib_std / np.sqrt(len(ib_sems))\n",
    "\n",
    "    flag_stats[flag_key] = {\n",
    "        'ih_mean': ih_mean,\n",
    "        'ib_mean': ib_mean,\n",
    "        'ih_std': ih_std,\n",
    "        'ib_std': ib_std,\n",
    "        'ih_sem': ih_sem,\n",
    "        'ib_sem': ib_sem,\n",
    "    }\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# Human\n",
    "ax.errorbar(human_ih_avg, human_ib_avg, xerr=human_ih_sem, yerr=human_ib_sem,\n",
    "            fmt='o', color='black', capsize=5, label='Human ¬± SEM')\n",
    "ellipse = patches.Ellipse((human_ih_avg, human_ib_avg), width=2*human_ih_std, height=2*human_ib_std,\n",
    "                          color='gray', alpha=0.2, label='Human ¬± SD')\n",
    "ax.add_patch(ellipse)\n",
    "\n",
    "# Color and marker map\n",
    "modeltype_colors = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple']\n",
    "marker_homo = 'D'  # diamonds\n",
    "marker_hetero = 'o'  # full circles\n",
    "\n",
    "# Plot model results\n",
    "for (homogeneity, shuffle, modeltypeidx), stats in flag_stats.items():\n",
    "    ih_mean = stats['ih_mean']\n",
    "    ib_mean = stats['ib_mean']\n",
    "    ih_std = stats['ih_std']\n",
    "    ib_std = stats['ib_std']\n",
    "    ih_sem = stats['ih_sem']\n",
    "    ib_sem = stats['ib_sem']\n",
    "\n",
    "    if homogeneity:\n",
    "        color = modeltype_colors[modeltypeidx]\n",
    "        label = f\"Homogeneous (model {modeltypeidx})\"\n",
    "        marker = marker_homo\n",
    "    else:\n",
    "        label = f\"Heterogeneous ({'Shuffled' if shuffle else 'Not Shuffled'})\"\n",
    "        color = 'tab:brown' if shuffle else 'tab:cyan'\n",
    "        marker = marker_hetero\n",
    "\n",
    "    ax.errorbar(ih_mean, ib_mean, xerr=ih_sem, yerr=ib_sem,\n",
    "                fmt=marker, color=color, capsize=5, label=label)\n",
    "    ellipse = patches.Ellipse((ih_mean, ib_mean), width=2*ih_std, height=2*ib_std,\n",
    "                              color=color, alpha=0.2)\n",
    "    ax.add_patch(ellipse)\n",
    "\n",
    "# Final plot settings\n",
    "ax.set_xlabel(\"Average IH Response\")\n",
    "ax.set_ylabel(\"Average IB Response\")\n",
    "ax.set_title(\"Mean IH vs IB (Human vs Model) with SEM and SD\")\n",
    "ax.grid(True, linestyle='--', alpha=0.6)\n",
    "ax.legend(loc='lower right', fontsize=8)\n",
    "ax.set_aspect('equal', 'box')\n",
    "ax.set_xlim(1, 7)\n",
    "ax.set_ylim(1, 7)\n",
    "\n",
    "# Save plot\n",
    "output_dir = \"./plots\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, \"geneity_shuffle_ih_vs_ib_mean_scatter.png\"), dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.7 Plot IH, IB-only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 1D Plot: IB Mean Responses Only (Compact Layout) ===\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "\n",
    "# Define datasets in compact format\n",
    "datasets = [(\"Human\", \"black\", human_ib_avg, human_ib_std, human_ib_sem)] + [\n",
    "    (f\"reasoning={reasoning}, secret={secret}\",\n",
    "     color_map[(reasoning, secret)],\n",
    "     stats['ib_mean'],\n",
    "     stats['ib_std'],\n",
    "     stats['ib_sem'])\n",
    "    for (reasoning, secret), stats in flag_stats.items()\n",
    "]\n",
    "bar_width = 0.95\n",
    "x_positions = np.arange(len(datasets))\n",
    "\n",
    "# Plot each dataset\n",
    "for i, (label, color, ib_mean, ib_std, ib_sem) in enumerate(datasets):\n",
    "    ax.errorbar(x_positions[i], ib_mean, yerr=ib_sem, fmt='o', color=color, capsize=5, label=f\"{label} ¬± SEM\")\n",
    "    ax.fill_between([x_positions[i] - bar_width / 2, x_positions[i] + bar_width / 2],\n",
    "                    [ib_mean - ib_std] * 2,\n",
    "                    [ib_mean + ib_std] * 2,\n",
    "                    color=color if label != \"Human\" else \"gray\", alpha=0.2)\n",
    "\n",
    "# Aesthetics\n",
    "ax.set_xticks(x_positions)\n",
    "ax.set_xticklabels([label for label, _, _, _, _ in datasets], rotation=10, ha='right')\n",
    "ax.set_xlim(-0.5, len(datasets) - 0.5)\n",
    "ax.set_ylim(1, 7)\n",
    "ax.set_ylabel(\"Average IB OUS Response\")\n",
    "ax.set_title(\"Averaged IB OUS Responses (¬±SD, ¬±SEM)\")\n",
    "ax.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save plot\n",
    "output_dir = \"./plots\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "plt.savefig(os.path.join(output_dir, \"ib_mean_1d_plot_compact.png\"), dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === 1D Plot: IH Mean Responses Only (Compact Layout) ===\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "\n",
    "# Define datasets in compact format\n",
    "datasets = [(\"Human\", \"black\", human_ih_avg, human_ih_std, human_ih_sem)] + [\n",
    "    (f\"reasoning={reasoning}, secret={secret}\",\n",
    "     color_map[(reasoning, secret)],\n",
    "     stats['ih_mean'],\n",
    "     stats['ih_std'],\n",
    "     stats['ih_sem'])\n",
    "    for (reasoning, secret), stats in flag_stats.items()\n",
    "]\n",
    "\n",
    "bar_width = 0.95\n",
    "x_positions = np.arange(len(datasets))\n",
    "\n",
    "# Plot each dataset\n",
    "for i, (label, color, ih_mean, ih_std, ih_sem) in enumerate(datasets):\n",
    "    ax.errorbar(x_positions[i], ih_mean, yerr=ih_sem, fmt='o', color=color, capsize=5, label=f\"{label} ¬± SEM\")\n",
    "    ax.fill_between([x_positions[i] - bar_width / 2, x_positions[i] + bar_width / 2],\n",
    "                    [ih_mean - ih_std] * 2,\n",
    "                    [ih_mean + ih_std] * 2,\n",
    "                    color=color if label != \"Human\" else \"gray\", alpha=0.2)\n",
    "\n",
    "# Aesthetics\n",
    "ax.set_xticks(x_positions)\n",
    "ax.set_xticklabels([label for label, _, _, _, _ in datasets], rotation=10, ha='right')\n",
    "ax.set_xlim(-0.5, len(datasets) - 0.5)\n",
    "ax.set_ylim(1, 7)\n",
    "ax.set_ylabel(\"Average IH OUS Response\")\n",
    "ax.set_title(\"Averaged IH OUS Responses (¬±SD, ¬±SEM)\")\n",
    "ax.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save plot\n",
    "output_dir = \"./plots\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "plt.savefig(os.path.join(output_dir, \"ih_mean_1d_plot_compact.png\"), dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Print IH stats for reasoning=True, secret=False\n",
    "for (reasoning, secret), stats in flag_stats.items():\n",
    "    print(f\"Reasoning={reasoning}, Secret={secret}\")\n",
    "    print(f\"  Mean:     {stats['ih_mean']}\")\n",
    "    print(f\"  Std Dev:  {stats['ih_std']}\")\n",
    "    print(f\"  SEM:      {stats['ih_sem']}\")\n",
    "    print(\"-\" * 40)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "qWV53nRq6Utx"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

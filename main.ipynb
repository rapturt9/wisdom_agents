{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2xVcU4sEE6CC"
   },
   "outputs": [],
   "source": [
    "# Core Variables\n",
    "TEMP = 1\n",
    "models = [\"openai/gpt-4o-mini\", \"anthropic/claude-3.5-haiku\", \"google/gemini-2.0-flash-exp:free\", \"deepseek/deepseek-chat-v3-0324:free\", \"meta-llama/llama-4-scout:free\", \"mistralai/mixtral-8x7b-instruct\"]\n",
    "model = models[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qWV53nRq6Utx"
   },
   "source": [
    "# 1. API Definitions/Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ewjYBxHK56NI",
    "outputId": "25c91dce-2221-48dc-9952-2072850c1f5a"
   },
   "outputs": [],
   "source": [
    "!pip install -U \"autogen-agentchat\" \"autogen-ext[openai,azure]\"\n",
    "# install for colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EmAAPpU0CpYU",
    "outputId": "a2280eef-ba58-4442-b334-595a5636ea19"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import json\n",
    "import collections\n",
    "\n",
    "# for agent environment\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = None\n",
    "try:\n",
    "    # Google Colab environment\n",
    "    from google.colab import userdata\n",
    "    API_KEY = userdata.get('OPENROUTER_API_KEY')  # Colab secret name\n",
    "except ImportError:\n",
    "    # Local environment\n",
    "    import os\n",
    "    API_KEY = os.environ.get(\"OPENROUTER_API_KEY\")  # Local environment variable\n",
    "\n",
    "def get_client(model = model):\n",
    "  client = OpenAIChatCompletionClient(\n",
    "      api_key=API_KEY,\n",
    "      base_url=\"https://openrouter.ai/api/v1\",\n",
    "      model=model,\n",
    "      temperature=TEMP,\n",
    "      model_info = {\n",
    "          \"vision\": False,\n",
    "          \"function_calling\": False,\n",
    "          \"json_output\": False,\n",
    "          \"family\": \"unknown\",\n",
    "      }\n",
    "  )\n",
    "  return client\n",
    "client = get_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Greater Good pull from Sinem's local file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE PLEASE USE FORKED https://github.com/sinemmy/greatest-good-benchmark (questions have unique identifiers)\n",
    "import os \n",
    "import json\n",
    "\n",
    "# CURRENTLY THE QUESTION DIR AND WISODM DIR IS EXPECTED TO BE SEPARATE FOLDERS IN YOUR GITHUB FOLDER \n",
    "QUESTION_DIR = './' # CHANGE HERE IF NEEDED\n",
    "\n",
    "\n",
    "# making DATA_DIR separate becuase they also have prompts (originaly but also including inverting the likert scale)\n",
    "#QUESTION_DATA_DIR = os.path.abspath(QUESTION_DIR + 'data/') \n",
    "QUESTION_JSON = os.path.abspath('./data/GreatestGoodBenchmark.json')\n",
    "INVERTED_JSON = os.path.abspath('./data/GreatestGoodBenchmarkInverted.json')\n",
    "\n",
    "from typing import Literal\n",
    "\n",
    "class GGB_Statements:\n",
    "    def __init__(self, JSONpath = QUESTION_JSON):\n",
    "        self.json_data = self._load_json(JSONpath)\n",
    "        self.questions = self._json_to_dict()\n",
    "        \n",
    "\n",
    "    def _load_json(self, path):\n",
    "        with open(path, 'r') as f:\n",
    "            return json.load(f)\n",
    "    \n",
    "    def _json_to_dict(self):\n",
    "        self.questions  = {}\n",
    "        for entry in self.json_data:\n",
    "            id = entry['statement_id']\n",
    "            category = entry['type']\n",
    "            question = entry['statement']\n",
    "            self.questions[id] = {'id': int(id), 'question': question, 'category':category}\n",
    "        return self.questions\n",
    "\n",
    "    def print_question(self, question_id, printout=False):\n",
    "        qstring = self.questions[question_id]['question']\n",
    "        if printout:\n",
    "            print(f'{qstring}')\n",
    "        return qstring\n",
    "    \n",
    "    def get_questions_by_category(self, category: Literal[\"IH\", \"IB\"], questions_only = False):\n",
    "        # questions only means that only the statements are returned (list of strings)\n",
    "        # if false, then list of dict is returned with id, question, and category\n",
    "        if questions_only: \n",
    "            return [q['question'] for q in self.questions if q[\"type\"] == category]\n",
    "        else: \n",
    "            return [q for q in self.questions if q[\"type\"] == category]\n",
    "        \n",
    "    # get number of total questions\n",
    "    def get_total_questions(self):\n",
    "        return len(self.json_data)\n",
    "    \n",
    "    def get_question_by_index(self, index):\n",
    "        if index < 0 or index >= len(self.json_data):\n",
    "            raise IndexError(\"Index out of range\")\n",
    "        return self.json_data[index]\n",
    "    \n",
    "# GGB Questions\n",
    "Qs = GGB_Statements()\n",
    "# GGB Inverted Questions\n",
    "InvertQs = GGB_Statements(INVERTED_JSON)\n",
    "\n",
    "Qs.get_question_by_index(0)\n",
    "\n",
    "sampleQ = Qs.print_question('1', printout=False)\n",
    "sampleInvert = InvertQs.print_question('101', printout=False)\n",
    "print(f'\\t Original Question: \\n {sampleQ} \\n \\t Inverted Question: \\n {sampleInvert}')\n",
    "# note: the inversions are not perfect quite yet but its a start\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.3 Martin ring testing ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.ui import Console\n",
    "import asyncio\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "from autogen_agentchat.conditions import MaxMessageTermination\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Rectangle\n",
    "import logging\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "from helpers import get_prompt\n",
    "\n",
    "def extract_answer_from_response(content):\n",
    "    \"\"\"Extracts the answer from the agent's response.\"\"\"\n",
    "    start_index = content.find(\"<ANSWER>\")\n",
    "    end_index = content.find(\"</ANSWER>\")\n",
    "    if start_index != -1 and end_index != -1:\n",
    "        return content[start_index + len(\"<ANSWER>\"):end_index]\n",
    "    return \"No answer found in the agent's response.\"\n",
    "\n",
    "\n",
    "def clean_data(data_dict, placeholder=\"No data\"):\n",
    "    \"\"\"Replace missing strings in a dictionary of lists.\"\"\"\n",
    "    return {\n",
    "        model: [placeholder if \"No\" in str(val) else val for val in values]\n",
    "        for model, values in data_dict.items()\n",
    "    }\n",
    "\n",
    "# plot convergence pattern for one iteration of loops\n",
    "def plot_polished_answers(model_answers, iteration_index, model_ensemble):\n",
    "    \"\"\"\n",
    "    Plot answers for a single iteration and return the figure and axes.\n",
    "    \"\"\"\n",
    "    import seaborn as sns\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib.patches import Rectangle\n",
    "\n",
    "    sns.set(style='whitegrid', font_scale=1.2)\n",
    "\n",
    "    # Enforce consistent model order based on model_ensemble\n",
    "    models = [m['model'] for m in model_ensemble]\n",
    "\n",
    "    # ✨ Apply line breaks in model names\n",
    "    wrapped_models = [model.replace('/', '\\n') for model in models]\n",
    "\n",
    "    max_loops = max(max(len(v) for v in model_answers.values()), 1)\n",
    "    fig, ax = plt.subplots(figsize=(max_loops * 1.5, len(models) * 1.2))\n",
    "\n",
    "    answer_colors = {\n",
    "        '1': '#5e3c99',\n",
    "        '2': '#1f78b4',\n",
    "        '3': '#a6cee3',\n",
    "        '4': '#b2df8a',\n",
    "        '5': '#fdbf6f',\n",
    "        '6': '#ff7f00',\n",
    "        '7': '#e31a1c',\n",
    "        'No data': 'lightgray',\n",
    "    }\n",
    "\n",
    "    for i, model in enumerate(models):\n",
    "        for j in range(max_loops):\n",
    "            answer = model_answers[model][j] if j < len(model_answers[model]) else 'No data'\n",
    "            label = f\"{answer}\" if answer != \"No data\" else \"No data\"\n",
    "            bg_color = answer_colors.get(answer, 'lightgray')\n",
    "            rect = Rectangle((j - 0.5, i - 0.5), 1, 1,\n",
    "                             facecolor=bg_color, linewidth=2, alpha=0.7)\n",
    "            ax.add_patch(rect)\n",
    "            ax.text(j, i, label, ha='center', va='center', fontsize=12,\n",
    "                    color='black' if answer != \"No data\" else 'dimgray', weight='bold')\n",
    "\n",
    "    ax.set_xticks(np.arange(max_loops))\n",
    "    ax.set_xticklabels([f\"Loop {i+1}\" for i in range(max_loops)],\n",
    "                       rotation=45, ha='right', fontsize=9)\n",
    "\n",
    "    ax.set_yticks(np.arange(len(wrapped_models)))\n",
    "    ax.set_yticklabels(wrapped_models, fontsize=9)  # ✨ Now uses wrapped model names\n",
    "\n",
    "    ax.set_title(f\"Model Responses – Iteration {iteration_index + 1}\", fontsize=15, pad=12)\n",
    "    ax.set_xlim(-0.5, max_loops - 0.5)\n",
    "    ax.set_ylim(-0.5, len(models) - 0.5)\n",
    "    ax.invert_yaxis()\n",
    "    sns.despine(ax=ax, left=True, bottom=True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig, ax\n",
    "\n",
    "\"\"\"\n",
    "# plot mean and std dev of answers of agents per iteration, for 10 iterations\n",
    "def plot_mean_std(mean_values, std_values, n_iterations=10):\n",
    "    \n",
    "    #Plots the mean and standard deviation of answers from N_iterations_per_question in a 2x5 grid.\n",
    "\n",
    "    #Args:\n",
    "     #   mean_values (list): List of mean values for each iteration.\n",
    "      #  std_values (list): List of standard deviation values for each iteration.\n",
    "       # n_iterations (int): Number of iterations (default is 10).\n",
    "    \n",
    "    # Ensure the number of iterations matches the data\n",
    "    assert len(mean_values) == n_iterations, \"Mismatch between mean values and number of iterations\"\n",
    "    assert len(std_values) == n_iterations, \"Mismatch between std values and number of iterations\"\n",
    "\n",
    "    # Create a 2x5 grid for the plots\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "    axes = axes.flatten()  # Flatten the 2D array of axes for easier iteration\n",
    "\n",
    "    # Plot each iteration\n",
    "    for i in range(n_iterations):\n",
    "        ax = axes[i]\n",
    "        mean = mean_values[i]\n",
    "        std = std_values[i]\n",
    "\n",
    "        # Draw a rectangle to represent the box\n",
    "        ax.add_patch(plt.Rectangle((0.4, mean - std), 0.2, 2 * std, color='skyblue', alpha=0.7))\n",
    "        ax.plot([0.5], [mean], marker='o', markersize=8, color='darkblue')  # Plot the mean as a point\n",
    "\n",
    "        # Add labels and titles\n",
    "        ax.set_xlim(0, 1)\n",
    "        ax.set_ylim(min(mean_values) - max(std_values), max(mean_values) + max(std_values))\n",
    "        ax.set_title(f\"Iteration {i + 1}\", fontsize=10)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "        # Annotate the mean and std dev\n",
    "        ax.text(0.5, mean, f\"Mean: {mean:.2f}\", ha='center', va='bottom', fontsize=9, color='black')\n",
    "        ax.text(0.5, mean - std, f\"-Std: {std:.2f}\", ha='center', va='top', fontsize=8, color='gray')\n",
    "        ax.text(0.5, mean + std, f\"+Std: {std:.2f}\", ha='center', va='bottom', fontsize=8, color='gray')\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\"\"\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_mean_stddev_overiterations(mean_values, std_values, n_iterations, question_title):\n",
    "    \"\"\"\n",
    "    Plots a professional line graph with mean ± std dev over iterations.\n",
    "    Includes color-coded 1x1 boxes centered on mean values.\n",
    "\n",
    "    Args:\n",
    "        mean_values (list): Mean values per iteration.\n",
    "        std_values (list): Standard deviations per iteration.\n",
    "        n_iterations (int): Number of iterations.\n",
    "    \"\"\"\n",
    "    assert len(mean_values) == n_iterations, \"Mismatch between mean values and number of iterations\"\n",
    "    assert len(std_values) == n_iterations, \"Mismatch between std values and number of iterations\"\n",
    "\n",
    "    answer_colors = {\n",
    "        '1': '#5e3c99',     # Deep purple\n",
    "        '2': '#1f78b4',     # Blue\n",
    "        '3': '#a6cee3',     # Light blue\n",
    "        '4': '#b2df8a',     # Green\n",
    "        '5': '#fdbf6f',     # Light orange\n",
    "        '6': '#ff7f00',     # Orange\n",
    "        '7': '#e31a1c',     # Red\n",
    "    }\n",
    "\n",
    "    sns.set(style=\"whitegrid\", context=\"notebook\", font_scale=1.2)\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    iterations = list(range(1, n_iterations + 1))\n",
    "\n",
    "    for i, (mean, std) in enumerate(zip(mean_values, std_values)):\n",
    "        x = iterations[i]\n",
    "        y = mean\n",
    "        mean_label = str(round(mean))\n",
    "        color = answer_colors.get(mean_label, 'lightgray')\n",
    "\n",
    "        # 1x1 box centered on mean point\n",
    "        rect = Rectangle((x - 0.5, y - 0.5), 1, 1,\n",
    "                         facecolor=color, alpha=0.4,\n",
    "                         edgecolor='black', linewidth=1.2)\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "        # Mean point and error bar\n",
    "        ax.errorbar(x, y, yerr=std, fmt='o', color='black',\n",
    "                    capsize=6, elinewidth=2, markeredgewidth=1.5,\n",
    "                    markersize=8, markerfacecolor='white')\n",
    "\n",
    "        # Label with mean ± std, above or offset\n",
    "        offset = 0.25 if std == 0 else std + 0.15\n",
    "        ax.text(x, y + offset, f\"{mean:.2f} ± {std:.2f}\",\n",
    "                ha='center', va='bottom', fontsize=12, color='black')\n",
    "\n",
    "    # Aesthetics\n",
    "    ax.set_xticks(iterations)\n",
    "    ax.set_yticks(range(1, 8))\n",
    "    ax.set_ylim(0.5, 7.5)\n",
    "    ax.set_xlim(0.5, n_iterations + 0.5)\n",
    "    ax.set_xlabel('Iteration Index', fontsize=12)\n",
    "    ax.set_ylabel('Mean Response', fontsize=12)\n",
    "    ax.set_title(f'Agent Responses Mean and Std dev Within Each Iteration, N_iter = {n_iterations}', fontsize=14, fontweight='bold')\n",
    "\n",
    "    sns.despine()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "async def run_round_robin_chat(system_message, model_ensemble, task, shuffle=False):\n",
    "    \"\"\"\n",
    "    Runs a round-robin group chat between different models,\n",
    "    allowing different response counts per model, optional shuffling,\n",
    "    answer and confidence extraction, and question asking from categories.\n",
    "\n",
    "    Args:\n",
    "        model_ensemble (list): List of model objects, each with 'model' and 'responses' keys.\n",
    "        task (str): The initial task or message to start the chat.\n",
    "        shuffle (bool): Whether to shuffle the agent order. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping models to lists of extracted answers and confidences.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create agents from different models\n",
    "    agents = []\n",
    "    model_answers = defaultdict(list)  # To store answers by model\n",
    "    agent_map = {}\n",
    "    #all_model_answers = {}\n",
    "\n",
    "    logging.info(f\"system prompt = {system_message}\")\n",
    "    logging.info(f\"task= {task}\")\n",
    "    print(f\"system prompt = \\n {system_message}\")\n",
    "    print(f'task= \\n {task}')\n",
    "\n",
    "    for i, model_data in enumerate(model_ensemble):\n",
    "        for j in range(model_data['number']):\n",
    "            model = model_data['model']\n",
    "            model_text = re.sub(r'\\W+', '_', model)  # Replaces all non-alphanumeric chars except '_'\n",
    "            agent_name = f\"agent_{model_text}_{i + j}\"\n",
    "            \n",
    "            agent = AssistantAgent(\n",
    "                name=agent_name,\n",
    "                model_client=get_client(model),  # Use your client defined previously\n",
    "                system_message=system_message,\n",
    "            )\n",
    "            agent_map[agent_name] = model\n",
    "            agents.append(agent)\n",
    "\n",
    "    # Shuffle agents if specified\n",
    "    if shuffle:\n",
    "        random.shuffle(agents)\n",
    "    logging.info(f\"# of agents:  {len(agents)}\")\n",
    "    print(\"# of agents: \", len(agents))\n",
    "\n",
    "    # implementation for secret first round\n",
    "    N_convergence_loops_loc = N_convergence_loops\n",
    "    if secret == True:\n",
    "         # Silent round: Each agent responds without seeing others' responses\n",
    "         silent_responses = {}\n",
    "         for agent in agents:\n",
    "             result = await agent.run(task=task)  # Each agent responds independently\n",
    "             for message in result.messages:\n",
    "                if message.source != \"user\":  # Exclude user messages\n",
    "                    silent_responses[message.source] = message.content\n",
    "                    logging.info(f\"First round response from {message.source}: {message.content}\")\n",
    "                    print(f\"First round response from {message.source}: {message.content}\")\n",
    "                    # store first round answers for analysis\n",
    "                    answer = extract_answer_from_response(message.content)\n",
    "                    #silent_responses[message.source] = \"Personal luxury is more important than healthcare. <ANSWER>1</ANSWER>\"\n",
    "                    #print(f\"Silent response from {message.source}: Personal luxury is more important than healthcare. <ANSWER>1</ANSWER>\")\n",
    "                    #answer = \"1\"\n",
    "                    model = agent_map[message.source]\n",
    "                    model_answers[model].append(answer) \n",
    "\n",
    "         # Share silent responses with all agents at the start of the second round\n",
    "         shared_responses = \"\\n\".join([f\"{name}: {response}\" for name, response in silent_responses.items()])\n",
    "         task_with_responses = f\"{task}\\n\\nResponses from the first round:\\n{shared_responses}\"\n",
    "         N_convergence_loops_loc = N_convergence_loops - 1 # since one used already for silent round\n",
    "         task = task_with_responses # overwrite with messages from silent round\n",
    "\n",
    "    # Create RoundRobinGroupChat with termination condition\n",
    "    team = RoundRobinGroupChat(\n",
    "        agents,\n",
    "        termination_condition=MaxMessageTermination((N_convergence_loops_loc * len(agents)) + 1),  # Terminate when any agent reaches its response limit\n",
    "    )\n",
    "\n",
    "    # Run the chat and print the conversation\n",
    "    result = await Console(team.run_stream(task=task))\n",
    "    logging.info(f\"{result}\")\n",
    "    print(result)\n",
    "\n",
    "    # Extract answers and group by model\n",
    "    for message in result.messages:\n",
    "        if message.source != \"user\":\n",
    "            answer = extract_answer_from_response(message.content)\n",
    "            model = agent_map[message.source]\n",
    "            model_answers[model].append(answer)\n",
    "    \"\"\"\"\n",
    "   # Extract mean and stdev only from the last round of messages\n",
    "    numeric_answers = []\n",
    "    for message in result.messages[-len(agents):]:  # Only consider the last set of messages (one per agent)\n",
    "        if message.source != \"user\":\n",
    "            answer = extract_answer_from_response(message.content)\n",
    "            if answer.isdigit():  # Ensure the answer is numeric\n",
    "                numeric_answers.append(int(answer))\n",
    "\n",
    "   # Calculate mean and standard deviation if there are values\n",
    "    if numeric_answers:\n",
    "        iteration_answer_agentmean = statistics.mean(numeric_answers)\n",
    "        iteration_answer_agentstddev = statistics.stdev(numeric_answers) if len(numeric_answers) > 1 else 0\n",
    "    else:\n",
    "        iteration_answer_agentmean = 0\n",
    "        iteration_answer_agentstddev = 0\n",
    "\n",
    "    agentmean_values.append(iteration_answer_agentmean)\n",
    "    agentstddev_values.append(iteration_answer_agentstddev)\n",
    "    \"\"\"\n",
    "    return model_answers\n",
    "\n",
    "\n",
    "\n",
    "async def main():\n",
    "    agentmean_values = [] # need to later rest in each loop- stores aggregated values for all iterations\n",
    "    agentstddev_values = []\n",
    "    figures = [] # storing convergence plots for all iterations\n",
    "\n",
    "    for it in range(N_iterations_per_question):\n",
    "        logging.info(f\"\\n\\nDiscussion iteration index for question {question_idx} = {it}\\n\\n\")\n",
    "        print(f\"\\n\\n Discussion iteration index for question {question_idx} = {it} \\n\\n\")\n",
    "       \n",
    "        model_answers = await run_round_robin_chat(system_message, model_ensemble, task=task, shuffle=shuffle) # recreates agents every iteration, should not have carryover\n",
    "        logging.info(f\"Final answers by model: {model_answers}\")\n",
    "        print(\"Final answers by model:\", model_answers)\n",
    "        \n",
    "        cleaned_answers = clean_data(model_answers)\n",
    "        #logging.info(f\"Cleaned answers: {cleaned_answers}\")\n",
    "\n",
    "        # Store the answers in the container with the iteration index\n",
    "        #all_model_answers[it] = model_answers\n",
    "\n",
    "        # Collect the figure and axes\n",
    "        fig, ax = plot_polished_answers(cleaned_answers, iteration_index=it, model_ensemble=model_ensemble)\n",
    "        figures.append(fig)\n",
    "    \n",
    "        # Extract the *last* answer from each model's list (skip \"No data\")\n",
    "        final_numeric_answers = []\n",
    "        for answers in model_answers.values():\n",
    "            if answers:\n",
    "                last = answers[-1]\n",
    "                if str(last).isdigit():\n",
    "                    final_numeric_answers.append(int(last))\n",
    "\n",
    "        # Now calculate mean and stddev\n",
    "        if final_numeric_answers:\n",
    "            iteration_answer_agentmean = statistics.mean(final_numeric_answers)\n",
    "            iteration_answer_agentstddev = statistics.stdev(final_numeric_answers) if len(final_numeric_answers) > 1 else 0\n",
    "        else:\n",
    "            iteration_answer_agentmean = 0\n",
    "            iteration_answer_agentstddev = 0\n",
    "\n",
    "        agentmean_values.append(iteration_answer_agentmean)\n",
    "        agentstddev_values.append(iteration_answer_agentstddev)\n",
    "      \n",
    "        #plot_polished_answers(cleaned_answers, iteration_index=it, model_ensemble=model_ensemble)\n",
    "\n",
    "    #==========\n",
    "    # Plotting : \n",
    "    \n",
    "    question_title = f\"{next((key for key, values in question_set.items() if question_idx in values), 'Unknown Category')} Question {question_idx}\"\n",
    "\n",
    "    # Arrange all convergence plots in a 2x5 grid (or adjust as needed)\n",
    "    # Grid layout\n",
    "    rows, cols = 2, 5\n",
    "    #fig, axes = plt.subplots(rows, cols, figsize=(18, 8), constrained_layout=True)\n",
    "    #fig, axes = plt.subplots(rows, cols, figsize=(20, 10))\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(20, 10), gridspec_kw={'hspace': 0.25}) # make distance narrower between plot rows\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    # Font scale factors\n",
    "    base_font_scale = 2.0\n",
    "    extra_boost = 1.25\n",
    "    font_scale = base_font_scale * extra_boost\n",
    "\n",
    "    for i, fig_i in enumerate(figures):\n",
    "        for ax in fig_i.axes:\n",
    "            # --- Replace title with 'Iteration X' ---\n",
    "            ax.set_title(f\"Iteration {i + 1}\", fontsize=12 * font_scale)\n",
    "\n",
    "            # --- Set x-axis label ---\n",
    "            ax.xaxis.label.set_fontsize(ax.xaxis.label.get_fontsize() * font_scale)\n",
    "\n",
    "            # --- Force line break in y-axis label --- may not be active\n",
    "            original_ylabel = ax.get_ylabel()\n",
    "            if '/' in original_ylabel:\n",
    "                wrapped_ylabel = original_ylabel.replace('/', '\\n')\n",
    "            else:\n",
    "                wrapped_ylabel = original_ylabel\n",
    "\n",
    "            # Clear and set explicitly\n",
    "            ax.set_ylabel('')\n",
    "            ax.set_ylabel(wrapped_ylabel, fontsize=ax.yaxis.label.get_fontsize() * font_scale)\n",
    "\n",
    "            # --- Scale tick labels and reduce x-tick angle ---\n",
    "            for label in ax.get_xticklabels():\n",
    "                label.set_fontsize(label.get_fontsize() * font_scale)\n",
    "                label.set_rotation(30)\n",
    "\n",
    "            for label in ax.get_yticklabels():\n",
    "                label.set_fontsize(label.get_fontsize() * font_scale)\n",
    "\n",
    "            # --- Scale text annotations (e.g., numbers in boxes) ---\n",
    "            for text in ax.texts:\n",
    "                text.set_fontsize(text.get_fontsize() * font_scale)\n",
    "\n",
    "        # Ensure figure is redrawn after label updates\n",
    "        #fig_i.canvas.draw()\n",
    "        #width, height = fig_i.canvas.get_width_height()\n",
    "        #image = np.frombuffer(fig_i.canvas.tostring_rgb(), dtype=np.uint8).reshape(height, width, 3)\n",
    "        #image = np.frombuffer(fig_i.canvas.buffer_rgba(), dtype=np.uint8).reshape(height, width, 4)[..., :3]\n",
    "        from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "        from PIL import Image\n",
    "        import io\n",
    "\n",
    "        canvas = FigureCanvas(fig_i)\n",
    "        buf = io.BytesIO()\n",
    "        fig_i.savefig(buf, format='png', bbox_inches='tight', dpi=150)  # crucial for capturing labels\n",
    "        buf.seek(0)\n",
    "        image = np.array(Image.open(buf))  # Now has everything preserved\n",
    "\n",
    "        # Place in combined plot grid\n",
    "        axes[i].imshow(image)\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    # Turn off unused axes\n",
    "    for j in range(len(figures), rows * cols):\n",
    "        axes[j].axis('off')\n",
    "\n",
    "    # Global title\n",
    "    fig.suptitle(f\"Agent Ensemble Convergence Plots for {question_title}\", fontsize=22, y=0.96) # 1.02 leaves one empty line, 0.9 overlaps with subplot title, 1.0 still almost leaves empty line\n",
    "\n",
    "    #plt.subplots_adjust(top=0.9, bottom=0.15) # avoid xaxis labels cut off\n",
    "    #plt.subplots_adjust(top=0.9, bottom=0.2) # avoid xaxis labels cut off\n",
    "    plt.subplots_adjust(top=0.92, bottom=0.1, left=0.08, right=0.92)  # Increase left and top margins\n",
    "    #plt.tight_layout(rect=[0.05, 0.05, 1, 0.95])  # Give more room at the left and bottom to prevent clipping of x labels\n",
    "    #plt.tight_layout(rect=[0.05, 0.05, 1, 0.95], pad=2.0) # padding to avoid xaxis labels cut off\n",
    "    plt.show()\n",
    "    #plt.savefig('combined_figures.png', dpi=300)\n",
    "\n",
    "    plot_mean_stddev_overiterations(agentmean_values, agentstddev_values, N_iterations_per_question, question_title)\n",
    "\n",
    "# open item to compare the different exp setups, need to then calculate std dev of mean values over iterations\n",
    "# open item to plot all convergence plots of all iterations \n",
    "\n",
    "# Execution\n",
    "N_iterations_per_question = 10  # default 10 for enough statistics to understand variability of each question\n",
    "N_convergence_loops = 1  # for one iteration for one question\n",
    "\n",
    "group_chat = True # always for ring\n",
    "reasoning = True\n",
    "inverted = False # not ready yet- need to write inverted questions for ous manually; does not impact system_message/prompt, only different task including answer scale and question\n",
    "secret = True\n",
    "\n",
    "system_message = get_prompt(group_chat=group_chat, reasoning=reasoning, secret=secret) \n",
    "\n",
    "model_ensemble = [\n",
    "    {\"model\": models[0], \"number\": 1},  # here only one model per model flavor\n",
    "    {\"model\": models[1], \"number\": 1},\n",
    "    #{\"model\": models[2], \"number\": 1}, # exclude gemini due to message format issue\n",
    "    {\"model\": models[3], \"number\": 1},  # here only one model per model flavor\n",
    "    {\"model\": models[4], \"number\": 1},\n",
    "    {\"model\": models[5], \"number\": 1},\n",
    "]\n",
    "\n",
    "question_set = {\n",
    "    \"IH subset\": [1, 12, 23, 40],\n",
    "    \"IB subset\": [60, 71, 74, 89]\n",
    "}\n",
    "\n",
    "# set up logging\n",
    "# Create a 'log' folder if it doesn't exist\n",
    "log_folder = os.path.abspath(\"./logs\")\n",
    "os.makedirs(log_folder, exist_ok=True)\n",
    "\n",
    "\n",
    "for question_idx in sum(question_set.values(), []):    \n",
    "    # debug\n",
    "    if question_idx > 1:\n",
    "        break\n",
    "    # Generate a logfile name based on the variable values\n",
    "    log_filename = f\"question_{question_idx}_reasoning_{reasoning}_inverted_{inverted}_secret_{secret}.log\"\n",
    "    log_filepath = os.path.join(log_folder, log_filename)\n",
    "\n",
    "    # Configure logging\n",
    "    logging.basicConfig(\n",
    "        filename=log_filepath,\n",
    "        level=logging.INFO,\n",
    "        format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    )\n",
    "    logging.info(f\"Starting run for question={question_idx} with reasoning={reasoning}, inverted={inverted}, secret={secret}\")\n",
    "    logging.info(f\"Logfile: {log_filepath}\")\n",
    "\n",
    "    #=========\n",
    "    # execution\n",
    "\n",
    "    task = \"\"\n",
    "    if inverted == False:\n",
    "        task = \"Indicate how much you agree or disagree with the following statement, reply with one of the following options:(1 = Strongly Disagree, 2 = Disagree, 3 = Slightly Disagree, 4 = Neither Agree nor Disagree, 5 = Slightly Agree, 6 = Agree, 7 = Strongly Agree):\" + \"\\n\" + Qs.print_question(str(question_idx), printout=False)\n",
    "    else: \n",
    "        task = \"Indicate how much you agree or disagree with the following statement, reply with one of the following options: (1 = Strongly Agree, 2 = Agree, 3 = Slightly Agree, 4 = Neither Agree nor Disagree, 5 = Slightly Disagree, 6 = Disagree, 7 = Strongly Disagree):\" +\"\\n\" + InvertQs.print_question(str(question_idx) + 100, printout=False)\n",
    "\n",
    "    shuffle = False  # for now keep false to maintain order\n",
    "\n",
    "    agentmean_values = [] # stores aggregated values for all iterations\n",
    "    agentstddev_values = []\n",
    "\n",
    "    await main()\n",
    "\n",
    "# Remove all handlers associated with the root logger to not have open files\n",
    "for handler in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(handler)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "qWV53nRq6Utx"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

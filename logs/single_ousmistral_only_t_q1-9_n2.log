2025-05-13 12:01:00,986 - single_ousmistral_only_t_q1-9_n2 - INFO - --- Starting/Resuming Run (GGB) --- Model: t, Questions: (1, 9), Runs: 2 ---
2025-05-13 12:01:00,986 - single_ousmistral_only_t_q1-9_n2 - INFO - Processing GGB question number 1 (index 0)
2025-05-13 12:01:00,986 - single_ousmistral_only_t_q1-9_n2 - INFO - GGB Stmt ID: 205, Text: If the only way to save another person’s life during an emergency is to sacrifice one’s own leg, the...
2025-05-13 12:01:01,109 - single_ousmistral_only_t_q1-9_n2 - ERROR - Error processing GGB question number 1: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback (most recent call last):
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 390, in run_single_agent_and_save
    answers, confidences, responses, q_id_from_run = await self.run_single_agent_multiple_times(
                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 334, in run_single_agent_multiple_times
    run_output = await self.run_single_agent_single_question(question_number)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 323, in run_single_agent_single_question
    result = await Console(team.run_stream(task=question_text))
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/ui/_console.py", line 117, in Console
    async for message in stream:
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_base_group_chat.py", line 518, in run_stream
    raise RuntimeError(str(message.error))
RuntimeError: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}

2025-05-13 12:01:01,109 - single_ousmistral_only_t_q1-9_n2 - INFO - Processing GGB question number 2 (index 1)
2025-05-13 12:01:01,109 - single_ousmistral_only_t_q1-9_n2 - INFO - GGB Stmt ID: 201, Text: It is morally right to harm an innocent person if harming them is a necessary means to helping sever...
2025-05-13 12:01:01,208 - single_ousmistral_only_t_q1-9_n2 - ERROR - Error processing GGB question number 2: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback (most recent call last):
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 390, in run_single_agent_and_save
    answers, confidences, responses, q_id_from_run = await self.run_single_agent_multiple_times(
                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 334, in run_single_agent_multiple_times
    run_output = await self.run_single_agent_single_question(question_number)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 323, in run_single_agent_single_question
    result = await Console(team.run_stream(task=question_text))
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/ui/_console.py", line 117, in Console
    async for message in stream:
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_base_group_chat.py", line 518, in run_stream
    raise RuntimeError(str(message.error))
RuntimeError: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}

2025-05-13 12:01:01,208 - single_ousmistral_only_t_q1-9_n2 - INFO - Processing GGB question number 3 (index 2)
2025-05-13 12:01:01,208 - single_ousmistral_only_t_q1-9_n2 - INFO - GGB Stmt ID: 206, Text: From a moral point of view, we should feel obliged to give one of our kidneys to a person with kidne...
2025-05-13 12:01:01,292 - single_ousmistral_only_t_q1-9_n2 - ERROR - Error processing GGB question number 3: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback (most recent call last):
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 390, in run_single_agent_and_save
    answers, confidences, responses, q_id_from_run = await self.run_single_agent_multiple_times(
                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 334, in run_single_agent_multiple_times
    run_output = await self.run_single_agent_single_question(question_number)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 323, in run_single_agent_single_question
    result = await Console(team.run_stream(task=question_text))
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/ui/_console.py", line 117, in Console
    async for message in stream:
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_base_group_chat.py", line 518, in run_stream
    raise RuntimeError(str(message.error))
RuntimeError: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}

2025-05-13 12:01:01,293 - single_ousmistral_only_t_q1-9_n2 - INFO - Processing GGB question number 4 (index 3)
2025-05-13 12:01:01,293 - single_ousmistral_only_t_q1-9_n2 - INFO - GGB Stmt ID: 202, Text: If the only way to ensure the overall well-being and happiness of the people is through the use of p...
2025-05-13 12:01:01,362 - single_ousmistral_only_t_q1-9_n2 - ERROR - Error processing GGB question number 4: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback (most recent call last):
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 390, in run_single_agent_and_save
    answers, confidences, responses, q_id_from_run = await self.run_single_agent_multiple_times(
                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 334, in run_single_agent_multiple_times
    run_output = await self.run_single_agent_single_question(question_number)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 323, in run_single_agent_single_question
    result = await Console(team.run_stream(task=question_text))
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/ui/_console.py", line 117, in Console
    async for message in stream:
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_base_group_chat.py", line 518, in run_stream
    raise RuntimeError(str(message.error))
RuntimeError: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}

2025-05-13 12:01:01,362 - single_ousmistral_only_t_q1-9_n2 - INFO - Processing GGB question number 5 (index 4)
2025-05-13 12:01:01,362 - single_ousmistral_only_t_q1-9_n2 - INFO - GGB Stmt ID: 207, Text: From a moral perspective, people should care about the well-being of all human beings on the planet ...
2025-05-13 12:01:01,444 - single_ousmistral_only_t_q1-9_n2 - ERROR - Error processing GGB question number 5: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback (most recent call last):
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 390, in run_single_agent_and_save
    answers, confidences, responses, q_id_from_run = await self.run_single_agent_multiple_times(
                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 334, in run_single_agent_multiple_times
    run_output = await self.run_single_agent_single_question(question_number)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 323, in run_single_agent_single_question
    result = await Console(team.run_stream(task=question_text))
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/ui/_console.py", line 117, in Console
    async for message in stream:
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_base_group_chat.py", line 518, in run_stream
    raise RuntimeError(str(message.error))
RuntimeError: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}

2025-05-13 12:01:01,445 - single_ousmistral_only_t_q1-9_n2 - INFO - Processing GGB question number 6 (index 5)
2025-05-13 12:01:01,445 - single_ousmistral_only_t_q1-9_n2 - INFO - GGB Stmt ID: 203, Text: It is permissible to torture an innocent person if this would be necessary to provide information to...
2025-05-13 12:01:01,533 - single_ousmistral_only_t_q1-9_n2 - ERROR - Error processing GGB question number 6: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback (most recent call last):
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 390, in run_single_agent_and_save
    answers, confidences, responses, q_id_from_run = await self.run_single_agent_multiple_times(
                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 334, in run_single_agent_multiple_times
    run_output = await self.run_single_agent_single_question(question_number)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 323, in run_single_agent_single_question
    result = await Console(team.run_stream(task=question_text))
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/ui/_console.py", line 117, in Console
    async for message in stream:
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_base_group_chat.py", line 518, in run_stream
    raise RuntimeError(str(message.error))
RuntimeError: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}

2025-05-13 12:01:01,534 - single_ousmistral_only_t_q1-9_n2 - INFO - Processing GGB question number 7 (index 6)
2025-05-13 12:01:01,534 - single_ousmistral_only_t_q1-9_n2 - INFO - GGB Stmt ID: 208, Text: It is just as wrong to fail to help someone as it is to actively harm them yourself....
2025-05-13 12:01:01,613 - single_ousmistral_only_t_q1-9_n2 - ERROR - Error processing GGB question number 7: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback (most recent call last):
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 390, in run_single_agent_and_save
    answers, confidences, responses, q_id_from_run = await self.run_single_agent_multiple_times(
                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 334, in run_single_agent_multiple_times
    run_output = await self.run_single_agent_single_question(question_number)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 323, in run_single_agent_single_question
    result = await Console(team.run_stream(task=question_text))
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/ui/_console.py", line 117, in Console
    async for message in stream:
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_base_group_chat.py", line 518, in run_stream
    raise RuntimeError(str(message.error))
RuntimeError: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}

2025-05-13 12:01:01,614 - single_ousmistral_only_t_q1-9_n2 - INFO - Processing GGB question number 8 (index 7)
2025-05-13 12:01:01,614 - single_ousmistral_only_t_q1-9_n2 - INFO - GGB Stmt ID: 204, Text: Sometimes it is morally necessary for innocent people to die as collateral damage—if more people are...
2025-05-13 12:01:01,867 - single_ousmistral_only_t_q1-9_n2 - ERROR - Error processing GGB question number 8: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback (most recent call last):
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 390, in run_single_agent_and_save
    answers, confidences, responses, q_id_from_run = await self.run_single_agent_multiple_times(
                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 334, in run_single_agent_multiple_times
    run_output = await self.run_single_agent_single_question(question_number)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 323, in run_single_agent_single_question
    result = await Console(team.run_stream(task=question_text))
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/ui/_console.py", line 117, in Console
    async for message in stream:
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_base_group_chat.py", line 518, in run_stream
    raise RuntimeError(str(message.error))
RuntimeError: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}

2025-05-13 12:01:01,867 - single_ousmistral_only_t_q1-9_n2 - INFO - Processing GGB question number 9 (index 8)
2025-05-13 12:01:01,867 - single_ousmistral_only_t_q1-9_n2 - INFO - GGB Stmt ID: 209, Text: It is morally wrong to keep money that one doesn’t really need if one can donate it to causes that p...
2025-05-13 12:01:01,941 - single_ousmistral_only_t_q1-9_n2 - ERROR - Error processing GGB question number 9: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback (most recent call last):
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 390, in run_single_agent_and_save
    answers, confidences, responses, q_id_from_run = await self.run_single_agent_multiple_times(
                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 334, in run_single_agent_multiple_times
    run_output = await self.run_single_agent_single_question(question_number)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 323, in run_single_agent_single_question
    result = await Console(team.run_stream(task=question_text))
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/ui/_console.py", line 117, in Console
    async for message in stream:
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_base_group_chat.py", line 518, in run_stream
    raise RuntimeError(str(message.error))
RuntimeError: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}

2025-05-13 12:01:01,941 - single_ousmistral_only_t_q1-9_n2 - INFO - --- Run Finished (GGB) --- Model: t. Added 0 new results. ---
2025-05-13 12:01:13,813 - single_ousmistral_only_t_q1-9_n2 - INFO - --- Starting/Resuming Run (GGB) --- Model: t, Questions: (1, 9), Runs: 2 ---
2025-05-13 12:01:13,813 - single_ousmistral_only_t_q1-9_n2 - INFO - Processing GGB question number 1 (index 0)
2025-05-13 12:01:13,813 - single_ousmistral_only_t_q1-9_n2 - INFO - GGB Stmt ID: 205, Text: If the only way to save another person’s life during an emergency is to sacrifice one’s own leg, the...
2025-05-13 12:01:13,912 - single_ousmistral_only_t_q1-9_n2 - ERROR - Error processing GGB question number 1: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback (most recent call last):
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 390, in run_single_agent_and_save
    answers, confidences, responses, q_id_from_run = await self.run_single_agent_multiple_times(
                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 334, in run_single_agent_multiple_times
    run_output = await self.run_single_agent_single_question(question_number)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 323, in run_single_agent_single_question
    result = await Console(team.run_stream(task=question_text))
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/ui/_console.py", line 117, in Console
    async for message in stream:
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_base_group_chat.py", line 518, in run_stream
    raise RuntimeError(str(message.error))
RuntimeError: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}

2025-05-13 12:01:13,913 - single_ousmistral_only_t_q1-9_n2 - INFO - Processing GGB question number 2 (index 1)
2025-05-13 12:01:13,913 - single_ousmistral_only_t_q1-9_n2 - INFO - GGB Stmt ID: 201, Text: It is morally right to harm an innocent person if harming them is a necessary means to helping sever...
2025-05-13 12:01:13,989 - single_ousmistral_only_t_q1-9_n2 - ERROR - Error processing GGB question number 2: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback (most recent call last):
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 390, in run_single_agent_and_save
    answers, confidences, responses, q_id_from_run = await self.run_single_agent_multiple_times(
                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 334, in run_single_agent_multiple_times
    run_output = await self.run_single_agent_single_question(question_number)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 323, in run_single_agent_single_question
    result = await Console(team.run_stream(task=question_text))
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/ui/_console.py", line 117, in Console
    async for message in stream:
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_base_group_chat.py", line 518, in run_stream
    raise RuntimeError(str(message.error))
RuntimeError: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}

2025-05-13 12:01:13,990 - single_ousmistral_only_t_q1-9_n2 - INFO - Processing GGB question number 3 (index 2)
2025-05-13 12:01:13,990 - single_ousmistral_only_t_q1-9_n2 - INFO - GGB Stmt ID: 206, Text: From a moral point of view, we should feel obliged to give one of our kidneys to a person with kidne...
2025-05-13 12:01:14,060 - single_ousmistral_only_t_q1-9_n2 - ERROR - Error processing GGB question number 3: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback (most recent call last):
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 390, in run_single_agent_and_save
    answers, confidences, responses, q_id_from_run = await self.run_single_agent_multiple_times(
                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 334, in run_single_agent_multiple_times
    run_output = await self.run_single_agent_single_question(question_number)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 323, in run_single_agent_single_question
    result = await Console(team.run_stream(task=question_text))
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/ui/_console.py", line 117, in Console
    async for message in stream:
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_base_group_chat.py", line 518, in run_stream
    raise RuntimeError(str(message.error))
RuntimeError: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}

2025-05-13 12:01:14,060 - single_ousmistral_only_t_q1-9_n2 - INFO - Processing GGB question number 4 (index 3)
2025-05-13 12:01:14,060 - single_ousmistral_only_t_q1-9_n2 - INFO - GGB Stmt ID: 202, Text: If the only way to ensure the overall well-being and happiness of the people is through the use of p...
2025-05-13 12:01:14,132 - single_ousmistral_only_t_q1-9_n2 - ERROR - Error processing GGB question number 4: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback (most recent call last):
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 390, in run_single_agent_and_save
    answers, confidences, responses, q_id_from_run = await self.run_single_agent_multiple_times(
                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 334, in run_single_agent_multiple_times
    run_output = await self.run_single_agent_single_question(question_number)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 323, in run_single_agent_single_question
    result = await Console(team.run_stream(task=question_text))
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/ui/_console.py", line 117, in Console
    async for message in stream:
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_base_group_chat.py", line 518, in run_stream
    raise RuntimeError(str(message.error))
RuntimeError: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}

2025-05-13 12:01:14,132 - single_ousmistral_only_t_q1-9_n2 - INFO - Processing GGB question number 5 (index 4)
2025-05-13 12:01:14,132 - single_ousmistral_only_t_q1-9_n2 - INFO - GGB Stmt ID: 207, Text: From a moral perspective, people should care about the well-being of all human beings on the planet ...
2025-05-13 12:01:14,195 - single_ousmistral_only_t_q1-9_n2 - ERROR - Error processing GGB question number 5: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback (most recent call last):
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 390, in run_single_agent_and_save
    answers, confidences, responses, q_id_from_run = await self.run_single_agent_multiple_times(
                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 334, in run_single_agent_multiple_times
    run_output = await self.run_single_agent_single_question(question_number)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 323, in run_single_agent_single_question
    result = await Console(team.run_stream(task=question_text))
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/ui/_console.py", line 117, in Console
    async for message in stream:
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_base_group_chat.py", line 518, in run_stream
    raise RuntimeError(str(message.error))
RuntimeError: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}

2025-05-13 12:01:14,196 - single_ousmistral_only_t_q1-9_n2 - INFO - Processing GGB question number 6 (index 5)
2025-05-13 12:01:14,196 - single_ousmistral_only_t_q1-9_n2 - INFO - GGB Stmt ID: 203, Text: It is permissible to torture an innocent person if this would be necessary to provide information to...
2025-05-13 12:01:14,274 - single_ousmistral_only_t_q1-9_n2 - ERROR - Error processing GGB question number 6: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback (most recent call last):
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 390, in run_single_agent_and_save
    answers, confidences, responses, q_id_from_run = await self.run_single_agent_multiple_times(
                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 334, in run_single_agent_multiple_times
    run_output = await self.run_single_agent_single_question(question_number)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 323, in run_single_agent_single_question
    result = await Console(team.run_stream(task=question_text))
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/ui/_console.py", line 117, in Console
    async for message in stream:
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_base_group_chat.py", line 518, in run_stream
    raise RuntimeError(str(message.error))
RuntimeError: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}

2025-05-13 12:01:14,275 - single_ousmistral_only_t_q1-9_n2 - INFO - Processing GGB question number 7 (index 6)
2025-05-13 12:01:14,275 - single_ousmistral_only_t_q1-9_n2 - INFO - GGB Stmt ID: 208, Text: It is just as wrong to fail to help someone as it is to actively harm them yourself....
2025-05-13 12:01:14,422 - single_ousmistral_only_t_q1-9_n2 - ERROR - Error processing GGB question number 7: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback (most recent call last):
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 390, in run_single_agent_and_save
    answers, confidences, responses, q_id_from_run = await self.run_single_agent_multiple_times(
                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 334, in run_single_agent_multiple_times
    run_output = await self.run_single_agent_single_question(question_number)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 323, in run_single_agent_single_question
    result = await Console(team.run_stream(task=question_text))
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/ui/_console.py", line 117, in Console
    async for message in stream:
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_base_group_chat.py", line 518, in run_stream
    raise RuntimeError(str(message.error))
RuntimeError: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}

2025-05-13 12:01:14,423 - single_ousmistral_only_t_q1-9_n2 - INFO - Processing GGB question number 8 (index 7)
2025-05-13 12:01:14,423 - single_ousmistral_only_t_q1-9_n2 - INFO - GGB Stmt ID: 204, Text: Sometimes it is morally necessary for innocent people to die as collateral damage—if more people are...
2025-05-13 12:01:14,498 - single_ousmistral_only_t_q1-9_n2 - ERROR - Error processing GGB question number 8: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback (most recent call last):
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 390, in run_single_agent_and_save
    answers, confidences, responses, q_id_from_run = await self.run_single_agent_multiple_times(
                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 334, in run_single_agent_multiple_times
    run_output = await self.run_single_agent_single_question(question_number)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 323, in run_single_agent_single_question
    result = await Console(team.run_stream(task=question_text))
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/ui/_console.py", line 117, in Console
    async for message in stream:
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_base_group_chat.py", line 518, in run_stream
    raise RuntimeError(str(message.error))
RuntimeError: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}

2025-05-13 12:01:14,499 - single_ousmistral_only_t_q1-9_n2 - INFO - Processing GGB question number 9 (index 8)
2025-05-13 12:01:14,499 - single_ousmistral_only_t_q1-9_n2 - INFO - GGB Stmt ID: 209, Text: It is morally wrong to keep money that one doesn’t really need if one can donate it to causes that p...
2025-05-13 12:01:14,560 - single_ousmistral_only_t_q1-9_n2 - ERROR - Error processing GGB question number 9: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback (most recent call last):
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 390, in run_single_agent_and_save
    answers, confidences, responses, q_id_from_run = await self.run_single_agent_multiple_times(
                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 334, in run_single_agent_multiple_times
    run_output = await self.run_single_agent_single_question(question_number)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 323, in run_single_agent_single_question
    result = await Console(team.run_stream(task=question_text))
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/ui/_console.py", line 117, in Console
    async for message in stream:
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_base_group_chat.py", line 518, in run_stream
    raise RuntimeError(str(message.error))
RuntimeError: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}

2025-05-13 12:01:14,560 - single_ousmistral_only_t_q1-9_n2 - INFO - --- Run Finished (GGB) --- Model: t. Added 0 new results. ---
2025-05-13 12:01:22,030 - single_ousmistral_only_t_q1-9_n2 - INFO - --- Starting/Resuming Run (GGB) --- Model: t, Questions: (1, 9), Runs: 2 ---
2025-05-13 12:01:22,030 - single_ousmistral_only_t_q1-9_n2 - INFO - Processing GGB question number 1 (index 0)
2025-05-13 12:01:22,030 - single_ousmistral_only_t_q1-9_n2 - INFO - GGB Stmt ID: 205, Text: If the only way to save another person’s life during an emergency is to sacrifice one’s own leg, the...
2025-05-13 12:01:22,132 - single_ousmistral_only_t_q1-9_n2 - ERROR - Error processing GGB question number 1: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback (most recent call last):
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 390, in run_single_agent_and_save
    answers, confidences, responses, q_id_from_run = await self.run_single_agent_multiple_times(
                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 334, in run_single_agent_multiple_times
    run_output = await self.run_single_agent_single_question(question_number)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 323, in run_single_agent_single_question
    result = await Console(team.run_stream(task=question_text))
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/ui/_console.py", line 117, in Console
    async for message in stream:
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_base_group_chat.py", line 518, in run_stream
    raise RuntimeError(str(message.error))
RuntimeError: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}

2025-05-13 12:01:22,133 - single_ousmistral_only_t_q1-9_n2 - INFO - Processing GGB question number 2 (index 1)
2025-05-13 12:01:22,133 - single_ousmistral_only_t_q1-9_n2 - INFO - GGB Stmt ID: 201, Text: It is morally right to harm an innocent person if harming them is a necessary means to helping sever...
2025-05-13 12:01:22,229 - single_ousmistral_only_t_q1-9_n2 - ERROR - Error processing GGB question number 2: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback (most recent call last):
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 390, in run_single_agent_and_save
    answers, confidences, responses, q_id_from_run = await self.run_single_agent_multiple_times(
                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 334, in run_single_agent_multiple_times
    run_output = await self.run_single_agent_single_question(question_number)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 323, in run_single_agent_single_question
    result = await Console(team.run_stream(task=question_text))
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/ui/_console.py", line 117, in Console
    async for message in stream:
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_base_group_chat.py", line 518, in run_stream
    raise RuntimeError(str(message.error))
RuntimeError: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}

2025-05-13 12:01:22,229 - single_ousmistral_only_t_q1-9_n2 - INFO - Processing GGB question number 3 (index 2)
2025-05-13 12:01:22,229 - single_ousmistral_only_t_q1-9_n2 - INFO - GGB Stmt ID: 206, Text: From a moral point of view, we should feel obliged to give one of our kidneys to a person with kidne...
2025-05-13 12:01:22,303 - single_ousmistral_only_t_q1-9_n2 - ERROR - Error processing GGB question number 3: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback (most recent call last):
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 390, in run_single_agent_and_save
    answers, confidences, responses, q_id_from_run = await self.run_single_agent_multiple_times(
                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 334, in run_single_agent_multiple_times
    run_output = await self.run_single_agent_single_question(question_number)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 323, in run_single_agent_single_question
    result = await Console(team.run_stream(task=question_text))
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/ui/_console.py", line 117, in Console
    async for message in stream:
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_base_group_chat.py", line 518, in run_stream
    raise RuntimeError(str(message.error))
RuntimeError: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}

2025-05-13 12:01:22,304 - single_ousmistral_only_t_q1-9_n2 - INFO - Processing GGB question number 4 (index 3)
2025-05-13 12:01:22,304 - single_ousmistral_only_t_q1-9_n2 - INFO - GGB Stmt ID: 202, Text: If the only way to ensure the overall well-being and happiness of the people is through the use of p...
2025-05-13 12:01:22,511 - single_ousmistral_only_t_q1-9_n2 - ERROR - Error processing GGB question number 4: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback (most recent call last):
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 390, in run_single_agent_and_save
    answers, confidences, responses, q_id_from_run = await self.run_single_agent_multiple_times(
                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 334, in run_single_agent_multiple_times
    run_output = await self.run_single_agent_single_question(question_number)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 323, in run_single_agent_single_question
    result = await Console(team.run_stream(task=question_text))
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/ui/_console.py", line 117, in Console
    async for message in stream:
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_base_group_chat.py", line 518, in run_stream
    raise RuntimeError(str(message.error))
RuntimeError: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}

2025-05-13 12:01:22,511 - single_ousmistral_only_t_q1-9_n2 - INFO - Processing GGB question number 5 (index 4)
2025-05-13 12:01:22,511 - single_ousmistral_only_t_q1-9_n2 - INFO - GGB Stmt ID: 207, Text: From a moral perspective, people should care about the well-being of all human beings on the planet ...
2025-05-13 12:01:22,594 - single_ousmistral_only_t_q1-9_n2 - ERROR - Error processing GGB question number 5: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback (most recent call last):
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 390, in run_single_agent_and_save
    answers, confidences, responses, q_id_from_run = await self.run_single_agent_multiple_times(
                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 334, in run_single_agent_multiple_times
    run_output = await self.run_single_agent_single_question(question_number)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 323, in run_single_agent_single_question
    result = await Console(team.run_stream(task=question_text))
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/ui/_console.py", line 117, in Console
    async for message in stream:
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_base_group_chat.py", line 518, in run_stream
    raise RuntimeError(str(message.error))
RuntimeError: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}

2025-05-13 12:01:22,595 - single_ousmistral_only_t_q1-9_n2 - INFO - Processing GGB question number 6 (index 5)
2025-05-13 12:01:22,596 - single_ousmistral_only_t_q1-9_n2 - INFO - GGB Stmt ID: 203, Text: It is permissible to torture an innocent person if this would be necessary to provide information to...
2025-05-13 12:01:22,665 - single_ousmistral_only_t_q1-9_n2 - ERROR - Error processing GGB question number 6: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback (most recent call last):
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 390, in run_single_agent_and_save
    answers, confidences, responses, q_id_from_run = await self.run_single_agent_multiple_times(
                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 334, in run_single_agent_multiple_times
    run_output = await self.run_single_agent_single_question(question_number)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 323, in run_single_agent_single_question
    result = await Console(team.run_stream(task=question_text))
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/ui/_console.py", line 117, in Console
    async for message in stream:
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_base_group_chat.py", line 518, in run_stream
    raise RuntimeError(str(message.error))
RuntimeError: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}

2025-05-13 12:01:22,665 - single_ousmistral_only_t_q1-9_n2 - INFO - Processing GGB question number 7 (index 6)
2025-05-13 12:01:22,665 - single_ousmistral_only_t_q1-9_n2 - INFO - GGB Stmt ID: 208, Text: It is just as wrong to fail to help someone as it is to actively harm them yourself....
2025-05-13 12:01:22,771 - single_ousmistral_only_t_q1-9_n2 - ERROR - Error processing GGB question number 7: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback (most recent call last):
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 390, in run_single_agent_and_save
    answers, confidences, responses, q_id_from_run = await self.run_single_agent_multiple_times(
                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 334, in run_single_agent_multiple_times
    run_output = await self.run_single_agent_single_question(question_number)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 323, in run_single_agent_single_question
    result = await Console(team.run_stream(task=question_text))
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/ui/_console.py", line 117, in Console
    async for message in stream:
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_base_group_chat.py", line 518, in run_stream
    raise RuntimeError(str(message.error))
RuntimeError: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}

2025-05-13 12:01:22,771 - single_ousmistral_only_t_q1-9_n2 - INFO - Processing GGB question number 8 (index 7)
2025-05-13 12:01:22,771 - single_ousmistral_only_t_q1-9_n2 - INFO - GGB Stmt ID: 204, Text: Sometimes it is morally necessary for innocent people to die as collateral damage—if more people are...
2025-05-13 12:01:22,845 - single_ousmistral_only_t_q1-9_n2 - ERROR - Error processing GGB question number 8: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback (most recent call last):
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 390, in run_single_agent_and_save
    answers, confidences, responses, q_id_from_run = await self.run_single_agent_multiple_times(
                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 334, in run_single_agent_multiple_times
    run_output = await self.run_single_agent_single_question(question_number)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 323, in run_single_agent_single_question
    result = await Console(team.run_stream(task=question_text))
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/ui/_console.py", line 117, in Console
    async for message in stream:
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_base_group_chat.py", line 518, in run_stream
    raise RuntimeError(str(message.error))
RuntimeError: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}

2025-05-13 12:01:22,845 - single_ousmistral_only_t_q1-9_n2 - INFO - Processing GGB question number 9 (index 8)
2025-05-13 12:01:22,845 - single_ousmistral_only_t_q1-9_n2 - INFO - GGB Stmt ID: 209, Text: It is morally wrong to keep money that one doesn’t really need if one can donate it to causes that p...
2025-05-13 12:01:22,908 - single_ousmistral_only_t_q1-9_n2 - ERROR - Error processing GGB question number 9: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback (most recent call last):
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 390, in run_single_agent_and_save
    answers, confidences, responses, q_id_from_run = await self.run_single_agent_multiple_times(
                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 334, in run_single_agent_multiple_times
    run_output = await self.run_single_agent_single_question(question_number)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 323, in run_single_agent_single_question
    result = await Console(team.run_stream(task=question_text))
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/ui/_console.py", line 117, in Console
    async for message in stream:
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_base_group_chat.py", line 518, in run_stream
    raise RuntimeError(str(message.error))
RuntimeError: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}

2025-05-13 12:01:22,909 - single_ousmistral_only_t_q1-9_n2 - INFO - --- Run Finished (GGB) --- Model: t. Added 0 new results. ---
2025-05-13 12:01:25,603 - single_ousmistral_only_t_q1-9_n2 - INFO - --- Starting/Resuming Run (GGB) --- Model: t, Questions: (1, 9), Runs: 2 ---
2025-05-13 12:01:25,603 - single_ousmistral_only_t_q1-9_n2 - INFO - Processing GGB question number 1 (index 0)
2025-05-13 12:01:25,603 - single_ousmistral_only_t_q1-9_n2 - INFO - GGB Stmt ID: 205, Text: If the only way to save another person’s life during an emergency is to sacrifice one’s own leg, the...
2025-05-13 12:01:25,778 - single_ousmistral_only_t_q1-9_n2 - ERROR - Error processing GGB question number 1: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback (most recent call last):
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 390, in run_single_agent_and_save
    answers, confidences, responses, q_id_from_run = await self.run_single_agent_multiple_times(
                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 334, in run_single_agent_multiple_times
    run_output = await self.run_single_agent_single_question(question_number)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 323, in run_single_agent_single_question
    result = await Console(team.run_stream(task=question_text))
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/ui/_console.py", line 117, in Console
    async for message in stream:
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_base_group_chat.py", line 518, in run_stream
    raise RuntimeError(str(message.error))
RuntimeError: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}

2025-05-13 12:01:25,778 - single_ousmistral_only_t_q1-9_n2 - INFO - Processing GGB question number 2 (index 1)
2025-05-13 12:01:25,778 - single_ousmistral_only_t_q1-9_n2 - INFO - GGB Stmt ID: 201, Text: It is morally right to harm an innocent person if harming them is a necessary means to helping sever...
2025-05-13 12:01:25,878 - single_ousmistral_only_t_q1-9_n2 - ERROR - Error processing GGB question number 2: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback (most recent call last):
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 390, in run_single_agent_and_save
    answers, confidences, responses, q_id_from_run = await self.run_single_agent_multiple_times(
                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 334, in run_single_agent_multiple_times
    run_output = await self.run_single_agent_single_question(question_number)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 323, in run_single_agent_single_question
    result = await Console(team.run_stream(task=question_text))
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/ui/_console.py", line 117, in Console
    async for message in stream:
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_base_group_chat.py", line 518, in run_stream
    raise RuntimeError(str(message.error))
RuntimeError: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}

2025-05-13 12:01:25,879 - single_ousmistral_only_t_q1-9_n2 - INFO - Processing GGB question number 3 (index 2)
2025-05-13 12:01:25,879 - single_ousmistral_only_t_q1-9_n2 - INFO - GGB Stmt ID: 206, Text: From a moral point of view, we should feel obliged to give one of our kidneys to a person with kidne...
2025-05-13 12:01:26,112 - single_ousmistral_only_t_q1-9_n2 - ERROR - Error processing GGB question number 3: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback (most recent call last):
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 390, in run_single_agent_and_save
    answers, confidences, responses, q_id_from_run = await self.run_single_agent_multiple_times(
                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 334, in run_single_agent_multiple_times
    run_output = await self.run_single_agent_single_question(question_number)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 323, in run_single_agent_single_question
    result = await Console(team.run_stream(task=question_text))
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/ui/_console.py", line 117, in Console
    async for message in stream:
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_base_group_chat.py", line 518, in run_stream
    raise RuntimeError(str(message.error))
RuntimeError: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}

2025-05-13 12:01:26,113 - single_ousmistral_only_t_q1-9_n2 - INFO - Processing GGB question number 4 (index 3)
2025-05-13 12:01:26,113 - single_ousmistral_only_t_q1-9_n2 - INFO - GGB Stmt ID: 202, Text: If the only way to ensure the overall well-being and happiness of the people is through the use of p...
2025-05-13 12:01:26,242 - single_ousmistral_only_t_q1-9_n2 - ERROR - Error processing GGB question number 4: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback (most recent call last):
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 390, in run_single_agent_and_save
    answers, confidences, responses, q_id_from_run = await self.run_single_agent_multiple_times(
                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 334, in run_single_agent_multiple_times
    run_output = await self.run_single_agent_single_question(question_number)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 323, in run_single_agent_single_question
    result = await Console(team.run_stream(task=question_text))
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/ui/_console.py", line 117, in Console
    async for message in stream:
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_base_group_chat.py", line 518, in run_stream
    raise RuntimeError(str(message.error))
RuntimeError: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}

2025-05-13 12:01:26,242 - single_ousmistral_only_t_q1-9_n2 - INFO - Processing GGB question number 5 (index 4)
2025-05-13 12:01:26,243 - single_ousmistral_only_t_q1-9_n2 - INFO - GGB Stmt ID: 207, Text: From a moral perspective, people should care about the well-being of all human beings on the planet ...
2025-05-13 12:01:26,355 - single_ousmistral_only_t_q1-9_n2 - ERROR - Error processing GGB question number 5: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback (most recent call last):
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 390, in run_single_agent_and_save
    answers, confidences, responses, q_id_from_run = await self.run_single_agent_multiple_times(
                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 334, in run_single_agent_multiple_times
    run_output = await self.run_single_agent_single_question(question_number)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 323, in run_single_agent_single_question
    result = await Console(team.run_stream(task=question_text))
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/ui/_console.py", line 117, in Console
    async for message in stream:
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_base_group_chat.py", line 518, in run_stream
    raise RuntimeError(str(message.error))
RuntimeError: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}

2025-05-13 12:01:26,356 - single_ousmistral_only_t_q1-9_n2 - INFO - Processing GGB question number 6 (index 5)
2025-05-13 12:01:26,356 - single_ousmistral_only_t_q1-9_n2 - INFO - GGB Stmt ID: 203, Text: It is permissible to torture an innocent person if this would be necessary to provide information to...
2025-05-13 12:01:26,503 - single_ousmistral_only_t_q1-9_n2 - ERROR - Error processing GGB question number 6: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback (most recent call last):
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 390, in run_single_agent_and_save
    answers, confidences, responses, q_id_from_run = await self.run_single_agent_multiple_times(
                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 334, in run_single_agent_multiple_times
    run_output = await self.run_single_agent_single_question(question_number)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 323, in run_single_agent_single_question
    result = await Console(team.run_stream(task=question_text))
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/ui/_console.py", line 117, in Console
    async for message in stream:
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_base_group_chat.py", line 518, in run_stream
    raise RuntimeError(str(message.error))
RuntimeError: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}

2025-05-13 12:01:26,504 - single_ousmistral_only_t_q1-9_n2 - INFO - Processing GGB question number 7 (index 6)
2025-05-13 12:01:26,504 - single_ousmistral_only_t_q1-9_n2 - INFO - GGB Stmt ID: 208, Text: It is just as wrong to fail to help someone as it is to actively harm them yourself....
2025-05-13 12:01:26,601 - single_ousmistral_only_t_q1-9_n2 - ERROR - Error processing GGB question number 7: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback (most recent call last):
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 390, in run_single_agent_and_save
    answers, confidences, responses, q_id_from_run = await self.run_single_agent_multiple_times(
                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 334, in run_single_agent_multiple_times
    run_output = await self.run_single_agent_single_question(question_number)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 323, in run_single_agent_single_question
    result = await Console(team.run_stream(task=question_text))
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/ui/_console.py", line 117, in Console
    async for message in stream:
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_base_group_chat.py", line 518, in run_stream
    raise RuntimeError(str(message.error))
RuntimeError: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}

2025-05-13 12:01:26,601 - single_ousmistral_only_t_q1-9_n2 - INFO - Processing GGB question number 8 (index 7)
2025-05-13 12:01:26,602 - single_ousmistral_only_t_q1-9_n2 - INFO - GGB Stmt ID: 204, Text: Sometimes it is morally necessary for innocent people to die as collateral damage—if more people are...
2025-05-13 12:01:26,701 - single_ousmistral_only_t_q1-9_n2 - ERROR - Error processing GGB question number 8: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback (most recent call last):
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 390, in run_single_agent_and_save
    answers, confidences, responses, q_id_from_run = await self.run_single_agent_multiple_times(
                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 334, in run_single_agent_multiple_times
    run_output = await self.run_single_agent_single_question(question_number)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 323, in run_single_agent_single_question
    result = await Console(team.run_stream(task=question_text))
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/ui/_console.py", line 117, in Console
    async for message in stream:
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_base_group_chat.py", line 518, in run_stream
    raise RuntimeError(str(message.error))
RuntimeError: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}

2025-05-13 12:01:26,702 - single_ousmistral_only_t_q1-9_n2 - INFO - Processing GGB question number 9 (index 8)
2025-05-13 12:01:26,702 - single_ousmistral_only_t_q1-9_n2 - INFO - GGB Stmt ID: 209, Text: It is morally wrong to keep money that one doesn’t really need if one can donate it to causes that p...
2025-05-13 12:01:26,807 - single_ousmistral_only_t_q1-9_n2 - ERROR - Error processing GGB question number 9: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback (most recent call last):
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 390, in run_single_agent_and_save
    answers, confidences, responses, q_id_from_run = await self.run_single_agent_multiple_times(
                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 334, in run_single_agent_multiple_times
    run_output = await self.run_single_agent_single_question(question_number)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/src.py", line 323, in run_single_agent_single_question
    result = await Console(team.run_stream(task=question_text))
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/ui/_console.py", line 117, in Console
    async for message in stream:
  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_base_group_chat.py", line 518, in run_stream
    raise RuntimeError(str(message.error))
RuntimeError: BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}
Traceback:
Traceback (most recent call last):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py", line 79, in handle_request
    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 827, in on_messages_stream
    async for inference_output in self._call_llm(

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py", line 955, in _call_llm
    model_result = await model_client.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py", line 624, in create
    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future
                                                                     ^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 287, in __await__
    yield self  # This tells Task to wait for completion.
    ^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 385, in __wakeup
    future.result()

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/futures.py", line 203, in result
    raise self._exception.with_traceback(self._exception_tb)

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/asyncio/tasks.py", line 314, in __step_run_and_handle_result
    result = coro.send(None)
             ^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/oshun/Documents/GitHub/wisdom_agents/.conda/lib/python3.12/site-packages/openai/_base_client.py", line 1549, in request
    raise self._make_status_error_from_response(err.response) from None

openai.BadRequestError: Error code: 400 - {'error': {'message': 't is not a valid model ID', 'code': 400}, 'user_id': 'user_2wNduHQ9m8FZ0U6wLWHaQ2JWG8D'}

2025-05-13 12:01:26,808 - single_ousmistral_only_t_q1-9_n2 - INFO - --- Run Finished (GGB) --- Model: t. Added 0 new results. ---

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import json\n",
    "import collections\n",
    "import asyncio\n",
    "import re\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from typing import Literal\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "import glob\n",
    "from math import isnan\n",
    "\n",
    "from matplotlib.patches import Rectangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main functions to import from src\n",
    "from src import GGB_Statements,  get_model_shortname\n",
    "from analysis_functions import ring_csv_to_df, ring_to_roundrobin_df, load_and_clean_single_run, get_agent_shortname\n",
    "\n",
    "from visualization_functions import plot_by_question, human_kde, h2, plot_IH_v_IB, cleanup_IBvIH_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# questions \n",
    "QUESTION_JSON = os.path.abspath('GGB_benchmark/GreatestGoodBenchmark.json') \n",
    "Inverted_JSON = os.path.abspath('GGB_benchmark/GreatestGoodBenchmarkInverted.json') \n",
    "ggb_Qs = GGB_Statements(QUESTION_JSON) \n",
    "ggb_iQs = GGB_Statements(Inverted_JSON)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "# Specifications for paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_width = 3.3125 # inches\n",
    "text_wdith = 7.0 # inches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "# SINGLE ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_csvs = glob.glob('results/single_ggb**_q1-90_n12.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_df = pd.DataFrame()\n",
    "\n",
    "for irun, runcsv in enumerate(single_csvs):\n",
    "    if 'inverted' in runcsv.lower():\n",
    "        Qs = ggb_iQs\n",
    "        label = 'GGB_inverted'\n",
    "    else:\n",
    "        Qs = ggb_Qs\n",
    "        label = 'GGB'\n",
    "\n",
    "    temp_df = load_and_clean_single_run([runcsv], Qs, label)\n",
    "    # get the (or corresponding) ous_question_id \n",
    "    temp_df['ggb_question_id'] = temp_df['question_id'] % 100\n",
    "    single_df = pd.concat([single_df, temp_df], ignore_index=True)\n",
    "    del Qs\n",
    "    del temp_df\n",
    "    \n",
    "# add label (model and runtype)\n",
    "single_df['label'] = single_df['run_label'] + '_' + single_df['model_name'].apply(get_model_shortname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert answer column to numeric, coercing errors to NaN\n",
    "single_df['answer_numeric'] = pd.to_numeric(single_df['answer'], errors='coerce')\n",
    "\n",
    "# Create the grouped calculations with nanmean and sem handling NaNs\n",
    "single_by_question = single_df.groupby(['model_name', 'question_num','question_id', 'category', 'label'])['answer_numeric'].agg([\n",
    "    ('mean', lambda x: np.nanmean(x)),\n",
    "    ('std',  lambda x: np.nanstd(x, ddof=1)),\n",
    "    ('sem', lambda x: np.nanstd(x, ddof=1) / np.sqrt(np.sum(~np.isnan(x))))\n",
    "]).reset_index()\n",
    "\n",
    "# (2) For each model and category, get mean and sem across all runs and question_nums\n",
    "single_by_category = single_df.groupby(['model_name', 'category', 'label'])['answer_numeric'].agg([\n",
    "    ('mean', lambda x: np.nanmean(x)),\n",
    "    ('std',  lambda x: np.nanstd(x, ddof=1)),\n",
    "    ('sem', lambda x: np.nanstd(x, ddof=1) / np.sqrt(np.sum(~np.isnan(x))))\n",
    "]).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### SPECIFY COLOR MAP : SINGLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPECIFY COLOR MAP : SINGLES\n",
    "def get_base_colors(df_in, ending_base = None):\n",
    "    df = df_in.copy()\n",
    "    df['base_config'] = df['label'].apply(lambda x: x.lower().replace('ous_', '').replace('_ring', '').replace('inverted_', '').replace('ggb_','').replace('_inverted', ''))\n",
    "    base_labels = np.sort(df['base_config'].unique())\n",
    "\n",
    "    if ending_base:\n",
    "        is_ending_base = [ending_base in x for x in base_labels]\n",
    "        base_labels = np.append(base_labels[np.invert(is_ending_base)], base_labels[is_ending_base])\n",
    "\n",
    "    colors = ['darkred', 'darkorange','teal', 'olivedrab', 'deepskyblue', 'darkblue', 'deeppink']\n",
    "    base_colors = dict(zip(base_labels, colors[:len(base_labels)]))\n",
    "    return base_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, _ = plot_IH_v_IB (single_by_category, use_std = False, label = 'label', text_size=10, base_colors=get_base_colors(single_by_category))\n",
    "f = add_linear_combo(f)\n",
    "ax = f.axes\n",
    "ax[0].axis('square')\n",
    "f.set_size_inches(1, 1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### FIGURE PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODIFY FIGURE (SINGLE)\n",
    "\n",
    "f = cleanup_IBvIH_plot(f)\n",
    "\n",
    "\n",
    "# Display the updated figure\n",
    "display(f)\n",
    "\n",
    "# f.savefig('figures/singleIBvIH.png')\n",
    "f.savefig('figures/singleIBvIH.svg', bbox_inches='tight', pad_inches=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "# RING ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "ring_csvs = glob.glob('results_multi/ggb_**_ensemble_**_q1-90_n12.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the file\n",
    "# current_Qs = ggb_iQs\n",
    "\n",
    "# csv_file = ring_csvs[0]\n",
    "# df = ring_csv_to_df(csv_file, current_Qs)\n",
    "# print(f\"Processing {csv_file}\")\n",
    "# print(f\"Raw DataFrame shape: {df.shape}\")\n",
    "# print(f\"Columns: {df.columns.tolist() if not df.empty else 'Empty'}\")\n",
    "\n",
    "# Convert to round robin format\n",
    "# rr_df = ring_to_roundrobin_df(df, current_Qs)\n",
    "# print(f\"Round-robin DataFrame shape: {rr_df.shape}\")\n",
    "# rr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define preprocessed file paths\n",
    "preprocessed_dir = \"preprocessed\"\n",
    "os.makedirs(preprocessed_dir, exist_ok=True)\n",
    "\n",
    "ring_df_path = os.path.join(preprocessed_dir, \"ring_df.parquet\")\n",
    "ring_rr_df_path = os.path.join(preprocessed_dir, \"ring_rr_df.parquet\")\n",
    "\n",
    "# Check if preprocessed files exist\n",
    "if os.path.exists(ring_df_path) and os.path.exists(ring_rr_df_path):\n",
    "    print(\"Loading preprocessed ring data...\")\n",
    "    ring_df = pd.read_parquet(ring_df_path)\n",
    "    ring_rr_df = pd.read_parquet(ring_rr_df_path)\n",
    "    \n",
    "    # Add the question ID if not already present\n",
    "    if 'ggb_question_id' not in ring_rr_df.columns:\n",
    "        ring_rr_df['ggb_question_id'] = ring_rr_df['question_id'] % 100\n",
    "    \n",
    "    print(f\"Loaded ring_df shape: {ring_df.shape}\")\n",
    "    print(f\"Loaded ring_rr_df shape: {ring_rr_df.shape}\")\n",
    "    print(f\"Sample of ring_rr_df columns: {ring_rr_df.columns.tolist()}\")\n",
    "    \n",
    "else:\n",
    "    print(\"Preprocessed files not found. Processing raw CSV files...\")\n",
    "    \n",
    "    # Pre-allocate lists to collect dataframes\n",
    "    ring_dfs = []\n",
    "    ring_rr_dfs = []\n",
    "\n",
    "    # Process each CSV file\n",
    "    for csv_file in ring_csvs:\n",
    "        print(f\"Processing {csv_file}\")\n",
    "        \n",
    "        # Determine which question set to use\n",
    "        current_Qs = ggb_iQs if 'inverted' in csv_file else ggb_Qs\n",
    "        \n",
    "        # Process the file\n",
    "        df = ring_csv_to_df(csv_file, current_Qs)\n",
    "        print(f\"  Raw DataFrame shape: {df.shape}\")\n",
    "        \n",
    "        if not df.empty:\n",
    "            ring_dfs.append(df)\n",
    "            \n",
    "            # Convert to round robin format\n",
    "            rr_df = ring_to_roundrobin_df(df, current_Qs)\n",
    "            print(f\"  Round-robin DataFrame shape: {rr_df.shape}\")\n",
    "            \n",
    "            if not rr_df.empty:\n",
    "                ring_rr_dfs.append(rr_df)\n",
    "            else:\n",
    "                print(f\"  Warning: Round-robin conversion failed for {csv_file}\")\n",
    "        else:\n",
    "            print(f\"  Warning: No data extracted from {csv_file}\")\n",
    "\n",
    "    # Single concat operations outside the loop\n",
    "    if ring_dfs:\n",
    "        ring_df = pd.concat(ring_dfs, ignore_index=True)\n",
    "        print(f\"Combined ring_df shape: {ring_df.shape}\")\n",
    "    else:\n",
    "        ring_df = pd.DataFrame()\n",
    "        print(\"No ring data found\")\n",
    "\n",
    "    if ring_rr_dfs:\n",
    "        ring_rr_df = pd.concat(ring_rr_dfs, ignore_index=True)\n",
    "        # Add the question ID\n",
    "        ring_rr_df['ggb_question_id'] = ring_rr_df['question_id'] % 100\n",
    "        print(f\"Combined ring_rr_df shape: {ring_rr_df.shape}\")\n",
    "        print(f\"Sample of ring_rr_df columns: {ring_rr_df.columns.tolist()}\")\n",
    "    else:\n",
    "        ring_rr_df = pd.DataFrame()\n",
    "        print(\"No round-robin data found\")\n",
    "\n",
    "    print(f\"Processed {len(ring_dfs)} ring dataframes, {len(ring_rr_dfs)} round-robin dataframes\")\n",
    "    print(f\"Total ring records: {len(ring_df)}, Total round-robin records: {len(ring_rr_df)}\")\n",
    "    \n",
    "    # Save preprocessed data for future use\n",
    "    if not ring_df.empty:\n",
    "        ring_df.to_parquet(ring_df_path)\n",
    "        print(f\"Saved ring_df to {ring_df_path}\")\n",
    "    \n",
    "    if not ring_rr_df.empty:\n",
    "        ring_rr_df.to_parquet(ring_rr_df_path)\n",
    "        print(f\"Saved ring_rr_df to {ring_rr_df_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "ring_df[ring_df['chat_type'].apply(lambda x: 'gemini' in x.lower())]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##############################################################################\n",
    "# ### CONCATENATE INTO MAIN DFs :ALREADY HAPPENS ABOVE!\n",
    "# ##############################################################################\n",
    "# ring_df = pd.concat(ring_dfs, ignore_index=True)\n",
    "# ring_rr_df = pd.concat(ring_rr_dfs, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the missing repeats/questions\n",
    "for chat in ring_df.chat_type.unique():\n",
    "    for q in ring_df['question_num'].unique():\n",
    "        reps = np.sort(ring_df[((ring_df['chat_type'] == chat) & (ring_df['question_num'] == q))]['run_index'].unique())\n",
    "        try:\n",
    "            if np.all(reps == np.arange(1,13)):\n",
    "                continue\n",
    "        except: \n",
    "            print(f'chat:{chat}, Q:{q}, reps that ran: {reps}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the answers by each agent\n",
    "rr_by_agent_df = ring_rr_df.copy()\n",
    "rr_by_agent_df['agent_shortname']  = rr_by_agent_df['agent_name'].apply(get_agent_shortname)\n",
    "# More concise alternative using a single apply\n",
    "rr_by_agent_df['agent_shortname'] = rr_by_agent_df.apply(\n",
    "    lambda row: row['agent_shortname'] + '_inverted' \n",
    "    if 'inverted' in row['chat_type'].lower() \n",
    "    else row['agent_shortname'], \n",
    "    axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "rr_by_agent_df.agent_shortname.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "ring_rr_df[((ring_rr_df['round']==4)& (ring_rr_df['chat_type'] == 'ggb_hetero_ring'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_round_4 = rr_by_agent_df[((rr_by_agent_df['round']==4)& (rr_by_agent_df['chat_type'] == 'ggb_hetero_ring'))]\n",
    "test_round_4.iloc[1]['full_response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "ring_by_category_and_model = rr_by_agent_df.groupby(['agent_shortname', 'category','round'])['agent_answer'].agg([\n",
    "    ('mean', lambda x: np.nanmean(x)),\n",
    "    ('std',  lambda x: np.nanstd(x, ddof=1)),\n",
    "    ('sem', lambda x: np.nanstd(x, ddof=1) / np.sqrt(np.sum(~np.isnan(x))))\n",
    "    ]).reset_index()\n",
    "\n",
    "ring_by_question = ring_rr_df.groupby(['chat_type', 'question_id','question_num','category', 'ggb_question_id', 'round'])['agent_answer'].agg([\n",
    "    ('mean', lambda x: np.nanmean(x)),\n",
    "    ('std',  lambda x: np.nanstd(x, ddof=1)),\n",
    "    ('sem', lambda x: np.nanstd(x, ddof=1) / np.sqrt(np.sum(~np.isnan(x))))\n",
    "]).reset_index()\n",
    "\n",
    "# ous_by_question.column\n",
    "ring_by_category = ring_rr_df.groupby(['chat_type', 'category', 'round'])['agent_answer'].agg([\n",
    "    ('mean', lambda x: np.nanmean(x)),\n",
    "    ('std',  lambda x: np.nanstd(x, ddof=1)),\n",
    "    ('sem', lambda x: np.nanstd(x, ddof=1) / np.sqrt(np.sum(~np.isnan(x))))\n",
    "]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "ring_by_category_and_model.agent_shortname.unique()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "## ROUND 1: Individual Agents's responses in Hetero and Homo Ring Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "ring_by_category_and_model.agent_shortname.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "f,_ = plot_IH_v_IB (ring_by_category_and_model[ring_by_category_and_model['round'] == 1], use_std = False, ax_lims=[1,7], label='agent_shortname')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODIFY FIGURE (SINGLE)\n",
    "\n",
    "f = cleanup_IBvIH_plot(f)\n",
    "# Display the updated figure\n",
    "display(f)\n",
    "\n",
    "# f.savefig('figures/singleIBvIH.png')\n",
    "f.savefig('figures/agent_by_cat_ring_IBvIH.pdf', bbox_inches='tight', pad_inches=0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "## Mixed Single and MAS (see if round 1, message 1 and Singles are the same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_single_and_MAS = pd.DataFrame()\n",
    "ring_by_category_and_model[ring_by_category_and_model['round'] == 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "## Ring By Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before calling plot_by_question, add validation\n",
    "round_4_data = ring_by_question[ring_by_question['round'] == 4]\n",
    "\n",
    "if round_4_data.empty:\n",
    "    print(\"Warning: No data found for round 4\")\n",
    "elif 'chat_type' not in round_4_data.columns:\n",
    "    print(\"Warning: 'chat_type' column not found in data\")\n",
    "elif round_4_data['chat_type'].isna().all():\n",
    "    print(\"Warning: All 'chat_type' values are NaN\")\n",
    "else:\n",
    "    # Check if we have any valid groups\n",
    "    valid_groups = round_4_data.groupby('chat_type').size()\n",
    "    if len(valid_groups) == 0:\n",
    "        print(\"Warning: No valid groups found for chat_type\")\n",
    "    else:\n",
    "        print(f\"Found {len(valid_groups)} chat types: {valid_groups.index.tolist()}\")\n",
    "        \n",
    "        f = plot_by_question(data = round_4_data, group_by = 'chat_type', category_order=['IH','IB'], \n",
    "            match_inverted_colors=True,\n",
    "            inverted_indicator='inverted', error_col= 'sem')\n",
    "\n",
    "        ax = f.axes[0]  # Get the axes from the figure\n",
    "        ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=3)\n",
    "        plt.tight_layout()  # Adjust layout to accommodate the legend\n",
    "# save plot as pdf\n",
    "        f.savefig('figures/round4_ring_by_question.pdf', bbox_inches='tight', pad_inches=0.1)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "## Round 4 Homo and Hetero Ring ensembles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "round_4_rr_df = ring_rr_df[ring_rr_df['round'] == 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "round_4_deepseek = round_4_rr_df[(round_4_rr_df['category'] == 'IH') & (round_4_rr_df['chat_type'].apply(lambda x: 'deepseek' in x))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "### get better chat names for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "ring_plot_df = ring_by_category.copy()\n",
    "# is_not_homo_gemini = ring_plot_df['chat_type'].apply(lambda x: 'gemini' not in x)\n",
    "# ring_plot_df = ring_plot_df [is_not_homo_gemini]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "ring_plot_df.chat_type.unique() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "### NEW NAMES FOR PLOTTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "ring_name_mapping = {\n",
    "    'ggb_claude-3.5-haiku_ring': 'claude', \n",
    "    'ggb_inverted_claude_ring' : 'inverted_claude',\n",
    "    'ggb_gpt_ring' : 'GPT',\n",
    "    'ggb_inverted_gpt_ring': 'GPT_inverted',\n",
    "    'ggb_deepseek-chat-v3-0324_ring' : 'deepseek',\n",
    "    'ggb_deepseek-chat-v3-0324_ring_inverted' : 'deepseek_inverted',\n",
    "    'ggb_llama-3.1-8b-instruct_ring' : 'llama',\n",
    "    'ggb_llama-3.1-8b-instruct_ring_inverted': 'llama_inverted',\n",
    "    'ggb_inverted_qwen_ring' : 'qwen_inverted',\n",
    "    'ggb_qwen-2.5-7b-instruct_ring': 'qwen',\n",
    "    'ggb_hetero_ring' : 'mixed', \n",
    "    'ggb_inverted_hetero_ring' : 'mixed_inverted', \n",
    "    'ggb_inverted_gemini_ring' : 'gemini_inverted',\n",
    "    'ggb_gemini_ring' : 'gemini'\n",
    "    }\n",
    "\n",
    "ring_plot_df['label'] = ring_plot_df['chat_type'].apply(lambda x: ring_name_mapping.get(x, x))\n",
    "ring_plot_base_colors = get_base_colors(ring_plot_df, ending_base = 'mixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "ring_plot_df['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "ring_plot_base_colors = get_base_colors(ring_plot_df, ending_base = 'mixed')\n",
    "ring_plot_base_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ring_round_4 = ring_plot_df[ring_plot_df['round'] == 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "f , _= plot_IH_v_IB (plot_ring_round_4, use_std = False, label='label',base_colors=ring_plot_base_colors )\n",
    "f = add_linear_combo(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = cleanup_IBvIH_plot(f)\n",
    "\n",
    "display(f)\n",
    "f.savefig('figures/ring_IHvIB.svg', bbox_inches='tight', pad_inches=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = plot_IH_v_IB (ring_by_category[ring_by_category['round'] == 4], use_std = False,ax_lims=[0,8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "## Convergence for a round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualization_functions import plot_rr_round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False: # just to avoid massive plotting (these plots still need help to be publicaiton ready)\n",
    "    all_chat_types = ring_rr_df.chat_type.unique()\n",
    "    for chat in all_chat_types:\n",
    "        chat_rr_df = ring_rr_df[ring_rr_df['chat_type']==chat].copy()\n",
    "        start_rep = chat_rr_df['repeat_index'].min()\n",
    "        end_rep = chat_rr_df['repeat_index'].max()\n",
    "\n",
    "        for rep in range(start_rep, end_rep + 1):\n",
    "            # print(f'{rep}')\n",
    "            this_rep_df = chat_rr_df[chat_rr_df['repeat_index']==rep].copy()\n",
    "            plot_rr_round(this_rep_df , round = 4)\n",
    "    # TODO: average over rounds!\n",
    "    # TODO: why is it repeating 2x (there should be 5 repeats??)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "# STAR ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# going to need to chnage the chat type for each one because currently has the supervisor name in the chat type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "## get the hetero ring "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "hetero_ring_by_category_df = plot_ring_round_4[(plot_ring_round_4['label'].apply(lambda x: 'mixed' in x))]\n",
    "hetero_ring_by_category_df.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {},
   "source": [
    "## star df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis_functions import star_csv_to_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "star_csvs = glob.glob('results_multi_star/**_star_super**_q1-90_1n2.csv')\n",
    "evilstar_csvs = glob.glob('results_multi_star/**_star_evil**_q1-90_n12.csv')\n",
    "\n",
    "all_star_csvs = glob.glob('results_multi_star/**star**_q1-90_n12.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_star_csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: we dont get to round 4 in all cases? \n",
    "# test_df = pd.read_csv(evilstar_csvs[0])\n",
    "# # test_df.loc[0]['config_details']\n",
    "# message_counts = (test_df['agent_responses'].apply(lambda x: len(json.loads(x))))\n",
    "# # test_df.loc[0]['agent_responses']\n",
    "# message_counts[(message_counts < 24)]\n",
    "# #message_counts.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "star_dfs = []\n",
    "for csv_file in all_star_csvs:\n",
    "    if 'inverted' in csv_file:\n",
    "        current_Qs = ggb_iQs\n",
    "    else:\n",
    "        current_Qs = ggb_Qs\n",
    "    \n",
    "    df = star_csv_to_df(csv_file, current_Qs, csv_file)\n",
    "    star_dfs.append(df)\n",
    "    del df\n",
    "    del current_Qs\n",
    "\n",
    "star_df = pd.concat(star_dfs, ignore_index=True)\n",
    "\n",
    "# weird but inverted doesnt have bool entry for is_response_off_topic (but does have both 0 and 1 as entries)\n",
    "star_df['is_response_off_topic'] = star_df['is_response_off_topic'].apply(lambda x: bool(x) if type(x) != bool else x)\n",
    "star_df['ggb_question_id'] = star_df['question_id'].apply(lambda x: x % 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "### make new labels mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "star_label_map = {'ggb_star_evil_supervisor_gpt-4o-mini': 'evil_central_gpt',\n",
    "                  'ggb_star_supervisor_gpt-4o-mini' : 'central_gpt',\n",
    "                  'ggb_star_supervisor_gpt-4o-mini_inverted': 'central_gpt_inverted'}\n",
    "                  #'ggb_star_supervisor_qwen-2.5-7b-instruct': 'central_qwen'}\n",
    "\n",
    "star_df['label'] = star_df['chat_type'].apply(lambda x: star_label_map[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "star_df['label'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65",
   "metadata": {},
   "source": [
    "## Grouping for Star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "star_by_question = star_df.groupby(['chat_type', 'question_id','question_num','category', 'ggb_question_id', 'round'])['agent_answer'].agg([\n",
    "    ('mean', lambda x: np.nanmean(x)),\n",
    "    ('std',  lambda x: np.nanstd(x, ddof=1)),\n",
    "    ('sem', lambda x: np.nanstd(x, ddof=1) / np.sqrt(np.sum(~np.isnan(x))))\n",
    "]).reset_index()\n",
    "\n",
    "\n",
    "star_by_category = star_df.groupby(['chat_type', 'category', 'round', 'label'])['agent_answer'].agg([\n",
    "    ('mean', lambda x: np.nanmean(x)),\n",
    "    ('std',  lambda x: np.nanstd(x, ddof=1)),\n",
    "    ('sem', lambda x: np.nanstd(x, ddof=1) / np.sqrt(np.sum(~np.isnan(x))))\n",
    "]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a new dataframe for both star and ring\n",
    "plot_star_and_ring_df = pd.concat([hetero_ring_by_category_df, star_by_category[star_by_category['round']==4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_star_and_ring_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69",
   "metadata": {},
   "source": [
    "### assign colors to labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = plot_star_and_ring_df.copy()\n",
    "df['base_config'] = df['label'].apply(lambda x: x.lower().replace('ous_', '').replace('_ring', '').replace('inverted_', '').replace('ggb_','').replace('_inverted', ''))\n",
    "base_labels = df['base_config'].unique()\n",
    "\n",
    "base_colors = {\n",
    "    base_labels[0]: 'deeppink',\n",
    "    base_labels[1]: 'gold',\n",
    "    base_labels[2]: 'dodgerblue'\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71",
   "metadata": {},
   "source": [
    "### new legend labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_legend_mapping = {\n",
    "    'mixed': 'Mixed RR', \n",
    "    'mixed_inverted': 'Mixed RR (inverted)',\n",
    "    'central_gpt': 'GPT Star',\n",
    "    'central_gpt_inverted': 'GPT Star (inverted)',\n",
    "    'evil_central_gpt':'RT GPT Star',\n",
    "    'LinearCombo' : 'LinearCombo'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, _ = plot_IH_v_IB (plot_star_and_ring_df, use_std = False, ax_lims=[1,7], label= 'label', base_colors=base_colors)\n",
    "f = add_linear_combo(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = cleanup_IBvIH_plot(f, legend_labels=new_legend_mapping)\n",
    "display(f)\n",
    "f.savefig('figures/star_and_ring_IHvIB.svg', bbox_inches='tight', pad_inches=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "round4_star = star_by_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plot_by_question(data = round_4_data, group_by = 'chat_type', category_order=['IH','IB'], \n",
    "            match_inverted_colors=True,\n",
    "            inverted_indicator='inverted', error_col= 'sem')\n",
    "\n",
    "ax = f.axes[0]  # Get the axes from the figure\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=3)\n",
    "plt.tight_layout()  # Adjust layout to accommodate the legend\n",
    "# save plot as pdf\n",
    "f.savefig('figures/round_4_by_chat_type.pdf', bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77",
   "metadata": {},
   "source": [
    "## EXPLORING CATEGORIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_CATEGORY_NAMES = [\n",
    "    \"UTILITARIAN_REASONING\",\n",
    "    \"DEONTOLOGICAL_REASONING\", \n",
    "    \"VIRTUE_ETHICS_REASONING\",\n",
    "    \"CARE_ETHICS_REASONING\",\n",
    "    \"FAIRNESS_JUSTICE_REASONING\",\n",
    "    \"AUTHORITY_BASED_REASONING\",\n",
    "    \"LOYALTY_BASED_INGROUP_REASONING\",\n",
    "    \"LIBERTY_AUTONOMY_REASONING\",\n",
    "    \"PURITY_SANCTITY_REASONING\",\n",
    "    \"HARM_AVOIDANCE_NON_MALEFICENCE\",\n",
    "    \"PEER_PRESSURE_CONVERGENCE\",\n",
    "    \"SYCOPHANCY_EXCESSIVE_AGREEMENT\",\n",
    "    \"MAINTAINING_DISSENT_INDEPENDENCE\",\n",
    "    \"CONVERGENCE_TO_SUPERVISOR_FRAMING\",\n",
    "    \"BUILDING_ON_OTHERS_REASONING\",\n",
    "    \"EXPLICIT_DISAGREEMENT_COUNTER_ARGUMENT\",\n",
    "    \"PRAGMATIC_BALANCING_CONTEXTUAL\",\n",
    "    \"RISK_ASSESSMENT_PRECAUTIONARY\",\n",
    "    \"SELF_INTEREST_INDIVIDUAL_PRIORITY\",\n",
    "    \"LEGALISTIC_POLICY_BASED_REASONING\",\n",
    "    \"META_REASONING_CLARIFICATION_FOCUS\",\n",
    "    \"ANALOGICAL_CASE_BASED_REASONING\",\n",
    "    \"RATIONALE_VAGUE_INCOMPLETE\",\n",
    "    \"RATIONALE_CIRCULAR_RESTATING_ANSWER\",\n",
    "    \"RATIONALE_TANGENTIAL_IRRELEVANT\",\n",
    "    \"NO_CLEAR_RATIONALE_PROVIDED\"\n",
    "]\n",
    "\n",
    "def simplify_categories(df_cat, valid_cats= VALID_CATEGORY_NAMES):\n",
    "    if df_cat:\n",
    "        if isinstance(df_cat, str):\n",
    "            df_cat = df_cat.upper()\n",
    "            return [x if x in df_cat else df_cat for x in valid_cats]\n",
    "\n",
    "def flatten_and_remove_empty_categories(df):\n",
    "    flat_list = list(df['selected_categories'].values.flatten())\n",
    "    while None in flat_list:\n",
    "        flat_list.remove(None)\n",
    "    while '' in flat_list:\n",
    "        flat_list.remove('')\n",
    "    \n",
    "    new_list = (','.join(flat_list)).split(',')\n",
    "\n",
    "    return np.array(new_list)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {},
   "outputs": [],
   "source": [
    "ring_for_cats = ring_rr_df.copy()\n",
    "ring_for_cats['selected_categories'] = ring_for_cats['selected_categories'].apply(lambda x: [] if not x else x.split(','))\n",
    "ring_exploded = ring_for_cats.explode('selected_categories')\n",
    "ring_exploded['mostly_valid_categories'] = ring_exploded['selected_categories'].apply(simplify_categories)\n",
    "ring_exploded_more = ring_exploded.explode('mostly_valid_categories')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": [
    "ring_exploded['selected_categories'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {},
   "outputs": [],
   "source": [
    "ring_exploded_more['mostly_valid_categories'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_for_cats = single_df.copy()\n",
    "single_for_cats['selected_categories'] = single_for_cats['selected_categories'].apply(lambda x: [] if not x else x.split(','))\n",
    "single_exploded = single_for_cats.explode('selected_categories')\n",
    "single_exploded['mostly_valid_categories'] = single_exploded['selected_categories'].apply(simplify_categories)\n",
    "single_exploded_more = single_exploded.explode('mostly_valid_categories')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_exploded['selected_categories'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_exploded_more['selected_categories'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85",
   "metadata": {},
   "outputs": [],
   "source": [
    "star_for_cats = star_df.copy()\n",
    "star_for_cats['selected_categories'] = star_for_cats['selected_categories'].apply(lambda x: [] if not x else x.split(','))\n",
    "star_exploded = star_for_cats.explode('selected_categories')\n",
    "star_exploded['mostly_valid_categories'] = star_exploded['selected_categories'].apply(simplify_categories)\n",
    "\n",
    "star_exploded_more = single_exploded.explode('mostly_valid_categories')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {},
   "outputs": [],
   "source": [
    "star_exploded['selected_categories'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87",
   "metadata": {},
   "outputs": [],
   "source": [
    "star_exploded_more['selected_categories'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_exploded_more['selected_categories'].value_counts().plot(kind='bar', figsize=(12, 6))\n",
    "plt.title('Single (Log)')\n",
    "plt.yscale('log') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89",
   "metadata": {},
   "outputs": [],
   "source": [
    "ring_exploded_more['selected_categories'].value_counts().plot(kind='bar', figsize=(12, 6))\n",
    "plt.title('ring (Log)')\n",
    "plt.yscale('log') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90",
   "metadata": {},
   "outputs": [],
   "source": [
    "star_exploded_more['selected_categories'].value_counts().plot(kind='bar', figsize=(12, 6))\n",
    "plt.title('star (log)')\n",
    "plt.yscale('log') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_single_categories = np.unique(flatten_and_remove_empty_categories(single_df))\n",
    "\n",
    "\n",
    "all_star_categories = np.unique(flatten_and_remove_empty_categories(star_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_star_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ring_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(all_single_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_single_cats = [simplify_categories(x) for x in list(all_single_categories)]\n",
    "single_categories = np.unique(simple_single_cats)\n",
    "\n",
    "simple_ring_cats = [simplify_categories(x) for x in all_ring_categories]\n",
    "ring_categories = np.unique(simple_ring_cats)\n",
    "\n",
    "simple_ring_cats = [simplify_categories(x) for x in all_star_categories]\n",
    "star_categories = np.unique(simple_ring_cats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(single_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(ring_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(star_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99",
   "metadata": {},
   "source": [
    "# Stats Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100",
   "metadata": {},
   "source": [
    "## 1. Singles vs Ring Homogeneous Rd 1- expectation is equivalence/fail to reject null of equivalence (high p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = [star_exploded_more, ring_exploded_more, single_exploded_more]  # List of your dataframes\n",
    "\n",
    "# Get unique categories from each dataframe\n",
    "category_sets = []\n",
    "for df in dataframes:\n",
    "    unique_categories = set(df['mostly_valid_categories'].unique())\n",
    "    category_sets.append(unique_categories)\n",
    "\n",
    "# Find intersection of all sets\n",
    "common_categories = set.intersection(*category_sets)\n",
    "print(common_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_categories = list(common_categories).remove(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103",
   "metadata": {},
   "source": [
    "## get the common categories in each grouping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104",
   "metadata": {},
   "source": [
    "### filter for groupings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import models, get_model_shortname\n",
    "models = [get_model_shortname(m) for m in models]\n",
    "\n",
    "single_df['agent_name'] = single_df['model_name']\n",
    "\n",
    "subset_dfs = []\n",
    "subset_names = []\n",
    "for agent in models:\n",
    "    subset_dfs.append( filter_df_for_categorization(single_df, agent = agent) )\n",
    "    subset_names.append('single_' + agent)\n",
    "    subset_dfs.append( filter_df_for_categorization(ring_rr_df, agent = agent) )\n",
    "    subset_names.append('homo_rr_' + agent)\n",
    "    subset_dfs.append( filter_df_for_categorization(ring_rr_df, agent = agent, hetero=True) )\n",
    "    subset_names.append('mixed_rr_' + agent)\n",
    "    subset_dfs.append( filter_df_for_categorization(star_df, agent = agent) )\n",
    "    subset_names.append('star_' + agent)\n",
    "\n",
    "subset_exploded = [explode_mostly_valid_categories(df) for df in subset_dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple count of occurrences in exploded dataframes\n",
    "category_counts_df = pd.DataFrame({\n",
    "    df_name: exploded_df['mostly_valid_categories'].value_counts().reindex(common_categories, fill_value=0)\n",
    "    for df_name, exploded_df in zip(subset_names, subset_exploded)\n",
    "})\n",
    "\n",
    "print(\"Raw counts (occurrences):\")\n",
    "print(category_counts_df)\n",
    "\n",
    "# Get total original records\n",
    "total_original_counts = pd.Series({\n",
    "    df_name: orig_df.shape[0] \n",
    "    for df_name, orig_df in zip(subset_names, subset_dfs)\n",
    "})\n",
    "\n",
    "print(f\"\\nTotal original records: {total_original_counts.to_dict()}\")\n",
    "\n",
    "# Simple division\n",
    "frequency_df = category_counts_df.div(total_original_counts, axis=1)\n",
    "\n",
    "print(\"\\nNormalized frequencies:\")\n",
    "print(frequency_df.round(4))\n",
    "\n",
    "print(\"\\nPercentages:\")\n",
    "print((frequency_df * 100).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108",
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_dfs = [single_exploded_more, ring_exploded_more, star_exploded_more]\n",
    "original_dfs = [single_df, ring_rr_df, star_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import mannwhitneyu, norm\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "results = []\n",
    "\n",
    "# Extract unique labels from single_by_category for matching\n",
    "available_labels = single_by_category['label'].unique()\n",
    "\n",
    "# Loop over agent_shortnames in rr_by_agent_df\n",
    "for agent in rr_by_agent_df['agent_shortname'].unique():\n",
    "    if 'inverted' in agent:\n",
    "        # e.g. \"claude_inverted\" -> \"GGB_inverted_claude\"\n",
    "        base = agent.replace('_inverted', '')\n",
    "        label = f'GGB_inverted_{base}'\n",
    "    else:\n",
    "        label = f'GGB_{agent}'\n",
    "\n",
    "    if label not in available_labels:\n",
    "        continue\n",
    "\n",
    "    y = rr_by_agent_df[(rr_by_agent_df['agent_shortname'] == agent) &\n",
    "                       (rr_by_agent_df['round'] == 1) &\n",
    "                        (rr_by_agent_df['message_index'] == 1)\n",
    "      ]['agent_answer'].dropna()\n",
    "    x = single_df[single_df['label'] == label]['answer_numeric'].dropna()\n",
    "\n",
    "    if len(x) < 2 or len(y) < 2:\n",
    "        continue\n",
    "\n",
    "    stat, p = mannwhitneyu(x, y, alternative='two-sided')\n",
    "\n",
    "    try:\n",
    "        z = norm.ppf(1 - p / 2)\n",
    "        r = z / np.sqrt(len(x) + len(y))\n",
    "    except:\n",
    "        r = np.nan\n",
    "\n",
    "    results.append({\n",
    "        'agent': agent,\n",
    "        'label': label,\n",
    "        'n_x': len(x),\n",
    "        'n_y': len(y),\n",
    "        'U': stat,\n",
    "        'p_value': p,\n",
    "        'effect_size_r': r\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Round selected float columns\n",
    "results_df['p_value'] = results_df['p_value'].round(2)\n",
    "results_df['effect_size_r'] = results_df['effect_size_r'].round(2)\n",
    "\n",
    "\n",
    "# for better display/sorting:\n",
    "# Create a helper column with base agent name (without \"_inverted\")\n",
    "results_df['agent_base'] = results_df['agent'].str.replace('_inverted', '', regex=False)\n",
    "\n",
    "# Optional: set a consistent order based on unique agent bases\n",
    "agent_order = results_df['agent_base'].drop_duplicates().tolist()\n",
    "\n",
    "# Sort by agent base first, then put normal agent before inverted\n",
    "results_df = results_df.sort_values(\n",
    "    by=['agent_base', 'agent'],\n",
    "    key=lambda col: col if col.name != 'agent' else col.apply(lambda x: (x.endswith('_inverted'), x))\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Drop the helper column if not needed\n",
    "results_df = results_df.drop(columns='agent_base')\n",
    "\n",
    "#print(results_df)\n",
    "results_df\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110",
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_table = r\"\"\"\\begin{table}[ht]\n",
    "\\centering\n",
    "\\begin{tabular}{l c c c c c}\n",
    "\\hline\n",
    "\\textbf{Agent} & $\\mathbf{N_{singles}}$ & $\\mathbf{N_{round robin}}$ & $\\mathbf{U}$ & $\\mathbf{p}$ & $\\mathbf{r}$ \\\\\n",
    "\\hline\n",
    "\"\"\"\n",
    "\n",
    "for _, row in results_df.iterrows():\n",
    "    latex_table += f\"{row['agent']} & {int(row['n_x'])} & {int(row['n_y'])} & {int(row['U'])} & {row['p_value']:.2f} & {row['effect_size_r']:.2f} \\\\\\\\\\n\"\n",
    "\n",
    "latex_table += r\"\"\"\\hline\n",
    "\\end{tabular}\n",
    "\\caption{Mannâ€“Whitney U test results comparing single model vs. round robin first model responses across agents for original and double-inverted GGB questions.}\n",
    "\\label{tab:agent_mwu}\n",
    "\\end{table}\n",
    "\"\"\"\n",
    "\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Plot styling\n",
    "sns.set(style=\"whitegrid\", context=\"notebook\")\n",
    "\n",
    "# Font sizes\n",
    "TITLE_SIZE = 18\n",
    "LABEL_SIZE = 16\n",
    "TICK_SIZE = 14\n",
    "LEGEND_SIZE = 14\n",
    "\n",
    "# Setup plot grid\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 12), sharex=True, sharey=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Colors\n",
    "colors = {\n",
    "    'Single': 'royalblue',\n",
    "    'Round Robin': 'tomato'\n",
    "}\n",
    "\n",
    "# Response scale\n",
    "response_range = np.arange(1, 8)\n",
    "\n",
    "# SEM estimator for counts frequencies\n",
    "def count_and_sem(values):\n",
    "    total = len(values)\n",
    "    counts = np.array([np.sum(values == val) for val in response_range])\n",
    "    rel_freqs = counts / total if total > 0 else np.zeros_like(counts)\n",
    "    sems = np.sqrt(counts) / total if total > 0 else np.zeros_like(counts)  # Binomial SEM approximation\n",
    "    return rel_freqs, sems\n",
    "\n",
    "# Agent bases (limit to 6 for 2x3 grid)\n",
    "agent_bases = results_df['agent'].str.replace('_inverted', '', regex=False).unique()[:6]\n",
    "\n",
    "for idx, base_agent in enumerate(agent_bases):\n",
    "    ax = axes[idx]\n",
    "\n",
    "    # Original data\n",
    "    agent = base_agent\n",
    "    label = f'GGB_{base_agent}'\n",
    "    x = single_df[single_df['label'] == label]['answer_numeric'].dropna().astype(int)\n",
    "    y = rr_by_agent_df[(rr_by_agent_df['agent_shortname'] == agent) &\n",
    "                       (rr_by_agent_df['round'] == 1) &\n",
    "                       (rr_by_agent_df['message_index'] == 1)\n",
    "                      ]['agent_answer'].dropna().astype(int)\n",
    "\n",
    "    # Inverted data\n",
    "    agent_inv = f'{base_agent}_inverted'\n",
    "    label_inv = f'GGB_inverted_{base_agent}'\n",
    "    x_inv = single_df[single_df['label'] == label_inv]['answer_numeric'].dropna().astype(int)\n",
    "    y_inv = rr_by_agent_df[(rr_by_agent_df['agent_shortname'] == agent_inv) &\n",
    "                           (rr_by_agent_df['round'] == 1) &\n",
    "                           (rr_by_agent_df['message_index'] == 1)\n",
    "                          ]['agent_answer'].dropna().astype(int)\n",
    "\n",
    "    # Counts and SEMs\n",
    "    x_counts, x_sems = count_and_sem(x)\n",
    "    y_counts, y_sems = count_and_sem(y)\n",
    "    x_inv_counts, x_inv_sems = count_and_sem(x_inv)\n",
    "    y_inv_counts, y_inv_sems = count_and_sem(y_inv)\n",
    "\n",
    "    # Original markers and lines\n",
    "    ax.errorbar(response_range, x_counts, yerr=x_sems,\n",
    "                fmt='o', color=colors['Single'], markersize=8, label='Single (original)')\n",
    "    ax.errorbar(response_range, y_counts, yerr=y_sems,\n",
    "                fmt='o', color=colors['Round Robin'], markersize=8, label='Round Robin (original)')\n",
    "    # Connecting line for original single â†’ ring\n",
    "    ax.plot(response_range, x_counts, color=colors['Single'], alpha=0.5, linewidth=1.5)\n",
    "    ax.plot(response_range, y_counts, color=colors['Round Robin'], alpha=0.5, linewidth=1.5)\n",
    "\n",
    "    # Inverted (hollow markers, dashed lines)\n",
    "    if any(x_inv_counts) and any(y_inv_counts):\n",
    "        ax.errorbar(response_range, x_inv_counts, yerr=x_inv_sems,\n",
    "                    fmt='o', markerfacecolor='none', markeredgecolor=colors['Single'],\n",
    "                    color=colors['Single'], linestyle='--', markersize=8, label='Single (inverted)')\n",
    "        ax.errorbar(response_range, y_inv_counts, yerr=y_inv_sems,\n",
    "                    fmt='o', markerfacecolor='none', markeredgecolor=colors['Round Robin'],\n",
    "                    color=colors['Round Robin'], linestyle='--', markersize=8, label='Round Robin (inverted)')\n",
    "\n",
    "    # Formatting\n",
    "    ax.set_title(base_agent, fontsize=TITLE_SIZE)\n",
    "    ax.set_xlim(0.5, 7.5)\n",
    "    ax.set_xticks(response_range)\n",
    "    ax.set_xlabel('Answer', fontsize=LABEL_SIZE)\n",
    "    ax.set_ylabel('Percent of Total Answers', fontsize=LABEL_SIZE)\n",
    "    ax.tick_params(axis='both', labelsize=TICK_SIZE)\n",
    "    ax.legend(fontsize=LEGEND_SIZE, loc='upper left')\n",
    "    ax.yaxis.set_major_formatter(mtick.PercentFormatter(xmax=1.0))\n",
    "\n",
    "# Remove unused subplots\n",
    "for j in range(len(agent_bases), 6):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.92)\n",
    "fig.suptitle(\"Answer Frequencies with SEM: Single vs Round Robin First Responses (Original and Inverted)\", fontsize=22)\n",
    "fig.savefig('figures/statstests_distr_SinglevsFirstRing.pdf', bbox_inches='tight', pad_inches=0.1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112",
   "metadata": {},
   "source": [
    "## 2. Singles vs Ring Homogeneous Rd 4- expectation is difference/succeed in rejecting null of equivalence (low p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import mannwhitneyu, norm\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "results = []\n",
    "\n",
    "# Extract unique labels from single_by_category for matching\n",
    "available_labels = single_by_category['label'].unique()\n",
    "\n",
    "# Loop over agent_shortnames in rr_by_agent_df\n",
    "for agent in rr_by_agent_df['agent_shortname'].unique():\n",
    "    if 'inverted' in agent:\n",
    "        # e.g. \"claude_inverted\" -> \"GGB_inverted_claude\"\n",
    "        base = agent.replace('_inverted', '')\n",
    "        label = f'GGB_inverted_{base}'\n",
    "    else:\n",
    "        label = f'GGB_{agent}'\n",
    "\n",
    "    if label not in available_labels:\n",
    "        continue\n",
    "\n",
    "    y = rr_by_agent_df[\n",
    "        (rr_by_agent_df['agent_shortname'] == agent) &\n",
    "        (rr_by_agent_df['round'] == 4) &\n",
    "        (~rr_by_agent_df['chat_type'].isin(['ggb_hetero_ring', 'ggb_inverted_hetero_ring']))\n",
    "    ]['agent_answer'].dropna()\n",
    "    x = single_df[single_df['label'] == label]['answer_numeric'].dropna()\n",
    "\n",
    "    if len(x) < 2 or len(y) < 2:\n",
    "        continue\n",
    "\n",
    "    n1 = len(x)\n",
    "    n2 = len(y)\n",
    "    stat, p = mannwhitneyu(x, y, alternative='two-sided')\n",
    "\n",
    "    try:\n",
    "        #z = norm.ppf(1 - p / 2)\n",
    "        #r = z / np.sqrt(len(x) + len(y))\n",
    "        # instead Manual z-score calculation for p~0\n",
    "        mean_u = n1 * n2 / 2\n",
    "        std_u = np.sqrt(n1 * n2 * (n1 + n2 + 1) / 12)\n",
    "        z = (stat - mean_u) / std_u\n",
    "\n",
    "        # Effect size r\n",
    "        r = abs(z) / np.sqrt(n1 + n2)\n",
    "    except:\n",
    "        r = np.nan\n",
    "\n",
    "    results.append({\n",
    "        'agent': agent,\n",
    "        'label': label,\n",
    "        'n_x': len(x),\n",
    "        'n_y': len(y),\n",
    "        'U': stat,\n",
    "        'p_value': p,\n",
    "        'effect_size_r': r\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Round selected float columns\n",
    "results_df['p_value'] = results_df['p_value'].round(2)\n",
    "results_df['effect_size_r'] = results_df['effect_size_r'].round(2)\n",
    "\n",
    "\n",
    "# for better display/sorting:\n",
    "# Create a helper column with base agent name (without \"_inverted\")\n",
    "results_df['agent_base'] = results_df['agent'].str.replace('_inverted', '', regex=False)\n",
    "\n",
    "# Optional: set a consistent order based on unique agent bases\n",
    "agent_order = results_df['agent_base'].drop_duplicates().tolist()\n",
    "\n",
    "# Sort by agent base first, then put normal agent before inverted\n",
    "results_df = results_df.sort_values(\n",
    "    by=['agent_base', 'agent'],\n",
    "    key=lambda col: col if col.name != 'agent' else col.apply(lambda x: (x.endswith('_inverted'), x))\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Drop the helper column if not needed\n",
    "results_df = results_df.drop(columns='agent_base')\n",
    "\n",
    "#print(results_df)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114",
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_table = r\"\"\"\\begin{table}[ht]\n",
    "\\centering\n",
    "\\begin{tabular}{l c c c c c}\n",
    "\\hline\n",
    "\\textbf{Agent} & $\\mathbf{N_{Singles}}$ & $\\mathbf{N_{Round robin}}$ & $\\mathbf{U}$ & $\\mathbf{p}$ & $\\mathbf{r}$ \\\\\n",
    "\\hline\n",
    "\"\"\"\n",
    "\n",
    "for _, row in results_df.iterrows():\n",
    "    latex_table += f\"{row['agent']} & {int(row['n_x'])} & {int(row['n_y'])} & {int(row['U'])} & {row['p_value']:.2f} & {row['effect_size_r']:.2f} \\\\\\\\\\n\"\n",
    "\n",
    "latex_table += r\"\"\"\\hline\n",
    "\\end{tabular}\n",
    "\\caption{Mannâ€“Whitney U test results comparing single model vs. round robin homogeneous ensembles after response convergence, across agents for original and double-inverted GGB questions.}\n",
    "\\label{tab:statstests_tab_SinglevsRingHomogeneous}\n",
    "\\end{table}\n",
    "\"\"\"\n",
    "\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Plot styling\n",
    "sns.set(style=\"whitegrid\", context=\"notebook\")\n",
    "\n",
    "# Font sizes\n",
    "TITLE_SIZE = 18\n",
    "LABEL_SIZE = 16\n",
    "TICK_SIZE = 14\n",
    "LEGEND_SIZE = 14\n",
    "\n",
    "# Setup plot grid\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 12), sharex=True, sharey=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Colors\n",
    "colors = {\n",
    "    'Single': 'royalblue',\n",
    "    'Round Robin': 'tomato'\n",
    "}\n",
    "\n",
    "# Response scale\n",
    "response_range = np.arange(1, 8)\n",
    "\n",
    "# SEM estimator for counts frequencies\n",
    "def count_and_sem(values):\n",
    "    total = len(values)\n",
    "    counts = np.array([np.sum(values == val) for val in response_range])\n",
    "    rel_freqs = counts / total if total > 0 else np.zeros_like(counts)\n",
    "    sems = np.sqrt(counts) / total if total > 0 else np.zeros_like(counts)  # Binomial SEM approximation\n",
    "    return rel_freqs, sems\n",
    "\n",
    "# Agent bases (limit to 6 for 2x3 grid)\n",
    "agent_bases = results_df['agent'].str.replace('_inverted', '', regex=False).unique()[:6]\n",
    "\n",
    "for idx, base_agent in enumerate(agent_bases):\n",
    "    ax = axes[idx]\n",
    "\n",
    "    # Original data\n",
    "    agent = base_agent\n",
    "    label = f'GGB_{base_agent}'\n",
    "    x = single_df[single_df['label'] == label]['answer_numeric'].dropna().astype(int)\n",
    "    y = rr_by_agent_df[\n",
    "        (rr_by_agent_df['agent_shortname'] == agent) &\n",
    "        (rr_by_agent_df['round'] == 4) &\n",
    "        (~rr_by_agent_df['chat_type'].isin(['ggb_hetero_ring', 'ggb_inverted_hetero_ring']))\n",
    "    ]['agent_answer'].dropna().astype(int)\n",
    "\n",
    "    # Inverted data\n",
    "    agent_inv = f'{base_agent}_inverted'\n",
    "    label_inv = f'GGB_inverted_{base_agent}'\n",
    "    x_inv = single_df[single_df['label'] == label_inv]['answer_numeric'].dropna().astype(int)\n",
    "    y_inv = rr_by_agent_df[(rr_by_agent_df['agent_shortname'] == agent_inv) &\n",
    "                           (rr_by_agent_df['round'] == 4) &\n",
    "                         (~rr_by_agent_df['chat_type'].isin(['ggb_hetero_ring', 'ggb_inverted_hetero_ring']))\n",
    "     ]['agent_answer'].dropna().astype(int)\n",
    "\n",
    "    # Counts and SEMs\n",
    "    x_counts, x_sems = count_and_sem(x)\n",
    "    y_counts, y_sems = count_and_sem(y)\n",
    "    x_inv_counts, x_inv_sems = count_and_sem(x_inv)\n",
    "    y_inv_counts, y_inv_sems = count_and_sem(y_inv)\n",
    "\n",
    "    # Original markers and lines\n",
    "    ax.errorbar(response_range, x_counts, yerr=x_sems,\n",
    "                fmt='o', color=colors['Single'], markersize=8, label='Single (original)')\n",
    "    ax.errorbar(response_range, y_counts, yerr=y_sems,\n",
    "                fmt='o', color=colors['Round Robin'], markersize=8, label='Round Robin Homog. (original)')\n",
    "    # Connecting line for original single â†’ ring\n",
    "    ax.plot(response_range, x_counts, color=colors['Single'], alpha=0.5, linewidth=1.5)\n",
    "    ax.plot(response_range, y_counts, color=colors['Round Robin'], alpha=0.5, linewidth=1.5)\n",
    "\n",
    "    # Inverted (hollow markers, dashed lines)\n",
    "    if any(x_inv_counts) and any(y_inv_counts):\n",
    "        ax.errorbar(response_range, x_inv_counts, yerr=x_inv_sems,\n",
    "                    fmt='o', markerfacecolor='none', markeredgecolor=colors['Single'],\n",
    "                    color=colors['Single'], linestyle='--', markersize=8, label='Single (inverted)')\n",
    "        ax.errorbar(response_range, y_inv_counts, yerr=y_inv_sems,\n",
    "                    fmt='o', markerfacecolor='none', markeredgecolor=colors['Round Robin'],\n",
    "                    color=colors['Round Robin'], linestyle='--', markersize=8, label='Round Robin Homog. (inverted)')\n",
    "\n",
    "    # Formatting\n",
    "    ax.set_title(base_agent, fontsize=TITLE_SIZE)\n",
    "    ax.set_xlim(0.5, 7.5)\n",
    "    ax.set_xticks(response_range)\n",
    "    ax.set_xlabel('Answer', fontsize=LABEL_SIZE)\n",
    "    ax.set_ylabel('Percent of Total Answers', fontsize=LABEL_SIZE)\n",
    "    ax.tick_params(axis='both', labelsize=TICK_SIZE)\n",
    "    ax.legend(fontsize=LEGEND_SIZE, loc='upper left')\n",
    "    ax.yaxis.set_major_formatter(mtick.PercentFormatter(xmax=1.0))\n",
    "\n",
    "# Remove unused subplots\n",
    "for j in range(len(agent_bases), 6):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.92)\n",
    "fig.suptitle(\"Answer Frequencies with SEM: Single vs Round Robin Homogeneous (Original and Inverted)\", fontsize=22)\n",
    "fig.savefig('figures/statstests_distr_SinglevsRingHomogeneous.pdf', bbox_inches='tight', pad_inches=0.1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116",
   "metadata": {},
   "outputs": [],
   "source": [
    "rr_by_agent_df.chat_type.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117",
   "metadata": {},
   "source": [
    "## Singles v Ring Homogeneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import wilcoxon\n",
    "import re\n",
    "\n",
    "# to calculate stats need to maintain raw measurements in each data set\n",
    "single_stats_periteration_df\n",
    "\n",
    "ring_by_category_and_model[\n",
    "    (ring_by_category_and_model['round'] == 1) &\n",
    "    (ring_by_category_and_model['message_index'] == 1)\n",
    "]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

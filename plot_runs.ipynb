{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Imports and Setup\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "import sys\n",
    "import glob\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# Define directories\n",
    "RESULTS_DIR = 'results' # Directory containing single-agent CSV results\n",
    "PLOTS_DIR = 'plots'\n",
    "AGGREGATE_JSON_FILE = os.path.join(PLOTS_DIR, 'aggregate_results.json')\n",
    "MORAL_BENCH_REPO_DIR = '../MoralBench_AgentEnsembles' # Adjust if needed\n",
    "\n",
    "# Create plots directory if it doesn't exist\n",
    "os.makedirs(PLOTS_DIR, exist_ok=True)\n",
    "\n",
    "# Add MoralBench repo to path to import Question_Handler\n",
    "moral_bench_path = os.path.abspath(MORAL_BENCH_REPO_DIR)\n",
    "if moral_bench_path not in sys.path:\n",
    "    sys.path.insert(0, moral_bench_path)\n",
    "print(f\"Using MoralBench repository at: {moral_bench_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Question Handler Definition (Copied for self-containment)\n",
    "# Note: Ideally, this would be imported from a shared module.\n",
    "class Question_Handler():\n",
    "  def __init__(self, repo_dir):\n",
    "    self.repo_dir = os.path.abspath(repo_dir) # Use absolute path\n",
    "    self.questions_dir = os.path.join(self.repo_dir, 'questions')\n",
    "    self.answers_dir = os.path.join(self.repo_dir, 'answers')\n",
    "    self.categories = self.list_categories()\n",
    "    self._build_question_map()\n",
    "\n",
    "  def _build_question_map(self):\n",
    "      \"\"\"Builds a map from question number to (category, index).\"\"\"\n",
    "      self.question_map = {}\n",
    "      current_question_num = 1\n",
    "      for category in self.categories:\n",
    "          count = self.get_question_count(category)\n",
    "          for i in range(count):\n",
    "              self.question_map[current_question_num] = {'category': category, 'index': i}\n",
    "              current_question_num += 1\n",
    "      self.total_questions = current_question_num - 1\n",
    "\n",
    "  def get_question_category_and_index(self, question_number):\n",
    "      \"\"\"Gets the category and index for a given question number.\"\"\"\n",
    "      return self.question_map.get(question_number)\n",
    "\n",
    "  def get_question_category(self, question_number):\n",
    "      \"\"\"Gets the category for a given question number.\"\"\"\n",
    "      mapping = self.question_map.get(question_number)\n",
    "      return mapping['category'] if mapping else None\n",
    "\n",
    "  def get_question_count(self, category_folder):\n",
    "      \"\"\"\n",
    "      Get the number of questions in a specific category folder.\n",
    "      \"\"\"\n",
    "      questions_path = os.path.join(self.questions_dir, category_folder)\n",
    "      if not os.path.exists(questions_path):\n",
    "          # print(f\"Warning: Category folder {questions_path} does not exist!\")\n",
    "          return 0\n",
    "      try:\n",
    "          question_files = [f for f in os.listdir(questions_path) if f.endswith('.txt')]\n",
    "          return len(question_files)\n",
    "      except FileNotFoundError:\n",
    "          # print(f\"Warning: Error accessing category folder {questions_path}.\")\n",
    "          return 0\n",
    "\n",
    "  def list_categories(self):\n",
    "      \"\"\"\n",
    "      List all available question categories.\n",
    "      \"\"\"\n",
    "      if not os.path.exists(self.questions_dir):\n",
    "          print(f\"Warning: Questions directory {self.questions_dir} not found!\")\n",
    "          return []\n",
    "      try:\n",
    "          categories = sorted([d for d in os.listdir(self.questions_dir) if os.path.isdir(os.path.join(self.questions_dir, d))])\n",
    "          return categories\n",
    "      except FileNotFoundError:\n",
    "           print(f\"Warning: Error listing categories in {self.questions_dir}.\")\n",
    "           return []\n",
    "\n",
    "  def load_question_answer(self, category_folder, index):\n",
    "      \"\"\"\n",
    "      Load a question and its possible answers using an index.\n",
    "      \"\"\"\n",
    "      questions_path = os.path.join(self.questions_dir, category_folder)\n",
    "      if not os.path.exists(questions_path):\n",
    "          # print(f\"Warning: Category folder {questions_path} does not exist!\")\n",
    "          return None\n",
    "\n",
    "      try:\n",
    "          # Get all question files and sort them\n",
    "          question_files = sorted([f for f in os.listdir(questions_path) if f.endswith('.txt')])\n",
    "\n",
    "          if index < 0 or index >= len(question_files):\n",
    "              # print(f\"Warning: Index {index} is out of range for category {category_folder}! Valid range: 0-{len(question_files)-1}\")\n",
    "              return None\n",
    "\n",
    "          # Get question filename and ID\n",
    "          question_file = question_files[index]\n",
    "          question_id = os.path.splitext(question_file)[0]\n",
    "\n",
    "          # Read question content\n",
    "          question_path = os.path.join(questions_path, question_file)\n",
    "          with open(question_path, 'r', encoding='utf-8') as f:\n",
    "              question_text = f.read()\n",
    "\n",
    "          # Load answers from JSON\n",
    "          answers_path = os.path.join(self.answers_dir, f\"{category_folder}.json\")\n",
    "          question_answers = None\n",
    "          if os.path.exists(answers_path):\n",
    "              try:\n",
    "                  with open(answers_path, 'r', encoding='utf-8') as f:\n",
    "                      all_answers = json.load(f)\n",
    "                  question_answers = all_answers.get(question_id, {})\n",
    "              except json.JSONDecodeError:\n",
    "                  print(f\"Warning: Error decoding JSON from {answers_path}\")\n",
    "              except Exception as e:\n",
    "                  print(f\"Warning: Error reading answers file {answers_path}: {e}\")\n",
    "          # else:\n",
    "              # print(f\"Warning: Answers file {answers_path} for {category_folder} does not exist!\")\n",
    "\n",
    "          return {\n",
    "              'question_id': question_id,\n",
    "              'question_text': question_text,\n",
    "              'answers': question_answers\n",
    "          }\n",
    "      except FileNotFoundError:\n",
    "          # print(f\"Warning: Error accessing files in {questions_path}.\")\n",
    "          return None\n",
    "      except Exception as e:\n",
    "          print(f\"Warning: Unexpected error loading question {category_folder}/{index}: {e}\")\n",
    "          return None\n",
    "\n",
    "  def get_question(self, number):\n",
    "      \"\"\"Gets question data by absolute number.\"\"\"\n",
    "      mapping = self.get_question_category_and_index(number)\n",
    "      if mapping:\n",
    "          return self.load_question_answer(mapping['category'], mapping['index'])\n",
    "      else:\n",
    "          # print(f\"Warning: Question number {number} not found in map.\")\n",
    "          return None\n",
    "\n",
    "  def get_total_question_count(self):\n",
    "      \"\"\"Returns the total number of questions across all categories.\"\"\"\n",
    "      return self.total_questions\n",
    "\n",
    "# --- Initialize Question Handler ---\n",
    "try:\n",
    "    Qs = Question_Handler(MORAL_BENCH_REPO_DIR)\n",
    "    print(f\"Question Handler initialized. Found {Qs.get_total_question_count()} questions in {len(Qs.categories)} categories.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing Question_Handler: {e}\")\n",
    "    Qs = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Helper Functions for Data Loading and Plotting\n",
    "\n",
    "def extract_filename_info(filename):\n",
    "    \"\"\"Extracts model name, question range, and num_runs from filename.\"\"\"\n",
    "    # Example filename: single_openai_gpt-4o-mini_q1-88_n10.csv\n",
    "    # Corrected regex to capture digits using \\d+\n",
    "    match = re.match(r\"single_(.*?)_q(\\d+)-(\\d+)_n(\\d+).csv\", os.path.basename(filename))\n",
    "    if match:\n",
    "        model_name = match.group(1).replace(\"_\", \"/\").replace(\"-instruct\", \"-instruct:\") # Handle specific cases if needed\n",
    "        q_start = int(match.group(2))\n",
    "        q_end = int(match.group(3))\n",
    "        num_runs = int(match.group(4))\n",
    "        # Quick fix for model names that were altered\n",
    "        if 'google/gemini' in model_name and ':free' not in model_name:\n",
    "             model_name += ':free'\n",
    "        if 'deepseek/deepseek' in model_name and ':free' not in model_name:\n",
    "             model_name += ':free'\n",
    "        if 'meta-llama/llama' in model_name and ':free' not in model_name:\n",
    "             model_name += ':free'\n",
    "        return model_name, (q_start, q_end), num_runs\n",
    "    else:\n",
    "        print(f\"Warning: Could not parse filename: {filename}\")\n",
    "        return None, None, None\n",
    "\n",
    "def load_all_csv_data(results_dir):\n",
    "    \"\"\"Loads all single-agent CSV files from the results directory.\"\"\"\n",
    "    all_files = glob.glob(os.path.join(results_dir, \"single_*.csv\"))\n",
    "    df_list = []\n",
    "    if not all_files:\n",
    "        print(f\"Warning: No 'single_*.csv' files found in {results_dir}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    for f in all_files:\n",
    "        model_name, q_range, n_runs = extract_filename_info(f)\n",
    "        if model_name:\n",
    "            try:\n",
    "                temp_df = pd.read_csv(f)\n",
    "                # Ensure model_name column exists or is added correctly\n",
    "                if 'model_name' not in temp_df.columns:\n",
    "                     temp_df['model_name'] = model_name\n",
    "                else:\n",
    "                     # Overwrite if filename parsing is more reliable\n",
    "                     temp_df['model_name'] = model_name\n",
    "                # Add other info if needed, though model_name is primary\n",
    "                # temp_df['file_q_range'] = str(q_range)\n",
    "                # temp_df['file_n_runs'] = n_runs\n",
    "                df_list.append(temp_df)\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading or processing {f}: {e}\")\n",
    "    if not df_list:\n",
    "        print(\"Warning: No data loaded from CSV files.\")\n",
    "        return pd.DataFrame()\n",
    "    return pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "def clean_data(df):\n",
    "    \"\"\"Cleans the DataFrame: converts types, extracts single letter answer.\"\"\"\n",
    "    if df.empty:\n",
    "        return df\n",
    "\n",
    "    # Confidence to numeric\n",
    "    df['confidence'] = pd.to_numeric(df['confidence'], errors='coerce')\n",
    "    df['confidence'] = df['confidence'].fillna(-1) # Use -1 for missing/invalid confidence\n",
    "    df['confidence'] = df['confidence'].astype(int)\n",
    "\n",
    "    # Extract single letter answer (handle variations like 'A.', ' A', etc.)\n",
    "    df['answer_raw'] = df['answer'] # Keep original\n",
    "    df['answer'] = df['answer'].astype(str).str.strip().str.upper()\n",
    "    # Take the first character if it's a letter A-Z\n",
    "    df['answer'] = df['answer'].apply(lambda x: x[0] if x and 'A' <= x[0] <= 'Z' else 'Invalid')\n",
    "\n",
    "    # Add category using Question_Handler\n",
    "    if Qs:\n",
    "        df['category'] = df['question_num'].apply(Qs.get_question_category)\n",
    "        df['category'] = df['category'].fillna('Unknown Category')\n",
    "    else:\n",
    "        df['category'] = 'Unknown Category'\n",
    "        print(\"Warning: Question_Handler not available, cannot determine categories.\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def calculate_aggregates(df_group):\n",
    "    \"\"\"Calculates aggregate statistics for a DataFrame group (e.g., per question or category).\"\"\"\n",
    "    if df_group.empty:\n",
    "        return {\n",
    "            'total_responses': 0,\n",
    "            'answer_distribution': {},\n",
    "            'confidence_distribution': {},\n",
    "            'confidence_mean': None,\n",
    "            'confidence_median': None,\n",
    "            'valid_confidence_responses': 0\n",
    "        }\n",
    "\n",
    "    answer_counts = df_group['answer'].value_counts().to_dict()\n",
    "    # Filter out invalid confidence values (-1) before calculating stats\n",
    "    valid_conf_df = df_group[df_group['confidence'] != -1]\n",
    "    conf_counts = valid_conf_df['confidence'].value_counts().sort_index().to_dict()\n",
    "\n",
    "    return {\n",
    "        'total_responses': len(df_group),\n",
    "        'answer_distribution': answer_counts,\n",
    "        'confidence_distribution': conf_counts,\n",
    "        'confidence_mean': valid_conf_df['confidence'].mean() if not valid_conf_df.empty else None,\n",
    "        'confidence_median': valid_conf_df['confidence'].median() if not valid_conf_df.empty else None,\n",
    "        'valid_confidence_responses': len(valid_conf_df)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Load and Process Data\n",
    "df_raw = load_all_csv_data(RESULTS_DIR)\n",
    "df = clean_data(df_raw.copy()) # Work on a copy\n",
    "\n",
    "if df.empty:\n",
    "    print(\"No data loaded or processed. Exiting.\")\n",
    "else:\n",
    "    print(f\"Loaded and cleaned {len(df)} records.\")\n",
    "    print(\"\\nUnique Models:\", df['model_name'].unique())\n",
    "    print(\"\\nUnique Categories:\", df['category'].unique())\n",
    "    print(\"\\nAnswer Values:\", df['answer'].unique())\n",
    "    print(\"\\nConfidence Values:\", df['confidence'].unique())\n",
    "    # Display first few rows and info\n",
    "    print(\"\\nDataFrame Head:\")\n",
    "    print(df.head())\n",
    "    print(\"\\nDataFrame Info:\")\n",
    "    df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Generate Aggregates and Summary Plots\n",
    "\n",
    "all_aggregate_data = defaultdict(lambda: {'questions': {}, 'categories': {}})\n",
    "\n",
    "if df.empty or Qs is None:\n",
    "    print(\"Skipping aggregate generation due to missing data or Question_Handler.\")\n",
    "else:\n",
    "    models = sorted(df['model_name'].unique()) # Sort models for consistent plot order\n",
    "    categories = sorted([c for c in df['category'].unique() if c != 'Unknown Category']) # Sort categories\n",
    "    question_numbers = sorted(df['question_num'].unique())\n",
    "\n",
    "    print(\"Calculating aggregates...\")\n",
    "    for model in models:\n",
    "        model_df = df[df['model_name'] == model]\n",
    "\n",
    "        # Per-Question Aggregates\n",
    "        for q_num in question_numbers:\n",
    "            q_df = model_df[model_df['question_num'] == q_num]\n",
    "            if not q_df.empty:\n",
    "                q_category = q_df['category'].iloc[0]\n",
    "                q_id_info = Qs.get_question(q_num)\n",
    "                q_id = q_id_info['question_id'] if q_id_info else f'UnknownID_Q{q_num}'\n",
    "\n",
    "                # Aggregate\n",
    "                q_agg = calculate_aggregates(q_df)\n",
    "                all_aggregate_data[model]['questions'][q_num] = {\n",
    "                    'question_id': q_id,\n",
    "                    'category': q_category,\n",
    "                    **q_agg\n",
    "                }\n",
    "            # else: No data for this model and question\n",
    "\n",
    "        # Per-Category Aggregates\n",
    "        for category in categories:\n",
    "             cat_df = model_df[model_df['category'] == category]\n",
    "             if not cat_df.empty:\n",
    "                 # Aggregate\n",
    "                 cat_agg = calculate_aggregates(cat_df)\n",
    "                 all_aggregate_data[model]['categories'][category] = cat_agg\n",
    "             # else: No data for this model and category\n",
    "    print(\"Aggregation complete.\")\n",
    "\n",
    "    # --- Generate Summary Plots ---\n",
    "    print(\"\\nGenerating summary plots...\")\n",
    "\n",
    "    # Plot 1: Mean Confidence per Question per Model\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    for model in models:\n",
    "        q_nums = sorted(all_aggregate_data[model]['questions'].keys())\n",
    "        mean_confs = [all_aggregate_data[model]['questions'][q]['confidence_mean'] for q in q_nums if all_aggregate_data[model]['questions'][q]['confidence_mean'] is not None]\n",
    "        valid_q_nums = [q for q in q_nums if all_aggregate_data[model]['questions'][q]['confidence_mean'] is not None]\n",
    "        if valid_q_nums:\n",
    "             # Shorten model names for legend\n",
    "             short_model_name = model.split('/')[-1].replace(':free', '') # Example shortening\n",
    "             plt.plot(valid_q_nums, mean_confs, marker='o', linestyle='-', markersize=4, label=short_model_name)\n",
    "\n",
    "    plt.title('Mean Confidence per Question', fontsize=16)\n",
    "    plt.xlabel('Question Number', fontsize=12)\n",
    "    plt.ylabel('Mean Confidence (0-5)', fontsize=12)\n",
    "    plt.xticks(fontsize=10)\n",
    "    plt.yticks(fontsize=10)\n",
    "    plt.legend(title='Model', bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10)\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.tight_layout(rect=[0, 0, 0.85, 1]) # Adjust layout to make space for legend\n",
    "    plot1_filename = os.path.join(PLOTS_DIR, 'summary_confidence_per_question.png')\n",
    "    plt.savefig(plot1_filename)\n",
    "    print(f\"Plot saved to {plot1_filename}\")\n",
    "    plt.close()\n",
    "\n",
    "    # Plot 2: Mean Confidence per Category per Model\n",
    "    category_data = defaultdict(lambda: defaultdict(lambda: np.nan))\n",
    "    for model in models:\n",
    "        for category in categories:\n",
    "            if category in all_aggregate_data[model]['categories']:\n",
    "                mean_conf = all_aggregate_data[model]['categories'][category]['confidence_mean']\n",
    "                if mean_conf is not None:\n",
    "                    category_data[category][model] = mean_conf\n",
    "\n",
    "    plot_df = pd.DataFrame(category_data).T # Transpose to have categories as index, models as columns\n",
    "    plot_df.index.name = 'Category'\n",
    "    plot_df.columns.name = 'Model'\n",
    "\n",
    "    if not plot_df.empty:\n",
    "        plot_df.plot(kind='bar', figsize=(15, 8), width=0.8)\n",
    "        plt.title('Mean Confidence per Category', fontsize=16)\n",
    "        plt.xlabel('Category', fontsize=12)\n",
    "        plt.ylabel('Mean Confidence (0-5)', fontsize=12)\n",
    "        plt.xticks(rotation=45, ha='right', fontsize=10)\n",
    "        plt.yticks(fontsize=10)\n",
    "        plt.legend(title='Model', bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10)\n",
    "        plt.grid(True, axis='y', linestyle='--', alpha=0.6)\n",
    "        plt.tight_layout(rect=[0, 0, 0.85, 1]) # Adjust layout\n",
    "        plot2_filename = os.path.join(PLOTS_DIR, 'summary_confidence_per_category.png')\n",
    "        plt.savefig(plot2_filename)\n",
    "        print(f\"Plot saved to {plot2_filename}\")\n",
    "        plt.close()\n",
    "    else:\n",
    "        print(\"Skipping category plot: No aggregated category data found.\")\n",
    "\n",
    "    # Save Aggregate JSON (remains the same)\n",
    "    print(f\"\\nSaving aggregate data to {AGGREGATE_JSON_FILE}...\")\n",
    "    try:\n",
    "        # Convert numpy types to standard Python types for JSON serialization\n",
    "        def convert_numpy(obj):\n",
    "            if isinstance(obj, np.integer):\n",
    "                return int(obj)\n",
    "            elif isinstance(obj, np.floating):\n",
    "                return float(obj)\n",
    "            elif isinstance(obj, np.ndarray):\n",
    "                return obj.tolist()\n",
    "            elif isinstance(obj, (np.bool_, bool)):\n",
    "                 return bool(obj)\n",
    "            elif pd.isna(obj): # Handle pandas NA/NaN\n",
    "                 return None\n",
    "            return obj\n",
    "\n",
    "        with open(AGGREGATE_JSON_FILE, 'w', encoding='utf-8') as f:\n",
    "            json.dump(all_aggregate_data, f, indent=4, default=convert_numpy)\n",
    "        print(\"Aggregate data saved successfully.\")\n",
    "    except TypeError as e:\n",
    "        print(f\"Error saving JSON: {e}. Check for non-serializable types.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred while saving JSON: {e}\")\n",
    "\n",
    "print(\"\\n--- Aggregation and Plotting Complete ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sitewiz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

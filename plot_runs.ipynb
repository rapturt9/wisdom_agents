{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Imports and Setup\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "import sys\n",
    "import glob\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# Define directories\n",
    "RESULTS_DIR = 'results' # Directory containing single-agent CSV results\n",
    "PLOTS_DIR = 'plots'\n",
    "AGGREGATE_JSON_FILE = os.path.join(PLOTS_DIR, 'aggregate_results.json')\n",
    "MORAL_BENCH_REPO_DIR = '../MoralBench_AgentEnsembles' # Adjust if needed\n",
    "\n",
    "# Create plots directory if it doesn't exist\n",
    "os.makedirs(PLOTS_DIR, exist_ok=True)\n",
    "\n",
    "# Add MoralBench repo to path to import Question_Handler\n",
    "moral_bench_path = os.path.abspath(MORAL_BENCH_REPO_DIR)\n",
    "if moral_bench_path not in sys.path:\n",
    "    sys.path.insert(0, moral_bench_path)\n",
    "print(f\"Using MoralBench repository at: {moral_bench_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_map = {\n",
    "   'authority': 'Authority',\n",
    "   'liberty': 'Liberty',\n",
    "   'fairness': 'Fairness',\n",
    "   'harm': 'Harm',\n",
    "   'loyalty': 'Loyalty',\n",
    "   'purity': 'Sanctity',\n",
    "   'ingroup': 'Care'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Question Handler Definition (Copied for self-containment)\n",
    "# Note: Ideally, this would be imported from a shared module.\n",
    "class Question_Handler():\n",
    "  def __init__(self, repo_dir):\n",
    "    self.repo_dir = os.path.abspath(repo_dir) # Use absolute path\n",
    "    self.questions_dir = os.path.join(self.repo_dir, 'questions')\n",
    "    self.answers_dir = os.path.join(self.repo_dir, 'answers')\n",
    "    self.categories = self.list_categories()\n",
    "    self._build_question_map()\n",
    "\n",
    "  def _build_question_map(self):\n",
    "      \"\"\"Builds a map from question number to (category, index).\"\"\"\n",
    "      self.question_map = {}\n",
    "      current_question_num = 1\n",
    "      for category in self.categories:\n",
    "          count = self.get_question_count(category)\n",
    "          for i in range(count):\n",
    "              self.question_map[current_question_num] = {'category': category, 'index': i}\n",
    "              current_question_num += 1\n",
    "      self.total_questions = current_question_num - 1\n",
    "\n",
    "  def get_question_category_and_index(self, question_number):\n",
    "      \"\"\"Gets the category and index for a given question number.\"\"\"\n",
    "      return self.question_map.get(question_number)\n",
    "\n",
    "  def get_question_category(self, question_number):\n",
    "      \"\"\"Gets the category for a given question number.\"\"\"\n",
    "      mapping = self.question_map.get(question_number)\n",
    "      return mapping['category'] if mapping else None\n",
    "\n",
    "  def get_question_count(self, category_folder):\n",
    "      \"\"\"\n",
    "      Get the number of questions in a specific category folder.\n",
    "      \"\"\"\n",
    "      questions_path = os.path.join(self.questions_dir, category_folder)\n",
    "      if not os.path.exists(questions_path):\n",
    "          # print(f\"Warning: Category folder {questions_path} does not exist!\")\n",
    "          return 0\n",
    "      try:\n",
    "          question_files = [f for f in os.listdir(questions_path) if f.endswith('.txt')]\n",
    "          return len(question_files)\n",
    "      except FileNotFoundError:\n",
    "          # print(f\"Warning: Error accessing category folder {questions_path}.\")\n",
    "          return 0\n",
    "\n",
    "  def list_categories(self):\n",
    "      \"\"\"\n",
    "      List all available question categories.\n",
    "      \"\"\"\n",
    "      if not os.path.exists(self.questions_dir):\n",
    "          print(f\"Warning: Questions directory {self.questions_dir} not found!\")\n",
    "          return []\n",
    "      try:\n",
    "          categories = sorted([d for d in os.listdir(self.questions_dir) if os.path.isdir(os.path.join(self.questions_dir, d))])\n",
    "          return categories\n",
    "      except FileNotFoundError:\n",
    "           print(f\"Warning: Error listing categories in {self.questions_dir}.\")\n",
    "           return []\n",
    "\n",
    "  def load_question_answer(self, category_folder, index):\n",
    "      \"\"\"\n",
    "      Load a question and its possible answers using an index.\n",
    "      \"\"\"\n",
    "      questions_path = os.path.join(self.questions_dir, category_folder)\n",
    "      if not os.path.exists(questions_path):\n",
    "          # print(f\"Warning: Category folder {questions_path} does not exist!\")\n",
    "          return None\n",
    "\n",
    "      try:\n",
    "          # Get all question files and sort them\n",
    "          question_files = sorted([f for f in os.listdir(questions_path) if f.endswith('.txt')])\n",
    "\n",
    "          if index < 0 or index >= len(question_files):\n",
    "              # print(f\"Warning: Index {index} is out of range for category {category_folder}! Valid range: 0-{len(question_files)-1}\")\n",
    "              return None\n",
    "\n",
    "          # Get question filename and ID\n",
    "          question_file = question_files[index]\n",
    "          question_id = os.path.splitext(question_file)[0]\n",
    "\n",
    "          # Read question content\n",
    "          question_path = os.path.join(questions_path, question_file)\n",
    "          with open(question_path, 'r', encoding='utf-8') as f:\n",
    "              question_text = f.read()\n",
    "\n",
    "          # Load answers from JSON\n",
    "          answers_path = os.path.join(self.answers_dir, f\"{category_folder}.json\")\n",
    "          question_answers = None\n",
    "          if os.path.exists(answers_path):\n",
    "              try:\n",
    "                  with open(answers_path, 'r', encoding='utf-8') as f:\n",
    "                      all_answers = json.load(f)\n",
    "                  question_answers = all_answers.get(question_id, {})\n",
    "              except json.JSONDecodeError:\n",
    "                  print(f\"Warning: Error decoding JSON from {answers_path}\")\n",
    "              except Exception as e:\n",
    "                  print(f\"Warning: Error reading answers file {answers_path}: {e}\")\n",
    "          # else:\n",
    "              # print(f\"Warning: Answers file {answers_path} for {category_folder} does not exist!\")\n",
    "\n",
    "          return {\n",
    "              'question_id': question_id,\n",
    "              'question_text': question_text,\n",
    "              'answers': question_answers\n",
    "          }\n",
    "      except FileNotFoundError:\n",
    "          # print(f\"Warning: Error accessing files in {questions_path}.\")\n",
    "          return None\n",
    "      except Exception as e:\n",
    "          print(f\"Warning: Unexpected error loading question {category_folder}/{index}: {e}\")\n",
    "          return None\n",
    "\n",
    "  def get_question(self, number):\n",
    "      \"\"\"Gets question data by absolute number.\"\"\"\n",
    "      mapping = self.get_question_category_and_index(number)\n",
    "      if mapping:\n",
    "          return self.load_question_answer(mapping['category'], mapping['index'])\n",
    "      else:\n",
    "          # print(f\"Warning: Question number {number} not found in map.\")\n",
    "          return None\n",
    "\n",
    "  def get_total_question_count(self):\n",
    "      \"\"\"Returns the total number of questions across all categories.\"\"\"\n",
    "      return self.total_questions\n",
    "\n",
    "# --- Initialize Question Handler ---\n",
    "try:\n",
    "    Qs = Question_Handler(MORAL_BENCH_REPO_DIR)\n",
    "    print(f\"Question Handler initialized. Found {Qs.get_total_question_count()} questions in {len(Qs.categories)} categories.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing Question_Handler: {e}\")\n",
    "    Qs = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Qs.get_question(31)  # Test the Question_Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Helper Functions for Data Loading and Plotting\n",
    "\n",
    "def extract_filename_info(filename):\n",
    "    \"\"\"Extracts model name, question range, and num_runs from filename.\"\"\"\n",
    "    # Example filename: single_openai_gpt-4o-mini_q1-88_n10.csv\n",
    "    # Corrected regex to capture digits using \\d+\n",
    "    match = re.match(r\"single_(.*?)_q(\\d+)-(\\d+)_n(\\d+).csv\", os.path.basename(filename))\n",
    "    if match:\n",
    "        model_name = match.group(1).replace(\"_\", \"/\").replace(\"-instruct\", \"-instruct:\") # Handle specific cases if needed\n",
    "        q_start = int(match.group(2))\n",
    "        q_end = int(match.group(3))\n",
    "        num_runs = int(match.group(4))\n",
    "        # Quick fix for model names that were altered\n",
    "        if 'google/gemini' in model_name and ':free' not in model_name:\n",
    "             model_name += ':free'\n",
    "        if 'deepseek/deepseek' in model_name and ':free' not in model_name:\n",
    "             model_name += ':free'\n",
    "        if 'meta-llama/llama' in model_name and ':free' not in model_name:\n",
    "             model_name += ':free'\n",
    "        return model_name, (q_start, q_end), num_runs\n",
    "    else:\n",
    "        print(f\"Warning: Could not parse filename: {filename}\")\n",
    "        return None, None, None\n",
    "\n",
    "def load_all_csv_data(results_dir):\n",
    "    \"\"\"Loads all single-agent CSV files from the results directory.\"\"\"\n",
    "    all_files = glob.glob(os.path.join(results_dir, \"single_*.csv\"))\n",
    "    df_list = []\n",
    "    if not all_files:\n",
    "        print(f\"Warning: No 'single_*.csv' files found in {results_dir}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    for f in all_files:\n",
    "        model_name, q_range, n_runs = extract_filename_info(f)\n",
    "        if model_name:\n",
    "            try:\n",
    "                temp_df = pd.read_csv(f)\n",
    "                # Ensure model_name column exists or is added correctly\n",
    "                if 'model_name' not in temp_df.columns:\n",
    "                     temp_df['model_name'] = model_name\n",
    "                else:\n",
    "                     # Overwrite if filename parsing is more reliable\n",
    "                     temp_df['model_name'] = model_name\n",
    "                # Add other info if needed, though model_name is primary\n",
    "                # temp_df['file_q_range'] = str(q_range)\n",
    "                # temp_df['file_n_runs'] = n_runs\n",
    "                df_list.append(temp_df)\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading or processing {f}: {e}\")\n",
    "    if not df_list:\n",
    "        print(\"Warning: No data loaded from CSV files.\")\n",
    "        return pd.DataFrame()\n",
    "    return pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "def clean_data(df):\n",
    "    \"\"\"Cleans the DataFrame: converts types, extracts single letter answer.\"\"\"\n",
    "    if df.empty:\n",
    "        return df\n",
    "\n",
    "    # Confidence to numeric\n",
    "    df['confidence'] = pd.to_numeric(df['confidence'], errors='coerce')\n",
    "    df['confidence'] = df['confidence'].fillna(-1) # Use -1 for missing/invalid confidence\n",
    "    df['confidence'] = df['confidence'].astype(int)\n",
    "\n",
    "    # Extract single letter answer (handle variations like 'A.', ' A', etc.)\n",
    "    df['answer_raw'] = df['answer'] # Keep original\n",
    "    df['answer'] = df['answer'].astype(str).str.strip().str.upper()\n",
    "    # Take the first character if it's a letter A-Z\n",
    "    df['answer'] = df['answer'].apply(lambda x: x[0] if x and 'A' <= x[0] <= 'Z' else 'Invalid')\n",
    "\n",
    "    # Add category using Question_Handler\n",
    "    if Qs:\n",
    "        df['category'] = df['question_num'].apply(Qs.get_question_category)\n",
    "        df['category'] = df['category'].fillna('Unknown Category')\n",
    "    else:\n",
    "        df['category'] = 'Unknown Category'\n",
    "        print(\"Warning: Question_Handler not available, cannot determine categories.\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def calculate_aggregates(df_group):\n",
    "    \"\"\"Calculates aggregate statistics for a DataFrame group (e.g., per question or category).\"\"\"\n",
    "    if df_group.empty:\n",
    "        return {\n",
    "            'total_responses': 0,\n",
    "            'answer_distribution': {},\n",
    "            'confidence_distribution': {},\n",
    "            'confidence_mean': None,\n",
    "            'confidence_median': None,\n",
    "            'valid_confidence_responses': 0\n",
    "        }\n",
    "\n",
    "    answer_counts = df_group['answer'].value_counts().to_dict()\n",
    "    # Filter out invalid confidence values (-1) before calculating stats\n",
    "    valid_conf_df = df_group[df_group['confidence'] != -1]\n",
    "    conf_counts = valid_conf_df['confidence'].value_counts().sort_index().to_dict()\n",
    "\n",
    "    return {\n",
    "        'total_responses': len(df_group),\n",
    "        'answer_distribution': answer_counts,\n",
    "        'confidence_distribution': conf_counts,\n",
    "        'confidence_mean': valid_conf_df['confidence'].mean() if not valid_conf_df.empty else None,\n",
    "        'confidence_median': valid_conf_df['confidence'].median() if not valid_conf_df.empty else None,\n",
    "        'valid_confidence_responses': len(valid_conf_df)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Load and Process Data\n",
    "df_raw = load_all_csv_data(RESULTS_DIR)\n",
    "df = clean_data(df_raw.copy()) # Work on a copy\n",
    "\n",
    "if df.empty:\n",
    "    print(\"No data loaded or processed. Exiting.\")\n",
    "else:\n",
    "    print(f\"Loaded and cleaned {len(df)} records.\")\n",
    "    print(\"\\nUnique Models:\", df['model_name'].unique())\n",
    "    print(\"\\nUnique Categories:\", df['category'].unique())\n",
    "    print(\"\\nAnswer Values:\", df['answer'].unique())\n",
    "    print(\"\\nConfidence Values:\", df['confidence'].unique())\n",
    "    # Display first few rows and info\n",
    "    print(\"\\nDataFrame Head:\")\n",
    "    print(df.head())\n",
    "    print(\"\\nDataFrame Info:\")\n",
    "    df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Generate Aggregates and Summary Plots\n",
    "\n",
    "all_aggregate_data = defaultdict(lambda: {'questions': {}, 'categories': {}})\n",
    "\n",
    "if df.empty or Qs is None:\n",
    "    print(\"Skipping aggregate generation due to missing data or Question_Handler.\")\n",
    "else:\n",
    "    models = sorted(df['model_name'].unique()) # Sort models for consistent plot order\n",
    "    categories = sorted([c for c in df['category'].unique() if c != 'Unknown Category']) # Sort categories\n",
    "    question_numbers = sorted(df['question_num'].unique())\n",
    "\n",
    "    print(\"Calculating aggregates...\")\n",
    "    for model in models:\n",
    "        model_df = df[df['model_name'] == model]\n",
    "\n",
    "        # Per-Question Aggregates\n",
    "        for q_num in question_numbers:\n",
    "            q_df = model_df[model_df['question_num'] == q_num]\n",
    "            if not q_df.empty:\n",
    "                q_category = q_df['category'].iloc[0]\n",
    "                q_id_info = Qs.get_question(q_num)\n",
    "                q_id = q_id_info['question_id'] if q_id_info else f'UnknownID_Q{q_num}'\n",
    "\n",
    "                # Aggregate\n",
    "                q_agg = calculate_aggregates(q_df)\n",
    "                # Convert q_num (potentially numpy int) to standard Python int for JSON key compatibility\n",
    "                q_num_int = int(q_num)\n",
    "                all_aggregate_data[model]['questions'][q_num_int] = {\n",
    "                    'question_id': q_id,\n",
    "                    'category': q_category,\n",
    "                    **q_agg\n",
    "                }\n",
    "            # else: No data for this model and question\n",
    "\n",
    "        # Per-Category Aggregates\n",
    "        for category in categories:\n",
    "             cat_df = model_df[model_df['category'] == category]\n",
    "             if not cat_df.empty:\n",
    "                 # Aggregate\n",
    "                 cat_agg = calculate_aggregates(cat_df)\n",
    "                 # Category is already a string, so no conversion needed for the key\n",
    "                 all_aggregate_data[model]['categories'][category] = cat_agg\n",
    "             # else: No data for this model and category\n",
    "    print(\"Aggregation complete.\")\n",
    "\n",
    "    # --- Generate Summary Plots ---\n",
    "    print(\"\\nGenerating summary plots...\")\n",
    "\n",
    "    # Plot 1: Mean Confidence per Question per Model\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    for model in models:\n",
    "        # Ensure keys are treated as integers for sorting and access\n",
    "        q_nums = sorted(all_aggregate_data[model]['questions'].keys()) # Keys are now int\n",
    "        mean_confs = [all_aggregate_data[model]['questions'][q]['confidence_mean'] for q in q_nums if all_aggregate_data[model]['questions'][q]['confidence_mean'] is not None]\n",
    "        valid_q_nums = [q for q in q_nums if all_aggregate_data[model]['questions'][q]['confidence_mean'] is not None]\n",
    "        if valid_q_nums:\n",
    "             # Shorten model names for legend\n",
    "             short_model_name = model.split('/')[-1].replace(':free', '') # Example shortening\n",
    "             plt.plot(valid_q_nums, mean_confs, marker='o', linestyle='-', markersize=4, label=short_model_name)\n",
    "\n",
    "    plt.title('Mean Confidence per Question', fontsize=16)\n",
    "    plt.xlabel('Question Number', fontsize=12)\n",
    "    plt.ylabel('Mean Confidence (0-5)', fontsize=12)\n",
    "    plt.xticks(fontsize=10)\n",
    "    plt.yticks(fontsize=10)\n",
    "    plt.legend(title='Model', bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10)\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.tight_layout(rect=[0, 0, 0.85, 1]) # Adjust layout to make space for legend\n",
    "    plot1_filename = os.path.join(PLOTS_DIR, 'summary_confidence_per_question.png')\n",
    "    plt.savefig(plot1_filename)\n",
    "    print(f\"Plot saved to {plot1_filename}\")\n",
    "    plt.close()\n",
    "\n",
    "    # Plot 2: Mean Confidence per Category per Model\n",
    "    category_data = defaultdict(lambda: defaultdict(lambda: np.nan))\n",
    "    for model in models:\n",
    "        for category in categories:\n",
    "            if category in all_aggregate_data[model]['categories']:\n",
    "                mean_conf = all_aggregate_data[model]['categories'][category]['confidence_mean']\n",
    "                if mean_conf is not None:\n",
    "                    category_data[category][model] = mean_conf\n",
    "\n",
    "    plot_df = pd.DataFrame(category_data).T # Transpose to have categories as index, models as columns\n",
    "    plot_df.index.name = 'Category'\n",
    "    plot_df.columns.name = 'Model'\n",
    "\n",
    "    if not plot_df.empty:\n",
    "        plot_df.plot(kind='bar', figsize=(15, 8), width=0.8)\n",
    "        plt.title('Mean Confidence per Category', fontsize=16)\n",
    "        plt.xlabel('Category', fontsize=12)\n",
    "        plt.ylabel('Mean Confidence (0-5)', fontsize=12)\n",
    "        plt.xticks(rotation=45, ha='right', fontsize=10)\n",
    "        plt.yticks(fontsize=10)\n",
    "        plt.legend(title='Model', bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10)\n",
    "        plt.grid(True, axis='y', linestyle='--', alpha=0.6)\n",
    "        plt.tight_layout(rect=[0, 0, 0.85, 1]) # Adjust layout\n",
    "        plot2_filename = os.path.join(PLOTS_DIR, 'summary_confidence_per_category.png')\n",
    "        plt.savefig(plot2_filename)\n",
    "        print(f\"Plot saved to {plot2_filename}\")\n",
    "        plt.close()\n",
    "    else:\n",
    "        print(\"Skipping category plot: No aggregated category data found.\")\n",
    "\n",
    "    # Save Aggregate JSON\n",
    "    print(f\"\\nSaving aggregate data to {AGGREGATE_JSON_FILE}...\")\n",
    "    try:\n",
    "        # Convert numpy types to standard Python types for JSON serialization\n",
    "        def convert_numpy(obj):\n",
    "            if isinstance(obj, np.integer):\n",
    "                return int(obj)\n",
    "            elif isinstance(obj, np.floating):\n",
    "                return float(obj)\n",
    "            elif isinstance(obj, np.ndarray):\n",
    "                return obj.tolist()\n",
    "            elif isinstance(obj, (np.bool_, bool)):\n",
    "                 return bool(obj)\n",
    "            elif pd.isna(obj): # Handle pandas NA/NaN\n",
    "                 return None\n",
    "            # Add handling for dictionary keys if they are numpy types (though addressed earlier)\n",
    "            elif isinstance(obj, dict):\n",
    "                 return {convert_numpy(k): convert_numpy(v) for k, v in obj.items()}\n",
    "            elif isinstance(obj, list):\n",
    "                 return [convert_numpy(i) for i in obj]\n",
    "            return obj\n",
    "\n",
    "        # Apply conversion recursively to the entire data structure before dumping\n",
    "        serializable_data = convert_numpy(all_aggregate_data)\n",
    "\n",
    "        with open(AGGREGATE_JSON_FILE, 'w', encoding='utf-8') as f:\n",
    "            # Dump the pre-converted data\n",
    "            json.dump(serializable_data, f, indent=4)\n",
    "        print(\"Aggregate data saved successfully.\")\n",
    "    except TypeError as e:\n",
    "        print(f\"Error saving JSON: {e}. Check for non-serializable types.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred while saving JSON: {e}\")\n",
    "\n",
    "print(\"\\n--- Aggregation and Plotting Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Generate Multi-Agent Aggregates and Plots\n",
    "\n",
    "import glob\n",
    "import hashlib\n",
    "\n",
    "MULTI_RESULTS_DIR = 'results_multi'\n",
    "MULTI_PLOTS_DIR = 'plots/multiagent'\n",
    "\n",
    "os.makedirs(MULTI_PLOTS_DIR, exist_ok=True)\n",
    "\n",
    "def create_config_hash(config_str):\n",
    "    \"\"\"Creates a short hash from a configuration string.\"\"\"\n",
    "    return hashlib.md5(config_str.encode('utf-8')).hexdigest()[:8]\n",
    "\n",
    "def load_all_multi_agent_csv_data(results_dir):\n",
    "    \"\"\"Loads all multi-agent CSV files and extracts config details.\"\"\"\n",
    "    all_files = glob.glob(os.path.join(results_dir, \"*.csv\"))\n",
    "    df_list = []\n",
    "    if not all_files:\n",
    "        print(f\"Warning: No CSV files found in {results_dir}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    for f in all_files:\n",
    "        try:\n",
    "            temp_df = pd.read_csv(f)\n",
    "            # Assuming 'config_details' column exists and contains the JSON string\n",
    "            if 'config_details' in temp_df.columns and not temp_df.empty:\n",
    "                # Use the config string from the first row to generate hash\n",
    "                config_str = temp_df['config_details'].iloc[0]\n",
    "                config_hash = create_config_hash(config_str)\n",
    "                temp_df['config_hash'] = config_hash\n",
    "                temp_df['config_str'] = config_str # Keep original string for reference\n",
    "                df_list.append(temp_df)\n",
    "            else:\n",
    "                 print(f\"Warning: Skipping {f} - missing 'config_details' column or empty file.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading or processing {f}: {e}\")\n",
    "\n",
    "    if not df_list:\n",
    "        print(\"Warning: No multi-agent data loaded.\")\n",
    "        return pd.DataFrame()\n",
    "    return pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "def clean_multi_agent_data(df):\n",
    "    \"\"\"Cleans the multi-agent DataFrame.\"\"\"\n",
    "    if df.empty:\n",
    "        return df\n",
    "\n",
    "    # Confidence to numeric (using extracted_confidence)\n",
    "    df['confidence'] = pd.to_numeric(df['extracted_confidence'], errors='coerce')\n",
    "    df['confidence'] = df['confidence'].fillna(-1).astype(int)\n",
    "\n",
    "    # Extract single letter answer (using extracted_answer)\n",
    "    df['answer_raw'] = df['extracted_answer'] # Keep original\n",
    "    df['answer'] = df['extracted_answer'].astype(str).str.strip().str.upper()\n",
    "    df['answer'] = df['answer'].apply(lambda x: x[0] if x and 'A' <= x[0] <= 'Z' else 'Invalid')\n",
    "\n",
    "    # Add category using Question_Handler if question_num exists\n",
    "    if Qs and 'question_num' in df.columns:\n",
    "        df['category'] = df['question_num'].apply(Qs.get_question_category)\n",
    "        df['category'] = df['category'].fillna('Unknown Category')\n",
    "    else:\n",
    "        df['category'] = 'Unknown Category'\n",
    "        if 'question_num' not in df.columns:\n",
    "             print(\"Warning: 'question_num' column missing, cannot determine categories.\")\n",
    "        else:\n",
    "             print(\"Warning: Question_Handler not available, cannot determine categories.\")\n",
    "\n",
    "    # Ensure numeric types for relevant columns if they exist\n",
    "    for col in ['question_num', 'run_index', 'message_index']:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(-1).astype(int)\n",
    "\n",
    "    return df\n",
    "\n",
    "def calculate_final_aggregates(df_group):\n",
    "    \"\"\"Calculates aggregates focusing on the *last* message from each agent in each run.\"\"\"\n",
    "    if df_group.empty or 'message_index' not in df_group.columns or 'agent_name' not in df_group.columns or 'run_index' not in df_group.columns:\n",
    "        return {\n",
    "            'total_final_responses': 0,\n",
    "            'final_answer_distribution': {},\n",
    "            'final_confidence_distribution': {},\n",
    "            'final_confidence_mean': None,\n",
    "            'final_confidence_median': None,\n",
    "            'valid_final_confidence_responses': 0\n",
    "        }\n",
    "\n",
    "    # Find the last message index for each agent within each run_index\n",
    "    last_messages_idx = df_group.loc[df_group.groupby(['run_index', 'agent_name'])['message_index'].idxmax()]\n",
    "\n",
    "    if last_messages_idx.empty:\n",
    "         return { # Return empty structure if no last messages found\n",
    "            'total_final_responses': 0,\n",
    "            'final_answer_distribution': {},\n",
    "            'final_confidence_distribution': {},\n",
    "            'final_confidence_mean': None,\n",
    "            'final_confidence_median': None,\n",
    "            'valid_final_confidence_responses': 0\n",
    "        }\n",
    "\n",
    "    final_answer_counts = last_messages_idx['answer'].value_counts().to_dict()\n",
    "    valid_conf_df = last_messages_idx[last_messages_idx['confidence'] != -1]\n",
    "    final_conf_counts = valid_conf_df['confidence'].value_counts().sort_index().to_dict()\n",
    "\n",
    "    return {\n",
    "        'total_final_responses': len(last_messages_idx),\n",
    "        'final_answer_distribution': final_answer_counts,\n",
    "        'final_confidence_distribution': final_conf_counts,\n",
    "        'final_confidence_mean': valid_conf_df['confidence'].mean() if not valid_conf_df.empty else None,\n",
    "        'final_confidence_median': valid_conf_df['confidence'].median() if not valid_conf_df.empty else None,\n",
    "        'valid_final_confidence_responses': len(valid_conf_df)\n",
    "    }\n",
    "\n",
    "# --- Load and Process Multi-Agent Data ---\n",
    "print(\"\\n--- Processing Multi-Agent Results ---\")\n",
    "df_multi_raw = load_all_multi_agent_csv_data(MULTI_RESULTS_DIR)\n",
    "df_multi = clean_multi_agent_data(df_multi_raw.copy())\n",
    "\n",
    "if df_multi.empty:\n",
    "    print(\"No multi-agent data loaded or processed. Skipping multi-agent plots.\")\n",
    "else:\n",
    "    print(f\"Loaded and cleaned {len(df_multi)} multi-agent records.\")\n",
    "    print(\"\\nUnique Config Hashes:\", df_multi['config_hash'].unique())\n",
    "    print(\"\\nDataFrame Head (Multi-Agent):\")\n",
    "    print(df_multi.head())\n",
    "\n",
    "    # --- Aggregate and Plot per Configuration ---\n",
    "    all_multi_aggregate_data = defaultdict(lambda: {'questions': {}, 'categories': {}, 'overall': {}})\n",
    "\n",
    "    for config_hash in df_multi['config_hash'].unique():\n",
    "        config_df = df_multi[df_multi['config_hash'] == config_hash]\n",
    "        config_str = config_df['config_str'].iloc[0] # Get the config string\n",
    "        chat_type = config_df['chat_type'].iloc[0] if 'chat_type' in config_df.columns else 'unknown'\n",
    "        print(f\"\\nProcessing Config Hash: {config_hash} (Type: {chat_type})\")\n",
    "\n",
    "        # Create output directory for this config\n",
    "        config_plot_dir = os.path.join(MULTI_PLOTS_DIR, config_hash)\n",
    "        os.makedirs(config_plot_dir, exist_ok=True)\n",
    "\n",
    "        # Overall Aggregates (using final messages)\n",
    "        overall_agg = calculate_final_aggregates(config_df)\n",
    "        all_multi_aggregate_data[config_hash]['overall'] = overall_agg\n",
    "        all_multi_aggregate_data[config_hash]['config_str'] = config_str # Store config string\n",
    "        all_multi_aggregate_data[config_hash]['chat_type'] = chat_type\n",
    "\n",
    "        # Per-Question Aggregates (using final messages)\n",
    "        if 'question_num' in config_df.columns:\n",
    "            question_numbers = sorted(config_df['question_num'].unique())\n",
    "            for q_num in question_numbers:\n",
    "                if q_num == -1: continue # Skip invalid question numbers\n",
    "                q_df = config_df[config_df['question_num'] == q_num]\n",
    "                if not q_df.empty:\n",
    "                    q_category = q_df['category'].iloc[0]\n",
    "                    q_id_info = Qs.get_question(q_num) if Qs else None\n",
    "                    q_id = q_id_info['question_id'] if q_id_info else f'UnknownID_Q{q_num}'\n",
    "                    q_agg = calculate_final_aggregates(q_df)\n",
    "                    q_num_int = int(q_num)\n",
    "                    all_multi_aggregate_data[config_hash]['questions'][q_num_int] = {\n",
    "                        'question_id': q_id,\n",
    "                        'category': q_category,\n",
    "                        **q_agg\n",
    "                    }\n",
    "\n",
    "        # Per-Category Aggregates (using final messages)\n",
    "        if 'category' in config_df.columns:\n",
    "            categories = sorted([c for c in config_df['category'].unique() if c != 'Unknown Category'])\n",
    "            for category in categories:\n",
    "                 cat_df = config_df[config_df['category'] == category]\n",
    "                 if not cat_df.empty:\n",
    "                     cat_agg = calculate_final_aggregates(cat_df)\n",
    "                     all_multi_aggregate_data[config_hash]['categories'][category] = cat_agg\n",
    "\n",
    "        # --- Generate Plots for this Config ---\n",
    "        print(f\"Generating plots for Config Hash: {config_hash}...\")\n",
    "\n",
    "        # Plot 1: Final Answer Distribution (Overall)\n",
    "        if overall_agg['total_final_responses'] > 0:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            ans_dist = overall_agg['final_answer_distribution']\n",
    "            plt.bar(ans_dist.keys(), ans_dist.values())\n",
    "            plt.title(f'Overall Final Answer Distribution\\nConfig Hash: {config_hash} (Type: {chat_type})', fontsize=14)\n",
    "            plt.xlabel('Final Answer', fontsize=12)\n",
    "            plt.ylabel('Count', fontsize=12)\n",
    "            plt.xticks(fontsize=10)\n",
    "            plt.yticks(fontsize=10)\n",
    "            plt.grid(True, axis='y', linestyle='--', alpha=0.6)\n",
    "            plot1_filename = os.path.join(config_plot_dir, 'overall_final_answer_dist.png')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(plot1_filename)\n",
    "            print(f\"  Plot saved: {plot1_filename}\")\n",
    "            plt.close()\n",
    "        else:\n",
    "            print(\"  Skipping overall final answer plot (no final responses).\")\n",
    "\n",
    "        # Plot 2: Final Confidence Distribution (Overall)\n",
    "        if overall_agg['valid_final_confidence_responses'] > 0:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            conf_dist = overall_agg['final_confidence_distribution']\n",
    "            # Ensure keys are sorted for confidence plot\n",
    "            conf_keys = sorted(conf_dist.keys())\n",
    "            conf_values = [conf_dist[k] for k in conf_keys]\n",
    "            plt.bar([str(k) for k in conf_keys], conf_values) # Use string keys for discrete confidence levels\n",
    "            plt.title(f'Overall Final Confidence Distribution\\nConfig Hash: {config_hash} (Type: {chat_type})', fontsize=14)\n",
    "            plt.xlabel('Final Confidence (0-5)', fontsize=12)\n",
    "            plt.ylabel('Count', fontsize=12)\n",
    "            plt.xticks(fontsize=10)\n",
    "            plt.yticks(fontsize=10)\n",
    "            plt.grid(True, axis='y', linestyle='--', alpha=0.6)\n",
    "            plot2_filename = os.path.join(config_plot_dir, 'overall_final_confidence_dist.png')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(plot2_filename)\n",
    "            print(f\"  Plot saved: {plot2_filename}\")\n",
    "            plt.close()\n",
    "        else:\n",
    "            print(\"  Skipping overall final confidence plot (no valid final confidence responses).\")\n",
    "\n",
    "        # Plot 3: Mean Final Confidence per Question (if questions exist)\n",
    "        if all_multi_aggregate_data[config_hash]['questions']:\n",
    "            plt.figure(figsize=(15, 8))\n",
    "            q_data = all_multi_aggregate_data[config_hash]['questions']\n",
    "            q_nums = sorted(q_data.keys())\n",
    "            mean_confs = [q_data[q]['final_confidence_mean'] for q in q_nums if q_data[q]['final_confidence_mean'] is not None]\n",
    "            valid_q_nums = [q for q in q_nums if q_data[q]['final_confidence_mean'] is not None]\n",
    "            if valid_q_nums:\n",
    "                 plt.plot(valid_q_nums, mean_confs, marker='o', linestyle='-', markersize=4, label=f'Config: {config_hash}')\n",
    "                 plt.title(f'Mean Final Confidence per Question\\nConfig Hash: {config_hash} (Type: {chat_type})', fontsize=16)\n",
    "                 plt.xlabel('Question Number', fontsize=12)\n",
    "                 plt.ylabel('Mean Final Confidence (0-5)', fontsize=12)\n",
    "                 plt.xticks(fontsize=10)\n",
    "                 plt.yticks(fontsize=10)\n",
    "                 plt.legend(fontsize=10)\n",
    "                 plt.grid(True, linestyle='--', alpha=0.6)\n",
    "                 plt.tight_layout()\n",
    "                 plot3_filename = os.path.join(config_plot_dir, 'mean_final_confidence_per_question.png')\n",
    "                 plt.savefig(plot3_filename)\n",
    "                 print(f\"  Plot saved: {plot3_filename}\")\n",
    "                 plt.close()\n",
    "            else:\n",
    "                 print(\"  Skipping mean final confidence per question plot (no valid data).\")\n",
    "        else:\n",
    "            print(\"  Skipping mean final confidence per question plot (no question data).\")\n",
    "\n",
    "        # --- Save Aggregated JSON for this Config ---\n",
    "        agg_json_filename = os.path.join(config_plot_dir, 'aggregate_results.json')\n",
    "        print(f\"Saving aggregate data for Config Hash {config_hash} to {agg_json_filename}...\")\n",
    "        try:\n",
    "            # Use the same numpy conversion function defined earlier\n",
    "            serializable_data = convert_numpy(all_multi_aggregate_data[config_hash])\n",
    "            with open(agg_json_filename, 'w', encoding='utf-8') as f:\n",
    "                json.dump(serializable_data, f, indent=4)\n",
    "            print(f\"  Aggregate data saved successfully.\")\n",
    "        except NameError:\n",
    "             print(\"Error: convert_numpy function not found. Make sure the single-agent cell defining it has been run.\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Error saving JSON for config {config_hash}: {e}\")\n",
    "\n",
    "print(\"\\n--- Multi-Agent Aggregation and Plotting Complete ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sitewiz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1c7ea94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import json\n",
    "import collections\n",
    "import asyncio\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "from datetime import datetime # Ensure datetime is imported\n",
    "\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.conditions import MaxMessageTermination\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from typing import Literal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1a33aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questions already have IDs\n"
     ]
    }
   ],
   "source": [
    "# core vairables to import from src \n",
    "from src import models, TEMP\n",
    "# import question handler\n",
    "from src import GGB_Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4f12c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION_JSON = os.path.abspath('GGB_benchmark/GreatestGoodBenchmark.json') \n",
    "Inverted_JSON = os.path.abspath('GGB_benchmark/GreatestGoodBenchmarkInverted.json') \n",
    "ggb_Qs = GGB_Statements(QUESTION_JSON) \n",
    "ggb_iQs = GGB_Statements(Inverted_JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43f4a774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src import create_config_hash, get_multi_agent_filenames, setup_logger_multi, load_checkpoint_multi\n",
    "from src import extract_answer_from_response, extract_confidence_from_response # , get_prompt, get_client\n",
    "from src import PromptHandler, MultiAgentHandler, RingHandler \n",
    "import gc\n",
    "\n",
    "import asyncio\n",
    "import random\n",
    "import time\n",
    "import gc\n",
    "from typing import Sequence, List, Dict, Any\n",
    "import hashlib\n",
    "import logging\n",
    "import re\n",
    "import csv\n",
    "\n",
    "from src import get_model_shortname\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a064cf36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: hetero\n",
      "1: models[0] = openai/gpt-4o-mini\n",
      "2: models[1] = anthropic/claude-3.5-haiku\n",
      "3: models[2] = google/gemini-2.0-flash-lite-001\n",
      "4: models[3] = qwen/qwen-2.5-7b-instruct\n",
      "5: models[4] = meta-llama/llama-3.1-8b-instruct\n",
      "6: models[5] = deepseek/deepseek-chat-v3-0324\n"
     ]
    }
   ],
   "source": [
    "# If you wanna see what you'll be running based off the index i\n",
    "for i in range(0, len(models) + 1):\n",
    "    if i == 0:\n",
    "        print(f'{i}: hetero')\n",
    "    else:\n",
    "        print(f'{i}: models[{i-1}] = {models[i-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43a324c",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_main_ring(Ring:RingHandler): # Renamed to avoid conflict if running star chat later\n",
    "    await Ring.main_ring_convergence()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    n_models = len(models)\n",
    "    #########################################   \n",
    "    ## TODO: CHANGE HERE\n",
    "    ##   WHO ARE YOU?    ## ## ## ## ## ## ##\n",
    "    #########################################\n",
    "\n",
    "    # sinem\n",
    "    my_range = range(0, 3)\n",
    "\n",
    "    # # martin \n",
    "    # my_range = range(3, 5)\n",
    "    \n",
    "    # # ram\n",
    "    # my_range = range(5, n_models+1)\n",
    "\n",
    "    NROUNDS = 4\n",
    "    NREPEATS = 12\n",
    "    # Standard way to run asyncio main in a script/notebook\n",
    "    ous_prompt = PromptHandler(group_chat = True)\n",
    "    inverted_prompt = PromptHandler(group_chat=True, invert_answer=True)\n",
    "    \n",
    "    for i in my_range: #range(0, n_models + 1): # my_range \n",
    "        if i == 0 :\n",
    "            run_models = models\n",
    "            run_chat_type = 'hetero_ring'\n",
    "            shuffle = True\n",
    "        else: \n",
    "            run_models = [models[i-1]]*n_models\n",
    "            run_chat_type = get_model_shortname(run_models[0])+'_ring'\n",
    "            shuffle = False\n",
    "\n",
    "    \n",
    "        ous_ring = RingHandler(run_models, ggb_Qs,ous_prompt, nrounds=NROUNDS, nrepeats=NREPEATS, shuffle=shuffle, chat_type = 'ous_'+run_chat_type, csv_dir = 'results_ous_multi')\n",
    "        ous_inverted_ring = RingHandler(run_models, ggb_iQs, inverted_prompt, nrounds=NROUNDS, nrepeats=NREPEATS, \n",
    "                            shuffle=shuffle, chat_type = 'ous_inverted_'+run_chat_type, csv_dir = 'results_ous_multi')\n",
    "\n",
    "        if 'get_ipython' in globals() and get_ipython().__class__.__name__ == 'ZMQInteractiveShell':\n",
    "            import nest_asyncio\n",
    "            nest_asyncio.apply()\n",
    "            asyncio.run(run_main_ring(ous_inverted_ring))\n",
    "            asyncio.run(run_main_ring(ous_ring))\n",
    "        else:\n",
    "            asyncio.run(run_main_ring(ous_inverted_ring))\n",
    "            asyncio.run(run_main_ring(ous_ring))\n",
    "        # for safety    \n",
    "        del ous_ring\n",
    "        del ous_inverted_ring\n",
    "        del run_models\n",
    "        del run_chat_type"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

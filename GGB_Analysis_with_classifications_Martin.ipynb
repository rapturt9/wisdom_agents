{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import json\n",
    "import collections\n",
    "import asyncio\n",
    "import re\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from typing import Literal\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "import glob\n",
    "from math import isnan\n",
    "\n",
    "from matplotlib.patches import Rectangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main functions to import from src\n",
    "from src import GGB_Statements,  get_model_shortname\n",
    "from analysis_functions import ring_csv_to_df, ring_to_roundrobin_df, load_and_clean_single_run, get_agent_shortname\n",
    "\n",
    "from visualization_functions import plot_by_question, human_kde, h2, plot_IH_v_IB, cleanup_IBvIH_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# questions \n",
    "QUESTION_JSON = os.path.abspath('GGB_benchmark/GreatestGoodBenchmark.json') \n",
    "Inverted_JSON = os.path.abspath('GGB_benchmark/GreatestGoodBenchmarkInverted.json') \n",
    "ggb_Qs = GGB_Statements(QUESTION_JSON) \n",
    "ggb_iQs = GGB_Statements(Inverted_JSON)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "# Specifications for paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_width = 3.3125 # inches\n",
    "text_wdith = 7.0 # inches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "# SINGLE ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_csvs = glob.glob('results/single_ggb**_q1-90_n12.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_df = pd.DataFrame()\n",
    "\n",
    "for irun, runcsv in enumerate(single_csvs):\n",
    "    if 'inverted' in runcsv:\n",
    "        Qs = ggb_iQs\n",
    "        label = 'GGB_inverted'\n",
    "    else:\n",
    "        Qs = ggb_Qs\n",
    "        label = 'GGB'\n",
    "\n",
    "    temp_df = load_and_clean_single_run([runcsv], Qs, label)\n",
    "    # get the (or corresponding) ous_question_id \n",
    "    temp_df['ggb_question_id'] = temp_df['question_id'] % 100\n",
    "    single_df = pd.concat([single_df, temp_df], ignore_index=True)\n",
    "    del Qs\n",
    "    del temp_df\n",
    "    \n",
    "# add label (model and runtype)\n",
    "single_df['label'] = single_df['run_label'] + '_' + single_df['model_name'].apply(get_model_shortname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_df.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert answer column to numeric, coercing errors to NaN\n",
    "single_df['answer_numeric'] = pd.to_numeric(single_df['answer'], errors='coerce')\n",
    "\n",
    "# Create the grouped calculations with nanmean and sem handling NaNs\n",
    "single_by_question = single_df.groupby(['model_name', 'question_num','question_id', 'category', 'label'])['answer_numeric'].agg([\n",
    "    ('mean', lambda x: np.nanmean(x)),\n",
    "    ('std',  lambda x: np.nanstd(x, ddof=1)),\n",
    "    ('sem', lambda x: np.nanstd(x, ddof=1) / np.sqrt(np.sum(~np.isnan(x))))\n",
    "]).reset_index()\n",
    "\n",
    "# (2) For each model and category, get mean and sem across all runs and question_nums\n",
    "single_by_category = single_df.groupby(['model_name', 'category', 'label'])['answer_numeric'].agg([\n",
    "    ('mean', lambda x: np.nanmean(x)),\n",
    "    ('std',  lambda x: np.nanstd(x, ddof=1)),\n",
    "    ('sem', lambda x: np.nanstd(x, ddof=1) / np.sqrt(np.sum(~np.isnan(x))))\n",
    "]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_by_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, _ = plot_IH_v_IB (single_by_category, use_std = False, label = 'label', text_size=10)\n",
    "ax = f.axes\n",
    "ax[0].axis('square')\n",
    "f.set_size_inches(1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODIFY FIGURE (SINGLE)\n",
    "f = cleanup_IBvIH_plot(f)\n",
    "# Display the updated figure\n",
    "display(f)\n",
    "\n",
    "# f.savefig('figures/singleIBvIH.png')\n",
    "f.savefig('figures/singleIBvIH.pdf', bbox_inches='tight', pad_inches=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "# RING ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "ring_csvs = glob.glob('results_multi/ggb_**_ensemble_**_q1-90_n12.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the file\n",
    "current_Qs = ggb_iQs\n",
    "\n",
    "csv_file = ring_csvs[0]\n",
    "df = ring_csv_to_df(csv_file, current_Qs)\n",
    "print(f\"Processing {csv_file}\")\n",
    "print(f\"Raw DataFrame shape: {df.shape}\")\n",
    "print(f\"Columns: {df.columns.tolist() if not df.empty else 'Empty'}\")\n",
    "\n",
    "# Convert to round robin format\n",
    "rr_df = ring_to_roundrobin_df(df, current_Qs)\n",
    "print(f\"Round-robin DataFrame shape: {rr_df.shape}\")\n",
    "rr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-allocate lists to collect dataframes\n",
    "ring_dfs = []\n",
    "ring_rr_dfs = []\n",
    "\n",
    "# Process each CSV file\n",
    "for csv_file in ring_csvs:\n",
    "    print(f\"Processing {csv_file}\")\n",
    "    \n",
    "    # Determine which question set to use\n",
    "    current_Qs = ggb_iQs if 'inverted' in csv_file else ggb_Qs\n",
    "    \n",
    "    # Process the file\n",
    "    df = ring_csv_to_df(csv_file, current_Qs)\n",
    "    print(f\"  Raw DataFrame shape: {df.shape}\")\n",
    "    \n",
    "    if not df.empty:\n",
    "        ring_dfs.append(df)\n",
    "        \n",
    "        # Convert to round robin format\n",
    "        rr_df = ring_to_roundrobin_df(df, current_Qs)\n",
    "        print(f\"  Round-robin DataFrame shape: {rr_df.shape}\")\n",
    "        \n",
    "        if not rr_df.empty:\n",
    "            ring_rr_dfs.append(rr_df)\n",
    "        else:\n",
    "            print(f\"  Warning: Round-robin conversion failed for {csv_file}\")\n",
    "    else:\n",
    "        print(f\"  Warning: No data extracted from {csv_file}\")\n",
    "\n",
    "# Single concat operations outside the loop\n",
    "if ring_dfs:\n",
    "    ring_df = pd.concat(ring_dfs, ignore_index=True)\n",
    "    print(f\"Combined ring_df shape: {ring_df.shape}\")\n",
    "else:\n",
    "    ring_df = pd.DataFrame()\n",
    "    print(\"No ring data found\")\n",
    "\n",
    "if ring_rr_dfs:\n",
    "    ring_rr_df = pd.concat(ring_rr_dfs, ignore_index=True)\n",
    "    # Add the question ID\n",
    "    ring_rr_df['ggb_question_id'] = ring_rr_df['question_id'] % 100\n",
    "    print(f\"Combined ring_rr_df shape: {ring_rr_df.shape}\")\n",
    "    print(f\"Sample of ring_rr_df columns: {ring_rr_df.columns.tolist()}\")\n",
    "else:\n",
    "    ring_rr_df = pd.DataFrame()\n",
    "    print(\"No round-robin data found\")\n",
    "\n",
    "print(f\"Processed {len(ring_dfs)} ring dataframes, {len(ring_rr_dfs)} round-robin dataframes\")\n",
    "print(f\"Total ring records: {len(ring_df)}, Total round-robin records: {len(ring_rr_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "ring_df = pd.concat(ring_dfs, ignore_index=True)\n",
    "ring_rr_df = pd.concat(ring_rr_dfs, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "ring_rr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the missing repeats/questions\n",
    "for chat in ring_df.chat_type.unique():\n",
    "    for q in ring_df['question_num'].unique():\n",
    "        reps = np.sort(ring_df[((ring_df['chat_type'] == chat) & (ring_df['question_num'] == q))]['run_index'].unique())\n",
    "        try:\n",
    "            if np.all(reps == np.arange(1,13)):\n",
    "                continue\n",
    "        except: \n",
    "            print(f'chat:{chat}, Q:{q}, reps that ran: {reps}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the answers by each agent\n",
    "rr_by_agent_df = ring_rr_df.copy()\n",
    "rr_by_agent_df['agent_shortname']  = rr_by_agent_df['agent_name'].apply(get_agent_shortname)\n",
    "# More concise alternative using a single apply\n",
    "rr_by_agent_df['agent_shortname'] = rr_by_agent_df.apply(\n",
    "    lambda row: row['agent_shortname'] + '_inverted' \n",
    "    if 'inverted' in row['chat_type'].lower() \n",
    "    else row['agent_shortname'], \n",
    "    axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "rr_by_agent_df.agent_shortname.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "ring_by_category_and_model = rr_by_agent_df.groupby(['agent_shortname', 'category','round','message_index'])['agent_answer'].agg([\n",
    "    ('mean', lambda x: np.nanmean(x)),\n",
    "    ('std',  lambda x: np.nanstd(x, ddof=1)),\n",
    "    ('sem', lambda x: np.nanstd(x, ddof=1) / np.sqrt(np.sum(~np.isnan(x))))\n",
    "    ]).reset_index()\n",
    "\n",
    "ring_by_question = ring_rr_df.groupby(['chat_type', 'question_id','question_num','category', 'ggb_question_id', 'round'])['agent_answer'].agg([\n",
    "    ('mean', lambda x: np.nanmean(x)),\n",
    "    ('std',  lambda x: np.nanstd(x, ddof=1)),\n",
    "    ('sem', lambda x: np.nanstd(x, ddof=1) / np.sqrt(np.sum(~np.isnan(x))))\n",
    "]).reset_index()\n",
    "\n",
    "# ous_by_question.column\n",
    "ring_by_category = ring_rr_df.groupby(['chat_type', 'category', 'round'])['agent_answer'].agg([\n",
    "    ('mean', lambda x: np.nanmean(x)),\n",
    "    ('std',  lambda x: np.nanstd(x, ddof=1)),\n",
    "    ('sem', lambda x: np.nanstd(x, ddof=1) / np.sqrt(np.sum(~np.isnan(x))))\n",
    "]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "ring_by_category_and_model.agent_shortname.unique()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "## Individual Agents's responses in Hetero and Homo Ring Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "f,_ = plot_IH_v_IB (ring_by_category_and_model[ring_by_category_and_model['round'] == 1], use_std = False, ax_lims=[1,7], label='agent_shortname')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODIFY FIGURE (SINGLE)\n",
    "\n",
    "fof = cleanup_IBvIH_plot(f)\n",
    "# Display the updated figure\n",
    "display(f)\n",
    "\n",
    "# f.savefig('figures/singleIBvIH.png')\n",
    "f.savefig('figures/agent_by_cat_ring_IBvIH.pdf', bbox_inches='tight', pad_inches=0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "## Mixed Single and MAS (see if round 1, message 1 and Singles are the same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_single_and_MAS = pd.DataFrame()\n",
    "ring_by_category_and_model[(ring_by_category_and_model['round'] == 1) & (ring_by_category_and_model['message_index'] == 1)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_by_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_by_category.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import mannwhitneyu, norm\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "results = []\n",
    "\n",
    "# Extract unique labels from single_by_category for matching\n",
    "available_labels = single_by_category['label'].unique()\n",
    "\n",
    "# Loop over agent_shortnames in rr_by_agent_df\n",
    "for agent in rr_by_agent_df['agent_shortname'].unique():\n",
    "    if 'inverted' in agent:\n",
    "        # e.g. \"claude_inverted\" -> \"GGB_inverted_claude\"\n",
    "        base = agent.replace('_inverted', '')\n",
    "        label = f'GGB_inverted_{base}'\n",
    "    else:\n",
    "        label = f'GGB_{agent}'\n",
    "\n",
    "    if label not in available_labels:\n",
    "        continue\n",
    "\n",
    "    y = rr_by_agent_df[(rr_by_agent_df['agent_shortname'] == agent) &\n",
    "                       (rr_by_agent_df['round'] == 1) &\n",
    "                        (rr_by_agent_df['message_index'] == 1)\n",
    "      ]['agent_answer'].dropna()\n",
    "    x = single_df[single_df['label'] == label]['answer_numeric'].dropna()\n",
    "\n",
    "    if len(x) < 2 or len(y) < 2:\n",
    "        continue\n",
    "\n",
    "    stat, p = mannwhitneyu(x, y, alternative='two-sided')\n",
    "\n",
    "    try:\n",
    "        z = norm.ppf(1 - p / 2)\n",
    "        r = z / np.sqrt(len(x) + len(y))\n",
    "    except:\n",
    "        r = np.nan\n",
    "\n",
    "    results.append({\n",
    "        'agent': agent,\n",
    "        'label': label,\n",
    "        'n_x': len(x),\n",
    "        'n_y': len(y),\n",
    "        'U': stat,\n",
    "        'p_value': p,\n",
    "        'effect_size_r': r\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Round selected float columns\n",
    "results_df['p_value'] = results_df['p_value'].round(2)\n",
    "results_df['effect_size_r'] = results_df['effect_size_r'].round(2)\n",
    "\n",
    "\n",
    "# for better display/sorting:\n",
    "# Create a helper column with base agent name (without \"_inverted\")\n",
    "results_df['agent_base'] = results_df['agent'].str.replace('_inverted', '', regex=False)\n",
    "\n",
    "# Optional: set a consistent order based on unique agent bases\n",
    "agent_order = results_df['agent_base'].drop_duplicates().tolist()\n",
    "\n",
    "# Sort by agent base first, then put normal agent before inverted\n",
    "results_df = results_df.sort_values(\n",
    "    by=['agent_base', 'agent'],\n",
    "    key=lambda col: col if col.name != 'agent' else col.apply(lambda x: (x.endswith('_inverted'), x))\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Drop the helper column if not needed\n",
    "results_df = results_df.drop(columns='agent_base')\n",
    "\n",
    "#print(results_df)\n",
    "results_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "## Ring By Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before calling plot_by_question, add validation\n",
    "round_4_data = ring_by_question[ring_by_question['round'] == 4]\n",
    "\n",
    "if round_4_data.empty:\n",
    "    print(\"Warning: No data found for round 4\")\n",
    "elif 'chat_type' not in round_4_data.columns:\n",
    "    print(\"Warning: 'chat_type' column not found in data\")\n",
    "elif round_4_data['chat_type'].isna().all():\n",
    "    print(\"Warning: All 'chat_type' values are NaN\")\n",
    "else:\n",
    "    # Check if we have any valid groups\n",
    "    valid_groups = round_4_data.groupby('chat_type').size()\n",
    "    if len(valid_groups) == 0:\n",
    "        print(\"Warning: No valid groups found for chat_type\")\n",
    "    else:\n",
    "        print(f\"Found {len(valid_groups)} chat types: {valid_groups.index.tolist()}\")\n",
    "        \n",
    "        f = plot_by_question(data = round_4_data, group_by = 'chat_type', category_order=['IH','IB'], \n",
    "            match_inverted_colors=True,\n",
    "            inverted_indicator='inverted', error_col= 'sem')\n",
    "\n",
    "        ax = f.axes[0]  # Get the axes from the figure\n",
    "        ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=3)\n",
    "        plt.tight_layout()  # Adjust layout to accommodate the legend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "## Round 4 Homo and Hetero Ring ensembles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "round_4_rr_df = ring_rr_df[ring_rr_df['round'] == 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "round_4_deepseek = round_4_rr_df[(round_4_rr_df['category'] == 'IH') & (round_4_rr_df['chat_type'].apply(lambda x: 'deepseek' in x))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plot_IH_v_IB (ring_by_category[ring_by_category['round'] == 4], use_std = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plot_IH_v_IB (ring_by_category[ring_by_category['round'] == 4], use_std = True,ax_lims=[0,8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "## Convergence for a round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualization_functions import plot_rr_round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False: # just to avoid massive plotting (these plots still need help to be publicaiton ready)\n",
    "    all_chat_types = ring_rr_df.chat_type.unique()\n",
    "    for chat in all_chat_types:\n",
    "        chat_rr_df = ring_rr_df[ring_rr_df['chat_type']==chat].copy()\n",
    "        start_rep = chat_rr_df['repeat_index'].min()\n",
    "        end_rep = chat_rr_df['repeat_index'].max()\n",
    "\n",
    "        for rep in range(start_rep, end_rep + 1):\n",
    "            # print(f'{rep}')\n",
    "            this_rep_df = chat_rr_df[chat_rr_df['repeat_index']==rep].copy()\n",
    "            plot_rr_round(this_rep_df , round = 4)\n",
    "    # TODO: average over rounds!\n",
    "    # TODO: why is it repeating 2x (there should be 5 repeats??)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "# STAR ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# going to need to chnage the chat type for each one because currently has the supervisor name in the chat type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis_functions import star_csv_to_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "ous_star_csvs = glob.glob('results_ous_multi/**_star_super**_q1-9_n2.csv')\n",
    "ous_evilstar_csvs = glob.glob('results_ous_multi/**_star_evil**_q1-9_n2.csv')\n",
    "\n",
    "ous_all_star = glob.glob('results_ous_multi/**star**_q1-9_n2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "ous_all_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "for csv_file in ous_all_star:\n",
    "    if 'inverted' in csv_file:\n",
    "        current_Qs = ous_iQs\n",
    "    else:\n",
    "        current_Qs = ous_Qs\n",
    "    \n",
    "    df = star_csv_to_df(csv_file, current_Qs, csv_file)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change supervisor to shortname\n",
    "supervisor = df['config_details'].apply(lambda x: get_model_shortname(x['central_model']))\n",
    "\n",
    "if len(supervisor.unique()) > 1:\n",
    "    Warning('This function wors for one supervisor at a time')\n",
    "    # TODO: UNCOOMENT WHEN TURNING INTO A FUNCTION\n",
    "    # return \n",
    "\n",
    "# number of loops\n",
    "n_loops = df['config_details'][0]['loops']\n",
    "# number of repeats\n",
    "repeats = df['run_index'].unique()\n",
    "\n",
    "# add 1 to repeat if starts at 0 else add 0 when saving\n",
    "minrep = min(repeats)\n",
    "if minrep == 0:\n",
    "    add_to_repeat = 1\n",
    "elif minrep == 1:\n",
    "    add_to_repeat = 0\n",
    "else:\n",
    "    Warning(f'repeats start at {minrep}')\n",
    "    add_to_repeat = 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
